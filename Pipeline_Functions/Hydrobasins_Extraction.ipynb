{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your coordinates data\n",
    "coordinates = pd.read_csv('/data/Hydra_Work/Rodeo_Data/static_indices.csv')[['site_id', 'latitude_mean', 'longitude_mean']]\n",
    "coordinates.set_index('site_id', inplace = True)\n",
    "\n",
    "# Define the base path and file names\n",
    "base_path = '/data/Hydra_Work/Pipeline_Functions/Camels_US/'\n",
    "file_names = ['camels_geol.txt', 'camels_clim.txt', 'camels_topo.txt', 'camels_soil.txt', 'camels_hydro.txt', 'camels_vege.txt', 'camels_name.txt']\n",
    "\n",
    "# Initialize an empty dictionary to hold the DataFrames\n",
    "dfs = {}\n",
    "\n",
    "# Read each file into a DataFrame and store it in the dictionary\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    df_name = file_name.split('.')[0].split('_')[1] + '_vars'  # Generate a variable name like 'geol_vars'\n",
    "    dfs[df_name] = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Merge all DataFrames on 'gauge_id'\n",
    "all_vars_df = dfs['geol_vars']\n",
    "for key in dfs:\n",
    "    if key != 'geol_vars':  # Skip the first DataFrame since we already initialized merged_df with it\n",
    "        all_vars_df = pd.merge(merged_df, dfs[key], on='gauge_id', how='inner')\n",
    "\n",
    "\n",
    "# List of attributes and their source\n",
    "Attributes_df = pd.read_excel('/data/Hydra_Work/Pipeline_Functions/Camels_US/camels_attributes_v2.0.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrobasins_df = pd.read_csv('/data/Hydra_Work/Rodeo_Data/hydrobasins_summary.csv')\n",
    " \n",
    "hydrobasins_df.set_index('site_id', inplace = True)\n",
    "hydrobasins_df.to_csv('/data/Hydra_Work/Rodeo_Data/static_indices.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>inu_pc_smn</th>\n",
       "      <th>inu_pc_smx</th>\n",
       "      <th>inu_pc_slt</th>\n",
       "      <th>inu_pc_umn</th>\n",
       "      <th>inu_pc_umx</th>\n",
       "      <th>inu_pc_ult</th>\n",
       "      <th>lka_pc_sse</th>\n",
       "      <th>lka_pc_use</th>\n",
       "      <th>dor_pc_pva</th>\n",
       "      <th>...</th>\n",
       "      <th>clz_cl_smj</th>\n",
       "      <th>cls_cl_smj</th>\n",
       "      <th>glc_cl_smj</th>\n",
       "      <th>pnv_cl_smj</th>\n",
       "      <th>wet_cl_smj</th>\n",
       "      <th>tbi_cl_smj</th>\n",
       "      <th>tec_cl_smj</th>\n",
       "      <th>fmh_cl_smj</th>\n",
       "      <th>fec_cl_smj</th>\n",
       "      <th>lit_cl_smj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>american_river_folsom_lake</td>\n",
       "      <td>1.281250</td>\n",
       "      <td>1.843750</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.343750</td>\n",
       "      <td>1.625000</td>\n",
       "      <td>5.218750</td>\n",
       "      <td>13.718750</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>366</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animas_r_at_durango</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>30.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boise_r_nr_boise</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>1.641509</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>2.226415</td>\n",
       "      <td>8.226415</td>\n",
       "      <td>1.773585</td>\n",
       "      <td>218.905660</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>367</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boysen_reservoir_inflow</td>\n",
       "      <td>3.611465</td>\n",
       "      <td>3.611465</td>\n",
       "      <td>6.464968</td>\n",
       "      <td>0.312102</td>\n",
       "      <td>0.312102</td>\n",
       "      <td>2.910828</td>\n",
       "      <td>27.974522</td>\n",
       "      <td>5.426752</td>\n",
       "      <td>61.343949</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13</td>\n",
       "      <td>438</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>colville_r_at_kettle_falls</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>8.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>361</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>detroit_lake_inflow</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>21.875000</td>\n",
       "      <td>5.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>352</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dillon_reservoir_inflow</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fontenelle_reservoir_inflow</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.395062</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>1.012346</td>\n",
       "      <td>8.395062</td>\n",
       "      <td>8.469136</td>\n",
       "      <td>78.172840</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13</td>\n",
       "      <td>438</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>green_r_bl_howard_a_hanson_dam</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>53.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>352</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hungry_horse_reservoir_inflow</td>\n",
       "      <td>2.687500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>4.562500</td>\n",
       "      <td>43.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>361</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>libby_reservoir_inflow</td>\n",
       "      <td>2.368715</td>\n",
       "      <td>2.374302</td>\n",
       "      <td>4.122905</td>\n",
       "      <td>0.167598</td>\n",
       "      <td>0.167598</td>\n",
       "      <td>0.955307</td>\n",
       "      <td>15.854749</td>\n",
       "      <td>2.664804</td>\n",
       "      <td>4.128492</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>361</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>merced_river_yosemite_at_pohono_bridge</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.875000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>366</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>missouri_r_at_toston</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>1.105263</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.674342</td>\n",
       "      <td>6.315789</td>\n",
       "      <td>3.526316</td>\n",
       "      <td>80.529605</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>394</td>\n",
       "      <td>6</td>\n",
       "      <td>142</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>owyhee_r_bl_owyhee_dam</td>\n",
       "      <td>0.701681</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>4.924370</td>\n",
       "      <td>0.063025</td>\n",
       "      <td>0.063025</td>\n",
       "      <td>1.197479</td>\n",
       "      <td>2.806723</td>\n",
       "      <td>1.596639</td>\n",
       "      <td>117.415966</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13</td>\n",
       "      <td>434</td>\n",
       "      <td>7</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pecos_r_nr_pecos</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pueblo_reservoir_inflow</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>2.159091</td>\n",
       "      <td>2.602273</td>\n",
       "      <td>2.409091</td>\n",
       "      <td>817.488636</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ruedi_reservoir_inflow</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>416.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>san_joaquin_river_millerton_reservoir</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>3.194444</td>\n",
       "      <td>4.777778</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>5.805556</td>\n",
       "      <td>9.111111</td>\n",
       "      <td>14.416667</td>\n",
       "      <td>11.305556</td>\n",
       "      <td>388.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>366</td>\n",
       "      <td>5</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>skagit_ross_reservoir</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>31.562500</td>\n",
       "      <td>4.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>358</td>\n",
       "      <td>5</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>snake_r_nr_heise</td>\n",
       "      <td>4.102564</td>\n",
       "      <td>4.153846</td>\n",
       "      <td>6.068376</td>\n",
       "      <td>0.623932</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>1.042735</td>\n",
       "      <td>29.324786</td>\n",
       "      <td>12.957265</td>\n",
       "      <td>142.213675</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>367</td>\n",
       "      <td>6</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>stehekin_r_at_stehekin</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>358</td>\n",
       "      <td>6</td>\n",
       "      <td>120</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sweetwater_r_nr_alcova</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>3.604167</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>4.895833</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13</td>\n",
       "      <td>438</td>\n",
       "      <td>7</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>taylor_park_reservoir_inflow</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>virgin_r_at_virtin</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>429</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>weber_r_nr_oakley</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>368</td>\n",
       "      <td>4</td>\n",
       "      <td>127</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>yampa_r_nr_maybell</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>1.826087</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.579710</td>\n",
       "      <td>2.086957</td>\n",
       "      <td>378.463768</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>353</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   site_id  inu_pc_smn  inu_pc_smx  \\\n",
       "0               american_river_folsom_lake    1.281250    1.843750   \n",
       "1                      animas_r_at_durango    1.090909    1.090909   \n",
       "2                         boise_r_nr_boise    0.320755    0.320755   \n",
       "3                  boysen_reservoir_inflow    3.611465    3.611465   \n",
       "4               colville_r_at_kettle_falls    1.300000    1.300000   \n",
       "5                      detroit_lake_inflow    0.375000    0.375000   \n",
       "6                  dillon_reservoir_inflow    0.200000    0.200000   \n",
       "7              fontenelle_reservoir_inflow    0.666667    0.666667   \n",
       "8           green_r_bl_howard_a_hanson_dam   17.000000   36.000000   \n",
       "9            hungry_horse_reservoir_inflow    2.687500    3.000000   \n",
       "10                  libby_reservoir_inflow    2.368715    2.374302   \n",
       "11  merced_river_yosemite_at_pohono_bridge    3.750000    3.875000   \n",
       "12                    missouri_r_at_toston    1.105263    1.105263   \n",
       "13                  owyhee_r_bl_owyhee_dam    0.701681    0.705882   \n",
       "14                        pecos_r_nr_pecos    0.000000    0.000000   \n",
       "15                 pueblo_reservoir_inflow    0.261364    0.261364   \n",
       "16                  ruedi_reservoir_inflow    0.000000    0.000000   \n",
       "17   san_joaquin_river_millerton_reservoir    0.888889    3.194444   \n",
       "18                   skagit_ross_reservoir    1.562500    1.562500   \n",
       "19                        snake_r_nr_heise    4.102564    4.153846   \n",
       "20                  stehekin_r_at_stehekin    1.400000    1.400000   \n",
       "21                  sweetwater_r_nr_alcova    0.041667    0.041667   \n",
       "22            taylor_park_reservoir_inflow    0.000000    0.000000   \n",
       "23                      virgin_r_at_virtin    0.266667    0.266667   \n",
       "24                       weber_r_nr_oakley    0.000000    1.000000   \n",
       "25                      yampa_r_nr_maybell    0.130435    0.130435   \n",
       "\n",
       "    inu_pc_slt  inu_pc_umn  inu_pc_umx  inu_pc_ult  lka_pc_sse  lka_pc_use  \\\n",
       "0     5.500000    1.343750    1.625000    5.218750   13.718750    9.250000   \n",
       "1     1.272727    0.090909    0.090909    0.545455    1.545455    0.636364   \n",
       "2     1.641509    0.037736    0.037736    2.226415    8.226415    1.773585   \n",
       "3     6.464968    0.312102    0.312102    2.910828   27.974522    5.426752   \n",
       "4     1.900000    0.750000    0.750000    1.550000    4.500000    8.950000   \n",
       "5     1.875000    0.125000    0.125000    2.500000   21.875000    5.375000   \n",
       "6     2.800000    0.000000    0.000000    2.000000   15.600000    9.800000   \n",
       "7     4.395062    0.037037    0.037037    1.012346    8.395062    8.469136   \n",
       "8    59.750000   32.500000   60.000000   83.000000    4.750000    1.250000   \n",
       "9     5.812500    0.468750    0.562500    1.375000   17.750000    4.562500   \n",
       "10    4.122905    0.167598    0.167598    0.955307   15.854749    2.664804   \n",
       "11   25.750000    4.500000    4.500000   31.750000    0.750000    1.125000   \n",
       "12    3.375000    0.184211    0.184211    0.674342    6.315789    3.526316   \n",
       "13    4.924370    0.063025    0.063025    1.197479    2.806723    1.596639   \n",
       "14    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "15    4.250000    0.011364    0.011364    2.159091    2.602273    2.409091   \n",
       "16    0.250000    0.000000    0.000000    0.250000    5.500000    1.250000   \n",
       "17    4.777778    1.583333    5.805556    9.111111   14.416667   11.305556   \n",
       "18    2.375000    0.250000    0.250000    0.562500   31.562500    4.062500   \n",
       "19    6.068376    0.623932    0.632479    1.042735   29.324786   12.957265   \n",
       "20    3.200000    1.800000    1.800000    3.800000    0.800000    1.200000   \n",
       "21    3.604167    0.020833    0.020833    4.895833    1.375000    0.916667   \n",
       "22    0.000000    0.000000    0.000000    0.000000   19.600000    2.200000   \n",
       "23    0.266667    0.066667    0.066667    0.066667    0.666667    0.266667   \n",
       "24    5.000000    0.000000    1.000000    5.333333    1.333333    1.666667   \n",
       "25    1.826087    0.014493    0.014493    0.666667    1.579710    2.086957   \n",
       "\n",
       "    dor_pc_pva  ...  clz_cl_smj  cls_cl_smj  glc_cl_smj  pnv_cl_smj  \\\n",
       "0   346.000000  ...           7          27           4           4   \n",
       "1    30.363636  ...           6          37           4           5   \n",
       "2   218.905660  ...           8          37           4           4   \n",
       "3    61.343949  ...           8          54          12          12   \n",
       "4     0.000000  ...           8          54           4           4   \n",
       "5     0.000000  ...           5          32           4           4   \n",
       "6     0.000000  ...           6          20           4           6   \n",
       "7    78.172840  ...           7          37           4           6   \n",
       "8    53.250000  ...           5          32           4           4   \n",
       "9    43.375000  ...           7          37           4           6   \n",
       "10    4.128492  ...           6          29           4           6   \n",
       "11    0.000000  ...           7          37           4           4   \n",
       "12   80.529605  ...           7          37           4           6   \n",
       "13  117.415966  ...           8          45          12          12   \n",
       "14    0.000000  ...           7          37           4           4   \n",
       "15  817.488636  ...           8          37           4          10   \n",
       "16  416.000000  ...           6          37           4           6   \n",
       "17  388.222222  ...          11          72           4           4   \n",
       "18    0.000000  ...           7          38           4           6   \n",
       "19  142.213675  ...           7          37           4           6   \n",
       "20    0.000000  ...           6          26           4           6   \n",
       "21    0.000000  ...           8          45          12          12   \n",
       "22    0.000000  ...           6          20           4           7   \n",
       "23    0.000000  ...           8          54           4           4   \n",
       "24  147.000000  ...           7          37           4           5   \n",
       "25  378.463768  ...           8          45           4           7   \n",
       "\n",
       "    wet_cl_smj  tbi_cl_smj  tec_cl_smj  fmh_cl_smj  fec_cl_smj  lit_cl_smj  \n",
       "0          1.0           5         366           5         125           9  \n",
       "1         11.0           5         353           4         130           3  \n",
       "2          1.0           5         367           7         121           9  \n",
       "3         11.0          13         438           6         142           3  \n",
       "4          1.0           5         361           6         120           1  \n",
       "5          1.0           5         352           7         121           2  \n",
       "6          1.0           5         353           4         130           9  \n",
       "7         11.0          13         438           4         130           1  \n",
       "8          1.0           5         352           5         103           2  \n",
       "9         11.0           5         361           6         120           6  \n",
       "10         2.0           5         361           6         120           6  \n",
       "11         1.0           5         366           5         125           9  \n",
       "12        11.0           8         394           6         142           8  \n",
       "13        11.0          13         434           7         121           2  \n",
       "14         NaN           5         353           4         133          13  \n",
       "15        10.0           5         353           6         144          10  \n",
       "16         1.0           5         353           4         130           9  \n",
       "17         1.0           5         366           5         125           3  \n",
       "18         2.0           5         358           5         103           5  \n",
       "19        11.0           5         367           6         122           3  \n",
       "20        11.0           5         358           6         120           8  \n",
       "21        11.0          13         438           7         143           3  \n",
       "22        11.0           5         353           4         130           9  \n",
       "23         1.0          13         429           4         129           5  \n",
       "24        11.0           5         368           4         127           3  \n",
       "25        11.0           5         353           4         130           3  \n",
       "\n",
       "[26 rows x 170 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "hydrobasins_df\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = hydrobasins_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "hydrobasins_df[numeric_columns] = scaler.fit_transform(hydrobasins_df[numeric_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_file_path = '/data/Hydra_Work/Scaled_Data/static_variables.pkl'\n",
    "hydrobasins_df.to_pickle(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  Fish River near Fort Kent, Maine\n",
      "1           Narraguagus River at Cherryfield, Maine\n",
      "2       Mattawamkeag River near Mattawamkeag, Maine\n",
      "3      Piscataquis River near Dover-Foxcroft, Maine\n",
      "4        Carrabassett River near North Anson, Maine\n",
      "                           ...                     \n",
      "666           WEST FORK COW CREEK NEAR GLENDALE, OR\n",
      "667                  STEAMBOAT CREEK NEAR GLIDE, OR\n",
      "668         SOUTH FORK COQUILLE RIVER AT POWERS, OR\n",
      "669                       STAR GULCH NEAR RUCH, OR.\n",
      "670                 CHETCO RIVER NEAR BROOKINGS, OR\n",
      "Name: gauge_name, Length: 671, dtype: object\n"
     ]
    }
   ],
   "source": [
    "all_vars_df['gauge_name']\n",
    "\n",
    "\n",
    "# search_name = 'colville'\n",
    "# filtered_df = all_vars_df[all_vars_df['gauge_name'].str.contains(search_name, case=False, na=False)]\n",
    "# print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gauge_id</th>\n",
       "      <th>geol_1st_class</th>\n",
       "      <th>glim_1st_class_frac</th>\n",
       "      <th>geol_2nd_class</th>\n",
       "      <th>glim_2nd_class_frac</th>\n",
       "      <th>carbonate_rocks_frac</th>\n",
       "      <th>geol_porostiy</th>\n",
       "      <th>geol_permeability</th>\n",
       "      <th>p_mean_x</th>\n",
       "      <th>pet_mean_x</th>\n",
       "      <th>...</th>\n",
       "      <th>gvf_max_y</th>\n",
       "      <th>gvf_diff_y</th>\n",
       "      <th>dom_land_cover_frac_y</th>\n",
       "      <th>dom_land_cover_y</th>\n",
       "      <th>root_depth_50_y</th>\n",
       "      <th>root_depth_99_y</th>\n",
       "      <th>huc_02_y</th>\n",
       "      <th>gauge_name_y</th>\n",
       "      <th>huc_02</th>\n",
       "      <th>gauge_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [gauge_id, geol_1st_class, glim_1st_class_frac, geol_2nd_class, glim_2nd_class_frac, carbonate_rocks_frac, geol_porostiy, geol_permeability, p_mean_x, pet_mean_x, p_seasonality_x, frac_snow_x, aridity_x, high_prec_freq_x, high_prec_dur_x, high_prec_timing_x, low_prec_freq_x, low_prec_dur_x, low_prec_timing_x, gauge_lat_x, gauge_lon_x, elev_mean_x, slope_mean_x, area_gages2_x, area_geospa_fabric_x, soil_depth_pelletier_x, soil_depth_statsgo_x, soil_porosity_x, soil_conductivity_x, max_water_content_x, sand_frac_x, silt_frac_x, clay_frac_x, water_frac_x, organic_frac_x, other_frac_x, q_mean_x, runoff_ratio_x, slope_fdc_x, baseflow_index_x, stream_elas_x, q5_x, q95_x, high_q_freq_x, high_q_dur_x, low_q_freq_x, low_q_dur_x, zero_q_freq_x, hfd_mean_x, frac_forest_x, lai_max_x, lai_diff_x, gvf_max_x, gvf_diff_x, dom_land_cover_frac_x, dom_land_cover_x, root_depth_50_x, root_depth_99_x, huc_02_x, gauge_name_x, p_mean_y, pet_mean_y, p_seasonality_y, frac_snow_y, aridity_y, high_prec_freq_y, high_prec_dur_y, high_prec_timing_y, low_prec_freq_y, low_prec_dur_y, low_prec_timing_y, gauge_lat_y, gauge_lon_y, elev_mean_y, slope_mean_y, area_gages2_y, area_geospa_fabric_y, soil_depth_pelletier_y, soil_depth_statsgo_y, soil_porosity_y, soil_conductivity_y, max_water_content_y, sand_frac_y, silt_frac_y, clay_frac_y, water_frac_y, organic_frac_y, other_frac_y, q_mean_y, runoff_ratio_y, slope_fdc_y, baseflow_index_y, stream_elas_y, q5_y, q95_y, high_q_freq_y, high_q_dur_y, low_q_freq_y, low_q_dur_y, zero_q_freq_y, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 114 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coordinates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Ensure the coordinate systems match\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a GeoDataFrame from the coordinates\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m geometry \u001b[38;5;241m=\u001b[39m [Point(xy) \u001b[38;5;28;01mfor\u001b[39;00m xy \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[43mcoordinates\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m], coordinates[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m      5\u001b[0m geo_df \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(coordinates, geometry\u001b[38;5;241m=\u001b[39mgeometry)\n\u001b[1;32m      6\u001b[0m geo_df\u001b[38;5;241m.\u001b[39mcrs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsg:4326\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'coordinates' is not defined"
     ]
    }
   ],
   "source": [
    "# Ensure the coordinate systems match\n",
    "# Load HydroBASINS data\n",
    "hydrobasins = gpd.read_file('path/to/hydrobasins_shapefile.shp')\n",
    "\n",
    "\n",
    "\n",
    "# Create a GeoDataFrame from the coordinates\n",
    "geometry = [Point(xy) for xy in zip(coordinates['lon'], coordinates['lat'])]\n",
    "geo_df = gpd.GeoDataFrame(coordinates, geometry=geometry)\n",
    "\n",
    "geo_df.crs = {'init': 'epsg:4326'}\n",
    "geo_df = geo_df.to_crs(hydrobasins.crs)\n",
    "\n",
    "# Perform the spatial join\n",
    "points_in_basins = gpd.sjoin(geo env -creae_df, hydrobasins, how='left', op='within')\n",
    "\n",
    "# 'points_in_basins' now contains the attributes of the HydroBASINS for each point\n",
    "\n",
    "# For example, extracting the 'BASIN_ID' for each point\n",
    "extracted_variables = points_in_basins[['lat', 'lon', 'BASIN_ID', 'other_variables']]\n",
    "print(extracted_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mneuralhydrology\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasetzoo\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdatazoo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshapely\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Point\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import neuralhydrology.datasetzoo as datazoo\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_camels_us_attributes() missing 1 required positional argument: 'data_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdatazoo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcamelsus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_camels_us_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_camels_us_attributes() missing 1 required positional argument: 'data_dir'"
     ]
    }
   ],
   "source": [
    "datazoo.camelsus.load_camels_us_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please email feedback to gdex@ucar.edu.\n",
      "\n",
      "camels_name.txt downloading: done\n",
      "camels_name.txt download successful\n",
      "camels_attributes_v2.0.xlsx downloading: done\n",
      "camels_attributes_v2.0.xlsx download successful\n",
      "camels_attributes_v2.0.pdf downloading: done\n",
      "camels_attributes_v2.0.pdf download successful\n",
      "basin_timeseries_v1p2_metForcing_obsFlow.zip downloading: done\n",
      "basin_timeseries_v1p2_metForcing_obsFlow.zip download validation error: [Errno 2] No such file or directory: 'basin_timeseries_v1p2_metForcing_obsFlow.zip.part'\n",
      "camels_topo.txt downloading: done\n",
      "camels_topo.txt download successful\n",
      "readme.txt downloading: done\n",
      "readme.txt download successful\n",
      "basin_set_full_res.zip downloading: done\n",
      "basin_set_full_res.zip download successful\n",
      "camels_vege.txt downloading: done\n",
      "camels_vege.txt download successful\n",
      "basin_timeseries_v1p2_modelOutput_maurer.zip downloading: done\n",
      "basin_timeseries_v1p2_modelOutput_maurer.zip download successful\n",
      "basin_timeseries_v1p2_modelOutput_nldas.zip downloading: done\n",
      "basin_timeseries_v1p2_modelOutput_nldas.zip download validation error: [Errno 2] No such file or directory: 'basin_timeseries_v1p2_modelOutput_nldas.zip.part'\n",
      "camels_geol.txt downloading: done\n",
      "camels_geol.txt download successful\n",
      "camels_clim.txt downloading: done\n",
      "camels_clim.txt download successful\n",
      "basin_timeseries_v1p2_modelOutput_daymet.zip downloading: done\n",
      "basin_timeseries_v1p2_modelOutput_daymet.zip download validation error: [Errno 2] No such file or directory: 'basin_timeseries_v1p2_modelOutput_daymet.zip.part'\n",
      "camels_hydro.txt downloading: done\n",
      "camels_hydro.txt download successful\n",
      "camels_soil.txt downloading: done\n",
      "camels_soil.txt download successful\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "import threading\n",
    "import sys\n",
    "import ssl\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError, URLError\n",
    "from urllib.parse import urlparse\n",
    "from platform import python_version\n",
    "\n",
    "################################################################\n",
    "#\n",
    "# Generated by: GDEX\n",
    "# Created: 2024-06-14T06:58:26-06:00\n",
    "#\n",
    "# Your download selection includes data that might be secured using API Token based\n",
    "# authentication. Therefore, this script can have your api-token. If you\n",
    "# re-generate your API Token after you download this script, the download will\n",
    "# fail. If that happens, you can either re-download the script or you can edit\n",
    "# this script replacing the old API Token with the new one. View your API token\n",
    "# by going to \"Account Home\":\n",
    "#\n",
    "# https://gdex.ucar.edu/account/user/account-home.html\n",
    "#\n",
    "# and clicking on the \"API Token\" link under \"Personal Account\". You will be asked\n",
    "# to log into the application before you can view your API Token.\n",
    "#\n",
    "# Usage: python3 python-camels-20240614T0658.py\n",
    "# Version: 1.0.1\n",
    "#\n",
    "# Dataset\n",
    "# camels\n",
    "# fbc54ccc-5184-4f54-b306-f58112a34700\n",
    "# https://gdex.ucar.edu/dataset/camels.html\n",
    "# https://gdex.ucar.edu/dataset/id/fbc54ccc-5184-4f54-b306-f58112a34700.html\n",
    "#\n",
    "# Dataset Version\n",
    "# 1.2\n",
    "# 0925542f-ede4-4f25-9424-3fce02d43240\n",
    "# https://gdex.ucar.edu/dataset/camels/version/1.2.html\n",
    "# https://gdex.ucar.edu/dataset/version/id/0925542f-ede4-4f25-9424-3fce02d43240.html\n",
    "#\n",
    "################################################################\n",
    "\n",
    "print('Please email feedback to gdex@ucar.edu.\\n')\n",
    "\n",
    "data = [\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_name.txt','filename':'camels_name.txt','bytes':'30417','md5Checksum':'c96491b32c4df55a31bead7ceca7d64b'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_attributes_v2.0.xlsx','filename':'camels_attributes_v2.0.xlsx','bytes':'16278','md5Checksum':'714c68bd5bb3314ca39b14f9467bd609'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_attributes_v2.0.pdf','filename':'camels_attributes_v2.0.pdf','bytes':'91532','md5Checksum':'77a6c084c798a31fbd05594ee58a90c7'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_metForcing_obsFlow.zip','filename':'basin_timeseries_v1p2_metForcing_obsFlow.zip','bytes':'3406626583','md5Checksum':'8e9a466710e8270b58f01d332a87184f'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_topo.txt','filename':'camels_topo.txt','bytes':'38677','md5Checksum':'0f6267838c40b1507b64582433bc0b8e'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/readme.txt','filename':'readme.txt','bytes':'1704','md5Checksum':'b37d64950e9d4c5c10a8b4ef82bc6219'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_set_full_res.zip','filename':'basin_set_full_res.zip','bytes':'45179559','md5Checksum':'958fe520f6c4062dbddbbb67cfc28985'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_vege.txt','filename':'camels_vege.txt','bytes':'107970','md5Checksum':'f40e843defc1e654a800be9fe5fd5090'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_modelOutput_maurer.zip','filename':'basin_timeseries_v1p2_modelOutput_maurer.zip','bytes':'3138552670','md5Checksum':'55fb2882136bc2f1e2ce35227396cc1f'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_modelOutput_nldas.zip','filename':'basin_timeseries_v1p2_modelOutput_nldas.zip','bytes':'3766449871','md5Checksum':'32c9973fb13d17a5268ed4affd95fb9a'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_geol.txt','filename':'camels_geol.txt','bytes':'71583','md5Checksum':'f5ce5de53eb1ea2532cda7e3b4813993'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_clim.txt','filename':'camels_clim.txt','bytes':'100673','md5Checksum':'67f22592f3fb72c57df81358ce68458b'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/basin_timeseries_v1p2_modelOutput_daymet.zip','filename':'basin_timeseries_v1p2_modelOutput_daymet.zip','bytes':'4207763546','md5Checksum':'f2af624b6277b75b3e410d6a0365591a'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_hydro.txt','filename':'camels_hydro.txt','bytes':'122799','md5Checksum':'55ebdeb36c42ee7acdb998229c3edb3a'},\n",
    "     {'url':'https://gdex.ucar.edu/api/v1/dataset/camels/file/camels_soil.txt','filename':'camels_soil.txt','bytes':'109125','md5Checksum':'8edb46a363a20b466a4b7105ba633767'},]\n",
    "\n",
    "def main(data):\n",
    "\n",
    "    args = processArguments()\n",
    "\n",
    "    for d in data:\n",
    "        executeDownload(Download(args, d))\n",
    "\n",
    "def processArguments():\n",
    "\n",
    "    args = {}\n",
    "    args.update({'apiToken': None})\n",
    "    args.update({'userAgent': 'python/{}/gateway/{}'.format(python_version(), '4.4.10-20240516-151433')})\n",
    "    args.update({'attemptMax': 10})\n",
    "    args.update({'initialSleepSeconds': 10})\n",
    "    args.update({'sleepMultiplier': 3})\n",
    "    args.update({'sleepMaxSeconds': 900})\n",
    "    args.update({'insecure': False})\n",
    "\n",
    "    if '-k' in sys.argv or '--insecure' in sys.argv:\n",
    "        args.update({'insecure': True})\n",
    "\n",
    "    if '-h' in sys.argv or '--help' in sys.argv:\n",
    "        print('Usage: {} [options...]'.format(sys.argv[0]))\n",
    "        print(' -h, --help        Show usage')\n",
    "        print(' -k, --insecure    Allow insecure server connections (no certificate check) when using SSL')\n",
    "        exit(0)\n",
    "\n",
    "    return args\n",
    "\n",
    "def executeDownload(download):\n",
    "\n",
    "    if not os.path.isfile(download.filename):\n",
    "        attemptAndValidateDownload(download)\n",
    "        moveDownload(download)\n",
    "    else:\n",
    "        download.success = True\n",
    "        download.valid = True\n",
    "\n",
    "    reportDownload(download)\n",
    "\n",
    "def moveDownload(download):\n",
    "\n",
    "    if download.success and (download.valid or download.vwarning):\n",
    "        os.rename(download.filenamePart, download.filename)\n",
    "\n",
    "def reportDownload(download):\n",
    "\n",
    "    if download.success and download.valid:\n",
    "        print('{} download successful'.format(download.filename))\n",
    "\n",
    "    if download.success and not download.valid and download.vwarning:\n",
    "        print('{} download validation warning: {}'.format(download.filename, download.vwarning))\n",
    "\n",
    "    if download.success and not download.valid and download.verror:\n",
    "        print('{} download validation error: {}'.format(download.filename, download.verror))\n",
    "\n",
    "    if not download.success and download.error:\n",
    "        print('{} download failed: {}'.format(download.filename, download.error))\n",
    "\n",
    "def attemptAndValidateDownload(download):\n",
    "\n",
    "    while download.attempt:\n",
    "        downloadFile(download)\n",
    "\n",
    "    if download.success:\n",
    "        validateFile(download)\n",
    "\n",
    "def downloadFile(download):\n",
    "\n",
    "    try :\n",
    "        startOrResumeDownload(download)\n",
    "    except HTTPError as error:\n",
    "        handleHTTPErrorAttempt(download, error)\n",
    "    except URLError as error:\n",
    "        handleRecoverableAttempt(download, error)\n",
    "    except TimeoutError as error:\n",
    "        handleRecoverableAttempt(download, error)\n",
    "    except Exception as error:\n",
    "        handleIrrecoverableAttempt(download, error)\n",
    "    else:\n",
    "        handleSuccessfulAttempt(download)\n",
    "\n",
    "def startOrResumeDownload(download):\n",
    "\n",
    "    startAnimateDownload('{} downloading:'.format(download.filename))\n",
    "\n",
    "    if os.path.isfile(download.filenamePart):\n",
    "        resumeDownloadFile(download)\n",
    "    else:\n",
    "        startDownloadFile(download)\n",
    "\n",
    "def startAnimateDownload(message):\n",
    "    global animateMessage\n",
    "    global animateOn\n",
    "\n",
    "    animateMessage = message\n",
    "    animateOn = True\n",
    "\n",
    "    # making the animation run as a daemon thread allows it to\n",
    "    # exit when the parent (main) is terminated or killed\n",
    "    t = threading.Thread(daemon=True, target=animateDownload)\n",
    "    t.start()\n",
    "\n",
    "def stopAnimateDownload(outcome):\n",
    "    global animateOutcome\n",
    "    global animateOn\n",
    "\n",
    "    animateOutcome = outcome\n",
    "    animateOn = False\n",
    "\n",
    "    # wait for animation child process to stop before any parent print\n",
    "    time.sleep(0.3)\n",
    "\n",
    "def animateDownload():\n",
    "    global animateMessage\n",
    "    global animateOutcome\n",
    "    global animateOn\n",
    "\n",
    "    for d in itertools.cycle(['.  ', '.. ', '...', '   ']):\n",
    "\n",
    "        if not animateOn:\n",
    "            print('\\r{} {}'.format(animateMessage, animateOutcome), flush=True)\n",
    "            break\n",
    "\n",
    "        print('\\r{} {}'.format(animateMessage, d), end='', flush=True)\n",
    "        time.sleep(0.2)\n",
    "\n",
    "def resumeDownloadFile(download):\n",
    "\n",
    "    request = createRequest(download, createResumeHeaders(download))\n",
    "    readFile(download, request)\n",
    "\n",
    "def startDownloadFile(download):\n",
    "\n",
    "    request = createRequest(download, createStartHeaders(download))\n",
    "    readFile(download, request)\n",
    "\n",
    "def createResumeHeaders(download):\n",
    "\n",
    "    headers = createStartHeaders(download)\n",
    "    headers.update(createRangeHeader(download))\n",
    "\n",
    "    return headers\n",
    "\n",
    "def createRequest(download, headers):\n",
    "\n",
    "    request = urllib.request.Request(download.url, headers=headers)\n",
    "\n",
    "    return request\n",
    "\n",
    "def createStartHeaders(download):\n",
    "\n",
    "    headers = {}\n",
    "    headers.update(createUserAgentHeader(download))\n",
    "\n",
    "    if download.apiToken:\n",
    "        headers.update(createAuthorizationHeader(download))\n",
    "\n",
    "    return headers\n",
    "\n",
    "def createUserAgentHeader(download):\n",
    "\n",
    "    return {'User-agent': download.userAgent}\n",
    "\n",
    "def createAuthorizationHeader(download):\n",
    "\n",
    "    return {'Authorization': 'api-token {}'.format(download.apiToken)}\n",
    "\n",
    "def createRangeHeader(download):\n",
    "\n",
    "    start = os.path.getsize(download.filenamePart)\n",
    "    header = {'Range': 'bytes={}-'.format(start)}\n",
    "\n",
    "    return header\n",
    "\n",
    "def readFile(download, request):\n",
    "\n",
    "    context = createSSLContext(download)\n",
    "\n",
    "    with urllib.request.urlopen(request, context=context) as response, open(download.filenamePart, 'ab') as fh:\n",
    "        collectResponseHeaders(download, response)\n",
    "        shutil.copyfileobj(response, fh)\n",
    "\n",
    "def createSSLContext(download):\n",
    "\n",
    "    # See:\n",
    "    #      https://docs.python.org/3/library/urllib.request.html\n",
    "    #      https://docs.python.org/3/library/http.client.html#http.client.HTTPSConnection\n",
    "    #      https://docs.python.org/3/library/ssl.html#ssl.SSLContext\n",
    "    #\n",
    "    # Excerpts:\n",
    "    #      If context is specified it must be a ssl.SSLContext instance...\n",
    "    #      http.client.HTTPSConnection performs all the necessary certificate and hostname checks by default.\n",
    "\n",
    "    if download.insecure:\n",
    "        return ssl._create_unverified_context()\n",
    "\n",
    "    return None\n",
    "\n",
    "def collectResponseHeaders(download, response):\n",
    "\n",
    "    download.responseHeaders = response.info()\n",
    "    if download.responseHeaders.get('ETag'):\n",
    "        download.etag = download.responseHeaders.get('ETag').strip('\"')\n",
    "\n",
    "def handleHTTPErrorAttempt(download, httpError):\n",
    "\n",
    "    if httpError.code == 416: # 416 is Range Not Satisfiable\n",
    "        # likely the file completely downloaded and validation was interrupted,\n",
    "        # therefore calling it successfully downloaded and allowing validation\n",
    "        # to say otherwise\n",
    "        handleSuccessfulAttempt(download)\n",
    "    else:\n",
    "        handleRecoverableAttempt(download, httpError)\n",
    "\n",
    "def handleRecoverableAttempt(download, error):\n",
    "\n",
    "    stopAnimateDownload('error')\n",
    "\n",
    "    print('failure on attempt {} downloading {}: {}'.format(download.attemptNumber, download.filename, error))\n",
    "\n",
    "    if download.attemptNumber < download.attemptMax:\n",
    "        sleepBeforeNextAttempt(download)\n",
    "        download.attemptNumber += 1\n",
    "    else:\n",
    "        download.attempt = False\n",
    "        download.error = error\n",
    "\n",
    "def sleepBeforeNextAttempt(download):\n",
    "\n",
    "    sleepSeconds = download.initialSleepSeconds * (download.sleepMultiplier ** (download.attemptNumber - 1))\n",
    "\n",
    "    if sleepSeconds > download.sleepMaxSeconds:\n",
    "        sleepSeconds = download.sleepMaxSeconds\n",
    "\n",
    "    print('waiting {} seconds before next attempt to download {}'.format(sleepSeconds, download.filename))\n",
    "    time.sleep(sleepSeconds)\n",
    "\n",
    "def handleIrrecoverableAttempt(download, error):\n",
    "\n",
    "    stopAnimateDownload('error')\n",
    "\n",
    "    download.attempt = False\n",
    "    download.error = error\n",
    "\n",
    "def handleSuccessfulAttempt(download):\n",
    "\n",
    "    stopAnimateDownload('done')\n",
    "\n",
    "    download.attempt = False\n",
    "    download.success = True\n",
    "\n",
    "def validateFile(download):\n",
    "\n",
    "    try:\n",
    "        validateAllSteps(download)\n",
    "    except InvalidDownload as error:\n",
    "        download.valid = False\n",
    "        download.vwarning = str(error)\n",
    "    except Exception as error:\n",
    "        download.valid = False\n",
    "        download.verror = error\n",
    "    else:\n",
    "        download.valid = True\n",
    "\n",
    "def validateAllSteps(download):\n",
    "\n",
    "    verrorData = validatePerData(download)\n",
    "    verrorEtag = validatePerEtag(download)\n",
    "    verrorStale = validateStaleness(download)\n",
    "\n",
    "    if verrorData and verrorEtag:\n",
    "        raise verrorData\n",
    "\n",
    "    if verrorStale:\n",
    "        raise verrorStale\n",
    "\n",
    "def validatePerData(download):\n",
    "\n",
    "    try:\n",
    "        validateBytes(download)\n",
    "        validateChecksum(download)\n",
    "    except InvalidDownload as error:\n",
    "        return error\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def validateBytes(download):\n",
    "\n",
    "    size = os.path.getsize(download.filenamePart)\n",
    "    if not download.bytes == size:\n",
    "        raise InvalidSizeValue(download, size)\n",
    "\n",
    "def validateChecksum(download):\n",
    "\n",
    "    if download.md5Checksum:\n",
    "        md5Checksum = readMd5Checksum(download)\n",
    "        if not download.md5Checksum == md5Checksum:\n",
    "            raise InvalidChecksumValue(download, md5Checksum)\n",
    "    else:\n",
    "        raise UnableToPerformChecksum(download)\n",
    "\n",
    "def readMd5Checksum(download):\n",
    "\n",
    "    hash_md5 = hashlib.md5()\n",
    "\n",
    "    with open(download.filenamePart, 'rb') as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b''):\n",
    "            hash_md5.update(chunk)\n",
    "\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def validatePerEtag(download):\n",
    "\n",
    "    try:\n",
    "        validateChecksumEtag(download)\n",
    "    except InvalidDownload as error:\n",
    "        return error\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def validateChecksumEtag(download):\n",
    "\n",
    "    if isEtagChecksum(download):\n",
    "        md5Checksum = readMd5Checksum(download)\n",
    "        if not download.etag == md5Checksum:\n",
    "            raise InvalidChecksumValuePerEtag(download, md5Checksum)\n",
    "    else:\n",
    "        raise UnableToPerformChecksum(download)\n",
    "\n",
    "def isEtagChecksum(download):\n",
    "\n",
    "    return download.etag and re.fullmatch(r'[a-z0-9]+', download.etag)\n",
    "\n",
    "def validateStaleness(download):\n",
    "\n",
    "    try:\n",
    "        validateStaleChecksum(download)\n",
    "    except InvalidDownload as error:\n",
    "        return error\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def validateStaleChecksum(download):\n",
    "\n",
    "    if isEtagChecksum(download):\n",
    "        if not download.md5Checksum or download.md5Checksum != download.etag:\n",
    "            raise StaleChecksumValue(download)\n",
    "\n",
    "class InvalidDownload(Exception):\n",
    "\n",
    "    pass\n",
    "\n",
    "class InvalidSizeValue(InvalidDownload):\n",
    "\n",
    "    def __init__(self, download, actual):\n",
    "        super().__init__('invalid byte size: downloaded file is {} bytes but should be {}'.format(actual, download.bytes))\n",
    "\n",
    "class InvalidChecksumValue(InvalidDownload):\n",
    "\n",
    "    def __init__(self, download, actual):\n",
    "        super().__init__('invalid checksum: downloaded file is {} but should be {}'.format(actual, download.md5Checksum))\n",
    "\n",
    "class InvalidChecksumValuePerEtag(InvalidDownload):\n",
    "\n",
    "    def __init__(self, download, actual):\n",
    "        super().__init__('invalid checksum: downloaded file is {} but should be {} according to server'.format(actual, download.etag))\n",
    "\n",
    "class UnableToPerformChecksum(InvalidDownload):\n",
    "\n",
    "    def __init__(self, download):\n",
    "        super().__init__('cannot verify checksum')\n",
    "\n",
    "class StaleChecksumValue(InvalidDownload):\n",
    "\n",
    "    def __init__(self, download):\n",
    "        super().__init__('checksum value has changed')\n",
    "\n",
    "class Download():\n",
    "\n",
    "    def __init__(self, args, datum):\n",
    "\n",
    "        self.apiToken = args.get('apiToken')\n",
    "        self.userAgent = args.get('userAgent')\n",
    "        self.attemptMax = args.get('attemptMax')\n",
    "        self.initialSleepSeconds = args.get('initialSleepSeconds')\n",
    "        self.sleepMultiplier = args.get('sleepMultiplier')\n",
    "        self.sleepMaxSeconds = args.get('sleepMaxSeconds')\n",
    "        self.insecure = args.get('insecure')\n",
    "\n",
    "        self.url = datum.get('url')\n",
    "        self.filename = datum.get('filename')\n",
    "        self.bytes = int(datum.get('bytes'))\n",
    "        self.md5Checksum = datum.get('md5Checksum')\n",
    "\n",
    "        self.filenamePart = self.filename + '.part'\n",
    "        self.success = False\n",
    "        self.attempt = True\n",
    "        self.attemptNumber = 1\n",
    "        self.responseHeaders = {}\n",
    "        self.etag = None\n",
    "        self.error = None\n",
    "        self.valid = False\n",
    "        self.vwarning = None\n",
    "        self.verror = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'url: {self.url}, filename: {self.filename}, bytes: {self.bytes}, md5Checksum: {self.md5Checksum}'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hydra_Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
