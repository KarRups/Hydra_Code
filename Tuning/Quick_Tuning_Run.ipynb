{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/Hydra_Work/Competition_Functions') \n",
    "from Processing_Functions import process_forecast_date, process_seasonal_forecasts\n",
    "\n",
    "import ML_Functions\n",
    "from ML_Functions import Hydra_LSTM_Block, initialize_models_optimizers, PinballLoss, SumPinballLoss, EarlyStopper, Model_Run, No_Body_Model_Run\n",
    "from Data_Transforming import read_nested_csvs, generate_daily_flow, use_USGS_flow_data, USGS_to_daily_df_yearly\n",
    "\n",
    "\n",
    "sys.path.append('/data/Hydra_Work/Pipeline_Functions')\n",
    "from Folder_Work import filter_rows_by_year, csv_dictionary, add_day_of_year_column\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the prep\n",
    "monthly_basins = ['animas_r_at_durango', 'boise_r_nr_boise', 'boysen_reservoir_inflow', 'colville_r_at_kettle_falls', 'detroit_lake_inflow', 'dillon_reservoir_inflow',\n",
    "    'fontenelle_reservoir_inflow', 'green_r_bl_howard_a_hanson_dam', 'hungry_horse_reservoir_inflow', 'libby_reservoir_inflow',\n",
    "    'missouri_r_at_toston','owyhee_r_bl_owyhee_dam', 'pecos_r_nr_pecos', 'pueblo_reservoir_inflow',\n",
    "    'ruedi_reservoir_inflow', 'skagit_ross_reservoir', 'snake_r_nr_heise', 'stehekin_r_at_stehekin', 'sweetwater_r_nr_alcova',\n",
    "    'taylor_park_reservoir_inflow', 'virgin_r_at_virtin', 'weber_r_nr_oakley', 'yampa_r_nr_maybell',\n",
    "]\n",
    "\n",
    "\n",
    "USGS_basins = ['animas_r_at_durango', 'boise_r_nr_boise', 'boysen_reservoir_inflow', 'colville_r_at_kettle_falls', 'detroit_lake_inflow', 'dillon_reservoir_inflow',   \n",
    "    'green_r_bl_howard_a_hanson_dam', 'hungry_horse_reservoir_inflow', 'libby_reservoir_inflow', 'merced_river_yosemite_at_pohono_bridge', 'missouri_r_at_toston',\n",
    "    'owyhee_r_bl_owyhee_dam', 'pecos_r_nr_pecos', 'pueblo_reservoir_inflow',    'san_joaquin_river_millerton_reservoir', 'snake_r_nr_heise', 'stehekin_r_at_stehekin',\n",
    "    'sweetwater_r_nr_alcova', 'taylor_park_reservoir_inflow', 'virgin_r_at_virtin', 'weber_r_nr_oakley', 'yampa_r_nr_maybell',\n",
    "]\n",
    "\n",
    "basins = list(set(monthly_basins + USGS_basins))\n",
    "\n",
    "\n",
    "selected_years = range(2000,2024,2)\n",
    "\n",
    "era5_folder = '/data/Hydra_Work/Rodeo_Data/era5'\n",
    "era5 = csv_dictionary(era5_folder, basins, years=selected_years)\n",
    "era5 = add_day_of_year_column(era5)\n",
    "\n",
    "flow_folder = '/data/Hydra_Work/Rodeo_Data/train_monthly_naturalized_flow'\n",
    "flow = csv_dictionary(flow_folder, monthly_basins)\n",
    "flow = filter_rows_by_year(flow, 1998)\n",
    "\n",
    "climatology_file_path = '/data/Hydra_Work/Rodeo_Data/climate_indices.csv'\n",
    "climate_indices = pd.read_csv(climatology_file_path)\n",
    "climate_indices['date'] = pd.to_datetime(climate_indices['date'])\n",
    "climate_indices.set_index('date', inplace = True)\n",
    "climate_indices.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "climate_indices = climate_indices[~climate_indices.index.duplicated(keep='first')]\n",
    "\n",
    "root_folder = '/data/Hydra_Work/Rodeo_Data/seasonal_forecasts'\n",
    "seasonal_forecasts = read_nested_csvs(root_folder)\n",
    "\n",
    "USGS_flow_folder = '/data/Hydra_Work/Rodeo_Data/USGS_streamflows'\n",
    "USGS_flow = csv_dictionary(USGS_flow_folder, USGS_basins)\n",
    "\n",
    "Static_variables = pd.read_csv('/data/Hydra_Work/Rodeo_Data/static_indices.csv', index_col= 'site_id')\n",
    "\n",
    "# Convert monthly flow values to daily flow estimates\n",
    "daily_flow = {}\n",
    "\n",
    "# Iterate through the dictionary and apply generate_daily_flow to each DataFrame\n",
    "for key, df in flow.items():\n",
    "    daily_flow[key] = generate_daily_flow(df, persistence_factor=0.7)\n",
    "\n",
    "# Replacing monhtly data for normalised USGS when available\n",
    "daily_flow = use_USGS_flow_data(daily_flow, USGS_flow)\n",
    "\n",
    "# Introducing the data from San_jaoqin and Merced, normalised by the yearly flow given\n",
    "path = '/data/Hydra_Work/Rodeo_Data/USGS_streamflows/san_joaquin_river_millerton_reservoir.csv'\n",
    "name = 'san_joaquin_river_millerton_reservoir'\n",
    "normalising_path = '/data/Hydra_Work/Rodeo_Data/train_yearly/san_joaquin_river_millerton_reservoir.csv'\n",
    "\n",
    "USGS_to_daily_df_yearly(daily_flow, path, name, normalising_path)\n",
    "\n",
    "path = '/data/Hydra_Work/Rodeo_Data/USGS_streamflows/merced_river_yosemite_at_pohono_bridge.csv'\n",
    "name = 'merced_river_yosemite_at_pohono_bridge'\n",
    "normalising_path = '/data/Hydra_Work/Rodeo_Data/train_yearly/merced_river_yosemite_at_pohono_bridge.csv'\n",
    "\n",
    "USGS_to_daily_df_yearly(daily_flow, path, name, normalising_path)\n",
    "\n",
    "path = '/data/Hydra_Work/Rodeo_Data/USGS_streamflows/detroit_lake_inflow.csv'\n",
    "name = 'detroit_lake_inflow'\n",
    "normalising_path = '/data/Hydra_Work/Rodeo_Data/train_yearly/detroit_lake_inflow.csv'\n",
    "\n",
    "USGS_to_daily_df_yearly(daily_flow, path, name, normalising_path)\n",
    "\n",
    "climate_scaler_filename = '/data/Hydra_Work/Rodeo_Data/scalers/climate_normalization_scaler.save'\n",
    "climate_scaler = joblib.load(climate_scaler_filename) \n",
    "climate_indices = pd.DataFrame(climate_scaler.transform(climate_indices), columns=climate_indices.columns, index=climate_indices.index)\n",
    "\n",
    "era5_scaler_filename = '/data/Hydra_Work/Rodeo_Data/scalers/era5_scaler.save'\n",
    "era5_scaler = joblib.load(era5_scaler_filename) \n",
    "era5 = {key: pd.DataFrame(era5_scaler.transform(df), columns=df.columns, index=df.index) for key, df in era5.items()}\n",
    "\n",
    "for basin, df in daily_flow.items(): \n",
    "    flow_scaler_filename = f'/data/Hydra_Work/Rodeo_Data/scalers/flows/{basin}_flow_scaler.save'\n",
    "    flow_scaler = joblib.load(flow_scaler_filename) \n",
    "    daily_flow[basin] = pd.DataFrame(flow_scaler.transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "seasonal_scaler_filename = \"/data/Hydra_Work/Rodeo_Data/scalers/seasonal_scaler.save\"\n",
    "seasonal_scaler = joblib.load(seasonal_scaler_filename)\n",
    "seasonal_forecasts = {key: pd.DataFrame(seasonal_scaler.transform(df), columns=df.columns, index=df.index ) for key, df in seasonal_forecasts.items()}\n",
    "\n",
    "static_scaler_filename = '/data/Hydra_Work/Rodeo_Data/scalers/static_scaler.save'\n",
    "static_scaler = joblib.load(static_scaler_filename) \n",
    "Static_variables = pd.DataFrame(static_scaler.transform(Static_variables), columns=Static_variables.columns, index=Static_variables.index)\n",
    "\n",
    "climatological_flows = {}\n",
    "\n",
    "for basin, df in daily_flow.items():\n",
    "    # Extract day of year and flow values\n",
    "    df['day_of_year'] = df.index.dayofyear\n",
    "\n",
    "    grouped = df.groupby('day_of_year')['daily_flow'].quantile([0.1, 0.5, 0.9]).unstack(level=1)\n",
    "\n",
    "    climatological_flows[basin] = pd.DataFrame({\n",
    "        'day_of_year': grouped.index,\n",
    "        '10th_percentile_flow': grouped[0.1],\n",
    "        '50th_percentile_flow': grouped[0.5],\n",
    "        '90th_percentile_flow': grouped[0.9]\n",
    "    })\n",
    "    \n",
    "    climatological_flows[basin].set_index('day_of_year', inplace=True)\n",
    "\n",
    "    # Drop the temporary 'day_of_year' column from the original dataframe\n",
    "    df.drop(columns='day_of_year', inplace=True)\n",
    "\n",
    "criterion = SumPinballLoss(quantiles = [0.1, 0.5, 0.9])\n",
    "\n",
    "basin = 'animas_r_at_durango' \n",
    "All_Dates = daily_flow[basin].index[\n",
    "    ((daily_flow[basin].index.month < 6) | ((daily_flow[basin].index.month == 6) & (daily_flow[basin].index.day < 25))) &\n",
    "    ((daily_flow[basin].index.year % 2 == 0) | ((daily_flow[basin].index.month > 10) | ((daily_flow[basin].index.month == 10) & (daily_flow[basin].index.day >= 1))))\n",
    "]\n",
    "All_Dates = All_Dates[All_Dates.year > 1998]\n",
    "\n",
    "\n",
    "# Validation Year\n",
    "Val_Dates = All_Dates[All_Dates.year == 2022]\n",
    "All_Dates = All_Dates[All_Dates.year < 2022]\n",
    "\n",
    "\n",
    "basin_to_remove = 'sweetwater_r_nr_alcova'\n",
    "\n",
    "if basin_to_remove in basins:\n",
    "    basins.remove(basin_to_remove)\n",
    "\n",
    "\n",
    "seed = 42 ; torch.manual_seed(seed) ; random.seed(seed) ; np.random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "days  = 90\n",
    "hidden_variables_size = 17\n",
    "\n",
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 5*2\n",
    "\n",
    "head_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "head_output_size = 3\n",
    "\n",
    "# Be careful of this: Trying to unpickle estimator MinMaxScaler from version 1.3.0 when using version 1.4.1.post1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning individual basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 5*2\n",
    "\n",
    "input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models(hidden_size, num_layers, dropout, bidirectional, learning_rate, copies = 3, output_size = 3, input_size = input_size, days = 90, hidden_variables_size = hidden_variables_size, device = device):\n",
    "    models = {}\n",
    "    params_to_optimize = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    for copy in range(copies):\n",
    "        models[copy] = Hydra_LSTM_Block(input_size, hidden_size, num_layers, output_size, H0_sequences_size=days * hidden_variables_size, dropout= dropout, bidirectional= bidirectional)\n",
    "        models[copy].to(device)\n",
    "        params_to_optimize[copy] = list(models[copy].parameters())\n",
    "\n",
    "        optimizers[copy] = torch.optim.Adam(params_to_optimize[copy], lr= learning_rate, weight_decay = 1e-3)\n",
    "        schedulers[copy] = lr_scheduler.CosineAnnealingLR(optimizers[copy], T_max=1e4)\n",
    "\n",
    "    return models, params_to_optimize, optimizers, schedulers\n",
    "\n",
    "def update_final_parameters(Final_Parameters, basin, min_val_loss_parameters, min_val_loss):\n",
    "    Final_Parameters['basin'].append(basin)\n",
    "    Final_Parameters['hidden_size'].append(min_val_loss_parameters[0])\n",
    "    Final_Parameters['num_layers'].append(min_val_loss_parameters[1])\n",
    "    Final_Parameters['dropout'].append(min_val_loss_parameters[2])\n",
    "    Final_Parameters['bidirectional'].append(min_val_loss_parameters[3])\n",
    "    Final_Parameters['learning_rate'].append(min_val_loss_parameters[4])\n",
    "    Final_Parameters['val_loss'].append(min_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "# Fixed parameters\n",
    "total_epochs = 30\n",
    "n_epochs = 1  # Epochs between tests\n",
    "group_lengths = np.arange(180)\n",
    "batch_size = 1\n",
    "copies = 3\n",
    "\n",
    "# parameters to tune\n",
    "hidden_sizes = [16, 64, 128]\n",
    "num_layers =  [1,3]\n",
    "dropout = [0.1, 0.4]\n",
    "bidirectional = [False, True]\n",
    "learning_rate = [1e-3, 1e-5]\n",
    "\n",
    "# Set up configuration space\n",
    "config_space = {\n",
    "    \"hidden_size\": tune.grid_search(hidden_sizes),\n",
    "    \"num_layers\": tune.grid_search(num_layers),\n",
    "    \"dropout\": tune.grid_search(dropout),\n",
    "    \"bidirectional\": tune.grid_search(bidirectional),\n",
    "    \"learning_rate\": tune.grid_search(learning_rate)\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    Val_Dates = ray.get(Val_Dates_id)  \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "\n",
    "\n",
    "    copies = 3\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "   \n",
    "    models, params_to_optimize, optimizers, schedulers = define_models(\n",
    "    config[\"hidden_size\"], config[\"num_layers\"], config[\"dropout\"],\n",
    "    config[\"bidirectional\"], config[\"learning_rate\"], copies=copies, device = device)\n",
    "\n",
    "\n",
    "    losses, val_losses = [], []\n",
    "    early_stopper = EarlyStopper(patience=4, min_delta=0.01)\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        train_losses = {}\n",
    "        epoch_val_losses = {}\n",
    "\n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_losses[copy] = No_Body_Model_Run(All_Dates, [basin], models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper=early_stopper, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, specialised=False)\n",
    "            epoch_val_losses[copy] = No_Body_Model_Run(Val_Dates, [basin], models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper=early_stopper, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, specialised=False)\n",
    "\n",
    "        loss = np.mean(list(train_losses.values()))\n",
    "        val_loss = np.mean(list(epoch_val_losses.values())).mean()\n",
    "\n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            break\n",
    "    return val_loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)  \n",
    "Val_Dates_id = ray.put(Val_Dates)  \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(Static_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "    print('Device available is', device)\n",
    "    \n",
    "\n",
    "    score = train_model(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "basin = 'stehekin_r_at_stehekin'\n",
    "\n",
    "\n",
    "# Can use fractions of GPU\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space=config_space) \n",
    "\n",
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"val_loss\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading models\n",
    "Tuned_Models = {}\n",
    "for basin in basins:\n",
    "    Tuned_Models[basin] = torch.load(f'/data/Hydra_Work/Post_Rodeo_Work/Tuned_Single_Models/basin.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 5*2\n",
    "\n",
    "input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_final_parameters_general(Final_Parameters, min_val_loss_parameters, min_val_loss):\n",
    "    Final_Parameters['hidden_size'].append(min_val_loss_parameters[0])\n",
    "    Final_Parameters['num_layers'].append(min_val_loss_parameters[1])\n",
    "    Final_Parameters['dropout'].append(min_val_loss_parameters[2])\n",
    "    Final_Parameters['bidirectional'].append(min_val_loss_parameters[3])\n",
    "    Final_Parameters['learning_rate'].append(min_val_loss_parameters[4])\n",
    "    Final_Parameters['val_loss'].append(min_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 20\n",
    "n_epochs = 1 # Epochs between tests\n",
    "group_lengths = np.arange(180)\n",
    "batch_size = 1\n",
    "copies = 2\n",
    "\n",
    "# parameters to tune\n",
    "# I tuned to 128,2,0.1,False,1e-3 \n",
    "hidden_sizes = [64, 128, 256]\n",
    "num_layers = [1,3]\n",
    "dropout = [0.1, 0.4]\n",
    "bidirectional =  [False, True]\n",
    "learning_rate = [1e-2, 1e-3, 1e-5]\n",
    "\n",
    "config_space = {\n",
    "    \"hidden_size\": tune.grid_search(hidden_sizes),\n",
    "    \"num_layers\": tune.grid_search(num_layers),\n",
    "    \"dropout\": tune.grid_search(dropout),\n",
    "    \"bidirectional\": tune.grid_search(bidirectional),\n",
    "    \"learning_rate\": tune.grid_search(learning_rate)\n",
    "}\n",
    "\n",
    "\n",
    "# Places to save info\n",
    "model_dir = '/data/Hydra_Work/Post_Rodeo_Work/Tuned_General_Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_general(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    Val_Dates = ray.get(Val_Dates_id)  \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "    copies = 3\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "   \n",
    "    models, params_to_optimize, optimizers, schedulers = define_models(\n",
    "    config[\"hidden_size\"], config[\"num_layers\"], config[\"dropout\"],\n",
    "    config[\"bidirectional\"], config[\"learning_rate\"], copies=copies, device = device)\n",
    "\n",
    "\n",
    "    losses, val_losses = [], []\n",
    "    early_stopper = EarlyStopper(patience=10, min_delta=0.01)\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        train_losses = {}\n",
    "        epoch_val_losses = {}\n",
    "\n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_losses[copy] = No_Body_Model_Run(All_Dates, basins, models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper=early_stopper, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, specialised=False)\n",
    "            epoch_val_losses[copy] = No_Body_Model_Run(Val_Dates, basins, models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper=early_stopper, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, specialised=False)\n",
    "\n",
    "        loss = np.mean(list(train_losses.values()))\n",
    "        val_loss = np.mean(list(epoch_val_losses.values())).mean()\n",
    "\n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            break\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-19 10:34:31</td></tr>\n",
       "<tr><td>Running for: </td><td>00:09:09.05        </td></tr>\n",
       "<tr><td>Memory:      </td><td>69.4/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                  </th><th>bidirectional  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_fddfe_00000</td><td>RUNNING </td><td>136.156.133.98:313403</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         323.604</td><td style=\"text-align: right;\">   22.2622</td></tr>\n",
       "<tr><td>objective_fddfe_00001</td><td>RUNNING </td><td>136.156.133.98:313404</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         326.332</td><td style=\"text-align: right;\">   22.7039</td></tr>\n",
       "<tr><td>objective_fddfe_00002</td><td>RUNNING </td><td>136.156.133.98:313405</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         316.371</td><td style=\"text-align: right;\">   20.7989</td></tr>\n",
       "<tr><td>objective_fddfe_00003</td><td>RUNNING </td><td>136.156.133.98:313406</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         346.225</td><td style=\"text-align: right;\">   21.3366</td></tr>\n",
       "<tr><td>objective_fddfe_00004</td><td>RUNNING </td><td>136.156.133.98:313416</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         315.955</td><td style=\"text-align: right;\">   21.2442</td></tr>\n",
       "<tr><td>objective_fddfe_00005</td><td>RUNNING </td><td>136.156.133.98:313437</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         330.584</td><td style=\"text-align: right;\">   21.1446</td></tr>\n",
       "<tr><td>objective_fddfe_00006</td><td>RUNNING </td><td>136.156.133.98:313446</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         315.921</td><td style=\"text-align: right;\">   21.9285</td></tr>\n",
       "<tr><td>objective_fddfe_00007</td><td>RUNNING </td><td>136.156.133.98:313464</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         325.054</td><td style=\"text-align: right;\">   22.708 </td></tr>\n",
       "<tr><td>objective_fddfe_00008</td><td>RUNNING </td><td>136.156.133.98:313488</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         367.611</td><td style=\"text-align: right;\">   22.6019</td></tr>\n",
       "<tr><td>objective_fddfe_00009</td><td>RUNNING </td><td>136.156.133.98:313531</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         349.316</td><td style=\"text-align: right;\">   21.0491</td></tr>\n",
       "<tr><td>objective_fddfe_00010</td><td>RUNNING </td><td>136.156.133.98:313532</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         401.172</td><td style=\"text-align: right;\">   21.096 </td></tr>\n",
       "<tr><td>objective_fddfe_00011</td><td>RUNNING </td><td>136.156.133.98:313533</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.01 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         355.452</td><td style=\"text-align: right;\">   22.7099</td></tr>\n",
       "<tr><td>objective_fddfe_00012</td><td>RUNNING </td><td>136.156.133.98:313538</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         318.519</td><td style=\"text-align: right;\">   21.054 </td></tr>\n",
       "<tr><td>objective_fddfe_00013</td><td>RUNNING </td><td>136.156.133.98:313545</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         314.112</td><td style=\"text-align: right;\">   22.8203</td></tr>\n",
       "<tr><td>objective_fddfe_00014</td><td>RUNNING </td><td>136.156.133.98:313550</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         332.023</td><td style=\"text-align: right;\">   21.7229</td></tr>\n",
       "<tr><td>objective_fddfe_00015</td><td>RUNNING </td><td>136.156.133.98:313635</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         415.531</td><td style=\"text-align: right;\">   21.1679</td></tr>\n",
       "<tr><td>objective_fddfe_00016</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00017</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00018</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00019</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00020</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00021</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00022</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00023</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00024</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00025</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00026</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00027</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00028</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00029</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00030</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00031</td><td>PENDING </td><td>                     </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_fddfe_00032</td><td>PENDING </td><td>                     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=313405)\u001b[0m Device available is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=313405)\u001b[0m /home/gbmc/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[36m(objective pid=313405)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=313405)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313437)\u001b[0m Device available is cuda\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=313405)\u001b[0m /home/gbmc/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313405)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=313405)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313545)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313416)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313488)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313635)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313532)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313532)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313545)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313405)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313464)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313464)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313531)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313533)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313488)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313488)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313532)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313635)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313635)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313545)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313405)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313545)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313437)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313437)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313406)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313406)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313533)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313488)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313532)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313532)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313635)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313545)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313538)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313403)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313403)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313550)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313437)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313550)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313406)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313406)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313533)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313531)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313533)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313488)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313488)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313416)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313545)\u001b[0m defaultdict(<class 'int'>, {})\n",
      "\u001b[36m(objective pid=313538)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313404)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313464)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313550)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=313550)\u001b[0m defaultdict(<class 'int'>, {})\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=315737)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=317064)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=318361)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=319947)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=321652)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=323205)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=324935)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=326335)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=328078)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=329680)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=331389)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=333004)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=334454)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=335895)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=337691)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=338627)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=340286)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=341205)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=342866)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=344355)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=346106)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=349640)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=350600)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=353643)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=354677)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=356342)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=357691)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=359379)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=361030)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=362618)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=364143)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=365509)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=367098)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=368934)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=370333)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=371913)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=373581)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=375250)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=376660)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=378392)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=380441)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=381711)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=383405)\u001b[0m Device available is cuda\n",
      "\u001b[36m(objective pid=384892)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=386369)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=387944)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=389575)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=390923)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=392033)\u001b[0m Device available is cuda\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=393411)\u001b[0m Device available is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 10:34:31,050\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-03-19 10:34:41,179\tINFO tune.py:1042 -- Total run time: 559.19 seconds (549.05 seconds for the tuning loop).\n",
      "2024-03-19 10:34:41,182\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/gbmc/ray_results/objective_2024-03-19_10-25-21\", trainable=...)\n",
      "2024-03-19 10:34:41,204\tWARNING experiment_analysis.py:193 -- Failed to fetch metrics for 17 trial(s):\n",
      "- objective_fddfe_00016: FileNotFoundError('Could not fetch metrics for objective_fddfe_00016: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00016_16_bidirectional=False,dropout=0.1000,hidden_size=128,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-22')\n",
      "- objective_fddfe_00017: FileNotFoundError('Could not fetch metrics for objective_fddfe_00017: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00017_17_bidirectional=True,dropout=0.1000,hidden_size=128,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00018: FileNotFoundError('Could not fetch metrics for objective_fddfe_00018: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00018_18_bidirectional=False,dropout=0.4000,hidden_size=128,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00019: FileNotFoundError('Could not fetch metrics for objective_fddfe_00019: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00019_19_bidirectional=True,dropout=0.4000,hidden_size=128,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00020: FileNotFoundError('Could not fetch metrics for objective_fddfe_00020: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00020_20_bidirectional=False,dropout=0.1000,hidden_size=256,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00021: FileNotFoundError('Could not fetch metrics for objective_fddfe_00021: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00021_21_bidirectional=True,dropout=0.1000,hidden_size=256,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00022: FileNotFoundError('Could not fetch metrics for objective_fddfe_00022: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00022_22_bidirectional=False,dropout=0.4000,hidden_size=256,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00023: FileNotFoundError('Could not fetch metrics for objective_fddfe_00023: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00023_23_bidirectional=True,dropout=0.4000,hidden_size=256,learning_rate=0.0010,num_layers=1_2024-03-19_10-25-26')\n",
      "- objective_fddfe_00024: FileNotFoundError('Could not fetch metrics for objective_fddfe_00024: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00024_24_bidirectional=False,dropout=0.1000,hidden_size=64,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00025: FileNotFoundError('Could not fetch metrics for objective_fddfe_00025: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00025_25_bidirectional=True,dropout=0.1000,hidden_size=64,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00026: FileNotFoundError('Could not fetch metrics for objective_fddfe_00026: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00026_26_bidirectional=False,dropout=0.4000,hidden_size=64,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00027: FileNotFoundError('Could not fetch metrics for objective_fddfe_00027: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00027_27_bidirectional=True,dropout=0.4000,hidden_size=64,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00028: FileNotFoundError('Could not fetch metrics for objective_fddfe_00028: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00028_28_bidirectional=False,dropout=0.1000,hidden_size=128,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00029: FileNotFoundError('Could not fetch metrics for objective_fddfe_00029: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00029_29_bidirectional=True,dropout=0.1000,hidden_size=128,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00030: FileNotFoundError('Could not fetch metrics for objective_fddfe_00030: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00030_30_bidirectional=False,dropout=0.4000,hidden_size=128,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00031: FileNotFoundError('Could not fetch metrics for objective_fddfe_00031: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00031_31_bidirectional=True,dropout=0.4000,hidden_size=128,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n",
      "- objective_fddfe_00032: FileNotFoundError('Could not fetch metrics for objective_fddfe_00032: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_10-25-21/objective_fddfe_00032_32_bidirectional=False,dropout=0.1000,hidden_size=256,learning_rate=0.0000,num_layers=1_2024-03-19_10-25-27')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'bidirectional': False, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "    print('Device available is', device)\n",
    "    \n",
    "\n",
    "    score = train_model_general(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "\n",
    "# Can use fractions of GPU\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space=config_space) \n",
    "\n",
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"val_loss\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_Model = torch.load('/data/Hydra_Work/Post_Rodeo_Work/Tuned_General_Model/General_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hydra Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models_hydra(body_input_size, body_hidden_size, body_num_layers, body_output_size, body_dropout, body_bidirectional,\n",
    "                                 head_input_size, head_hidden_size, head_num_layers, head_output_size, head_dropout, head_bidirectional,\n",
    "                        learning_rate_body, learning_rate_head, learning_rate_general_head, LR, basins = basins,  hidden_variables_size = hidden_variables_size, days = 90, device = device, copies = 3):\n",
    "    Hydra_Bodys = {}\n",
    "    model_heads = {}\n",
    "    General_Hydra_Heads = {}\n",
    "\n",
    "    params_to_optimize = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    for copy in range(copies):\n",
    "        Hydra_Bodys[copy], model_heads[copy], General_Hydra_Heads[copy], optimizers[copy], schedulers[copy] = initialize_models_optimizers(basins, body_input_size, body_hidden_size, body_num_layers, body_output_size, body_dropout, body_bidirectional,\n",
    "                            head_input_size, head_hidden_size, head_num_layers, head_output_size, head_dropout, head_bidirectional,\n",
    "                            days, hidden_variables_size, learning_rate_body, learning_rate_head, learning_rate_general_head, LR, device)\n",
    "\n",
    "    return Hydra_Bodys, General_Hydra_Heads, model_heads, optimizers, schedulers \n",
    "\n",
    "def update_final_parameters_hydra(Final_Parameters, min_val_loss_parameters, min_val_loss):\n",
    "    # Append body parameters\n",
    "    Final_Parameters['body_hidden_size'].append(min_val_loss_parameters[0])\n",
    "    Final_Parameters['body_num_layers'].append(min_val_loss_parameters[1])\n",
    "    Final_Parameters['body_dropout'].append(min_val_loss_parameters[2])\n",
    "    Final_Parameters['body_learning_rate'].append(min_val_loss_parameters[3])\n",
    "    Final_Parameters['body_output'].append(min_val_loss_parameters[4])\n",
    "    # Append head parameters\n",
    "    Final_Parameters['head_hidden_size'].append(min_val_loss_parameters[5])\n",
    "    Final_Parameters['head_num_layers'].append(min_val_loss_parameters[6])\n",
    "    Final_Parameters['head_dropout'].append(min_val_loss_parameters[7])\n",
    "    Final_Parameters['head_learning_rate'].append(min_val_loss_parameters[8])\n",
    "    # Append validation loss\n",
    "    Final_Parameters['val_loss'].append(min_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 20\n",
    "n_epochs = 1 # Epochs between tests\n",
    "group_lengths = np.arange(180)\n",
    "batch_size = 1\n",
    "copies = 3\n",
    "body_input_size = input_size\n",
    "head_output_size = 3\n",
    "\n",
    "# parameters to tune\n",
    "# chose 128, 2, 0.1, 1e-3, 6, 32, 1, 0.4, 1e-3\n",
    "body_hidden_sizes = [64, 128, 256]\n",
    "body_num_layers =  [1, 3]\n",
    "body_dropouts = [0.1, 0.4]\n",
    "body_learning_rates = [1e-3, 1e-5]\n",
    "body_outputs = [3, 6, 10]\n",
    "\n",
    "\n",
    "head_hidden_sizes = [16, 32, 64]\n",
    "head_num_layers = [1, 3]\n",
    "head_dropouts = [0.1, 0.4, 0.7]\n",
    "head_learning_rates = [1e-3, 1e-5]\n",
    "LR = [1e-3]\n",
    "bidirectionals = [False, True]\n",
    "\n",
    "config_space = {\n",
    "    \"body_hidden_size\": tune.grid_search(body_hidden_sizes),\n",
    "    \"body_num_layer\": tune.grid_search(body_num_layers),\n",
    "    \"body_dropout\": tune.grid_search(body_dropouts),\n",
    "    \"bidirectional\": tune.grid_search(bidirectionals),\n",
    "    \"body_output\": tune.grid_search(body_outputs),\n",
    "    \"body_learning_rate\": tune.grid_search(body_learning_rates),\n",
    "    \"head_hidden_size\": tune.grid_search(head_hidden_sizes),\n",
    "    \"head_num_layer\": tune.grid_search(head_num_layers),\n",
    "    \"head_dropout\": tune.grid_search(head_dropouts),\n",
    "    \"head_learning_rate\": tune.grid_search(head_learning_rates),\n",
    "    \"general_head_learning_rate\": tune.grid_search(head_learning_rates),\n",
    "    \"LR\": tune.grid_search(LR)\n",
    "}\n",
    "\n",
    "# Places to save info\n",
    "model_dir = '/data/Hydra_Work/Post_Rodeo_Work/Tuned_Hydra_Model/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_hydra(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    Val_Dates = ray.get(Val_Dates_id)  \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "    copies = 3\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "   \n",
    "\n",
    "    Hydra_Bodys, General_Hydra_Heads, model_heads, optimizers, schedulers  = define_models_hydra(body_input_size, config['body_hidden_size'],\n",
    "                                config['body_num_layer'],  config['body_output'], config['body_dropout'], config['bidirectional'], config['body_output'],\n",
    "                                config['head_hidden_size'], config['head_num_layer'], 3, config['head_dropout'], config['bidirectional'],\n",
    "                                config['body_learning_rate'], config['head_learning_rate'], config['general_head_learning_rate'], config['LR']\n",
    "                                )\n",
    "     \n",
    "\n",
    "    general_losses, specific_losses, general_val_losses, specific_val_losses = [], [], [], []\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=10, min_delta=0.01)\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        train_general_losses = {}\n",
    "        train_specific_losses = {}\n",
    "        epoch_val_general_losses = {}\n",
    "        epoch_val_specific_losses = {}\n",
    "        climate_losses = {}\n",
    "        \n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_general_losses[copy], train_specific_losses[copy], climate_losses[copy] = Model_Run(All_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper=early_stopper, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, feed_forcing = False)\n",
    "            epoch_val_general_losses[copy], epoch_val_specific_losses[copy], climate_losses[copy] = Model_Run(Val_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper=early_stopper, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, feed_forcing = False)\n",
    "\n",
    "        general_loss = np.mean(list(train_general_losses.values()))\n",
    "        specific_loss = np.mean(list(train_specific_losses.values()))\n",
    "        \n",
    "        epoch_val_general_loss = np.mean(list(epoch_val_general_losses.values())).mean()\n",
    "        epoch_val_specific_loss = np.mean(list(epoch_val_specific_losses.values())).mean()\n",
    "        \n",
    "        \n",
    "        general_losses.append(general_loss)\n",
    "        specific_losses.append(specific_loss)\n",
    "        specific_val_losses.append(epoch_val_specific_loss)\n",
    "        specific_val_losses.append(epoch_val_specific_loss)\n",
    "\n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            break\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-03-19 12:08:54</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:24.30        </td></tr>\n",
       "<tr><td>Memory:      </td><td>71.8/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 16.0/16 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">   LR</th><th>bidirectional  </th><th style=\"text-align: right;\">  body_dropout</th><th style=\"text-align: right;\">  body_hidden_size</th><th style=\"text-align: right;\">  body_learning_rate</th><th style=\"text-align: right;\">  body_num_layer</th><th style=\"text-align: right;\">  body_output</th><th style=\"text-align: right;\">      general_head_learnin\n",
       "g_rate</th><th style=\"text-align: right;\">  head_dropout</th><th style=\"text-align: right;\">  head_hidden_size</th><th style=\"text-align: right;\">  head_learning_rate</th><th style=\"text-align: right;\">  head_num_layer</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_fad02_00000</td><td>RUNNING </td><td>136.156.133.98:396242</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00001</td><td>RUNNING </td><td>136.156.133.98:396267</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00002</td><td>RUNNING </td><td>136.156.133.98:396301</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00003</td><td>RUNNING </td><td>136.156.133.98:396457</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00004</td><td>RUNNING </td><td>136.156.133.98:396459</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00005</td><td>RUNNING </td><td>136.156.133.98:396496</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00006</td><td>RUNNING </td><td>136.156.133.98:396528</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00007</td><td>RUNNING </td><td>136.156.133.98:396544</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00008</td><td>RUNNING </td><td>136.156.133.98:396577</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00009</td><td>RUNNING </td><td>136.156.133.98:396582</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00010</td><td>RUNNING </td><td>136.156.133.98:396583</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00011</td><td>RUNNING </td><td>136.156.133.98:396588</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00012</td><td>RUNNING </td><td>136.156.133.98:396593</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00013</td><td>RUNNING </td><td>136.156.133.98:396595</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00014</td><td>RUNNING </td><td>136.156.133.98:396601</td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00015</td><td>RUNNING </td><td>136.156.133.98:396730</td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00016</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00017</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00018</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00019</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00020</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00021</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00022</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00023</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               1e-05</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00024</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00025</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00026</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00027</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00028</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00029</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00030</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00031</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>True           </td><td style=\"text-align: right;\">           0.4</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_fad02_00032</td><td>PENDING </td><td>                     </td><td style=\"text-align: right;\">0.001</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">               256</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               3</td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">0.001</td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                16</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=396301)\u001b[0m Device available is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=396601)\u001b[0m /home/gbmc/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "\u001b[36m(objective pid=396601)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "\u001b[36m(objective pid=396601)\u001b[0m /home/gbmc/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396601)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\u001b[32m [repeated 16x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=396601)\u001b[0m Epoch 1: Training Mode\n",
      "\u001b[36m(objective pid=396601)\u001b[0m general difference : 2.6705935244298487 \n",
      "\u001b[36m(objective pid=396601)\u001b[0m specific difference: 9.121204995386716\n",
      "\u001b[36m(objective pid=396601)\u001b[0m Climatology loss: 29.276312078442377\n",
      "\u001b[36m(objective pid=396595)\u001b[0m Device available is cuda\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m Epoch 1: Training Mode\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m general difference : 1.901206251964984 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m specific difference: 7.5696723828779975\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m Climatology loss: 30.05716260423443\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396457)\u001b[0m Epoch 1: Training Mode\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396457)\u001b[0m general difference : 1.0403344970271724 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396457)\u001b[0m specific difference: 4.664757072053568\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396457)\u001b[0m Climatology loss: 29.273045060564854\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396601)\u001b[0m Epoch 1: Validation Mode\n",
      "\u001b[36m(objective pid=396528)\u001b[0m Epoch 1: Training Mode\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m general difference : 2.4793761716570173 \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m specific difference: 0.2819934928417206\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m Climatology loss: 20.635511403764998\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396301)\u001b[0m Epoch 1: Validation Mode\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m Epoch 1: Training Mode\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m general difference : 0.8112950985378271 \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m specific difference: 4.932332494676669\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m Climatology loss: 29.675903146117076\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396457)\u001b[0m Epoch 1: Validation Mode\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396544)\u001b[0m Epoch 1: Training Mode\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396577)\u001b[0m general difference : -0.36950703280312674 \u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396577)\u001b[0m specific difference: 1.0181304574012757\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396577)\u001b[0m Climatology loss: 18.22623148236956\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396577)\u001b[0m Epoch 1: Validation Mode\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m general difference : -0.04344029120036534 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m specific difference: -0.19438241754259383\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m Climatology loss: 23.397464065892354\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=396496)\u001b[0m Epoch 1: Validation Mode\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 12:08:53,912\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-03-19 12:09:04,231\tINFO tune.py:1042 -- Total run time: 214.42 seconds (204.09 seconds for the tuning loop).\n",
      "2024-03-19 12:09:04,234\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/gbmc/ray_results/objective_2024-03-19_12-05-29\", trainable=...)\n",
      "2024-03-19 12:09:04,246\tWARNING experiment_analysis.py:193 -- Failed to fetch metrics for 17 trial(s):\n",
      "- objective_fad02_00016: FileNotFoundError('Could not fetch metrics for objective_fad02_00016: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00016_16_LR=0.0010,bidirectional=False,body_dropout=0.1000,body_hidden_size=128,body_learning_rate=0.0000,body_num_2024-03-19_12-05-31')\n",
      "- objective_fad02_00017: FileNotFoundError('Could not fetch metrics for objective_fad02_00017: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00017_17_LR=0.0010,bidirectional=True,body_dropout=0.1000,body_hidden_size=128,body_learning_rate=0.0000,body_num__2024-03-19_12-05-36')\n",
      "- objective_fad02_00018: FileNotFoundError('Could not fetch metrics for objective_fad02_00018: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00018_18_LR=0.0010,bidirectional=False,body_dropout=0.4000,body_hidden_size=128,body_learning_rate=0.0000,body_num_2024-03-19_12-05-36')\n",
      "- objective_fad02_00019: FileNotFoundError('Could not fetch metrics for objective_fad02_00019: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00019_19_LR=0.0010,bidirectional=True,body_dropout=0.4000,body_hidden_size=128,body_learning_rate=0.0000,body_num__2024-03-19_12-05-36')\n",
      "- objective_fad02_00020: FileNotFoundError('Could not fetch metrics for objective_fad02_00020: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00020_20_LR=0.0010,bidirectional=False,body_dropout=0.1000,body_hidden_size=256,body_learning_rate=0.0000,body_num_2024-03-19_12-05-36')\n",
      "- objective_fad02_00021: FileNotFoundError('Could not fetch metrics for objective_fad02_00021: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00021_21_LR=0.0010,bidirectional=True,body_dropout=0.1000,body_hidden_size=256,body_learning_rate=0.0000,body_num__2024-03-19_12-05-36')\n",
      "- objective_fad02_00022: FileNotFoundError('Could not fetch metrics for objective_fad02_00022: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00022_22_LR=0.0010,bidirectional=False,body_dropout=0.4000,body_hidden_size=256,body_learning_rate=0.0000,body_num_2024-03-19_12-05-36')\n",
      "- objective_fad02_00023: FileNotFoundError('Could not fetch metrics for objective_fad02_00023: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00023_23_LR=0.0010,bidirectional=True,body_dropout=0.4000,body_hidden_size=256,body_learning_rate=0.0000,body_num__2024-03-19_12-05-36')\n",
      "- objective_fad02_00024: FileNotFoundError('Could not fetch metrics for objective_fad02_00024: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00024_24_LR=0.0010,bidirectional=False,body_dropout=0.1000,body_hidden_size=64,body_learning_rate=0.0010,body_num__2024-03-19_12-05-36')\n",
      "- objective_fad02_00025: FileNotFoundError('Could not fetch metrics for objective_fad02_00025: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00025_25_LR=0.0010,bidirectional=True,body_dropout=0.1000,body_hidden_size=64,body_learning_rate=0.0010,body_num_l_2024-03-19_12-05-36')\n",
      "- objective_fad02_00026: FileNotFoundError('Could not fetch metrics for objective_fad02_00026: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00026_26_LR=0.0010,bidirectional=False,body_dropout=0.4000,body_hidden_size=64,body_learning_rate=0.0010,body_num__2024-03-19_12-05-36')\n",
      "- objective_fad02_00027: FileNotFoundError('Could not fetch metrics for objective_fad02_00027: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00027_27_LR=0.0010,bidirectional=True,body_dropout=0.4000,body_hidden_size=64,body_learning_rate=0.0010,body_num_l_2024-03-19_12-05-36')\n",
      "- objective_fad02_00028: FileNotFoundError('Could not fetch metrics for objective_fad02_00028: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00028_28_LR=0.0010,bidirectional=False,body_dropout=0.1000,body_hidden_size=128,body_learning_rate=0.0010,body_num_2024-03-19_12-05-37')\n",
      "- objective_fad02_00029: FileNotFoundError('Could not fetch metrics for objective_fad02_00029: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00029_29_LR=0.0010,bidirectional=True,body_dropout=0.1000,body_hidden_size=128,body_learning_rate=0.0010,body_num__2024-03-19_12-05-37')\n",
      "- objective_fad02_00030: FileNotFoundError('Could not fetch metrics for objective_fad02_00030: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00030_30_LR=0.0010,bidirectional=False,body_dropout=0.4000,body_hidden_size=128,body_learning_rate=0.0010,body_num_2024-03-19_12-05-37')\n",
      "- objective_fad02_00031: FileNotFoundError('Could not fetch metrics for objective_fad02_00031: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00031_31_LR=0.0010,bidirectional=True,body_dropout=0.4000,body_hidden_size=128,body_learning_rate=0.0010,body_num__2024-03-19_12-05-37')\n",
      "- objective_fad02_00032: FileNotFoundError('Could not fetch metrics for objective_fad02_00032: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-03-19_12-05-29/objective_fad02_00032_32_LR=0.0010,bidirectional=False,body_dropout=0.1000,body_hidden_size=256,body_learning_rate=0.0010,body_num_2024-03-19_12-05-37')\n",
      "2024-03-19 12:09:04,248\tWARNING experiment_analysis.py:584 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m tuner \u001b[38;5;241m=\u001b[39m tune\u001b[38;5;241m.\u001b[39mTuner(tune\u001b[38;5;241m.\u001b[39mwith_resources(tune\u001b[38;5;241m.\u001b[39mwith_parameters(objective), resources\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m16\u001b[39m}), param_space\u001b[38;5;241m=\u001b[39mconfig_space) \n\u001b[1;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/ray/tune/result_grid.py:162\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    151\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    156\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "\n",
    "    score = train_model_hydra(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "\n",
    "# Can use fractions of GPU\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space=config_space) \n",
    "\n",
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"val_loss\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rodeo_V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
