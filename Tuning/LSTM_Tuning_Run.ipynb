{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/Hydra_Work/Competition_Functions') \n",
    "from Processing_Functions import process_forecast_date, process_seasonal_forecasts\n",
    "from Data_Transforming import read_nested_csvs, generate_daily_flow, use_USGS_flow_data, USGS_to_daily_df_yearly\n",
    "\n",
    "sys.path.append('/data/Hydra_Work/Pipeline_Functions')\n",
    "from Folder_Work import filter_rows_by_year, csv_dictionary, add_day_of_year_column\n",
    "\n",
    "sys.path.append('/data/Hydra_Work/Post_Rodeo_Work/ML_Functions.py')\n",
    "from Full_LSTM_ML_Functions import Specific_Heads, Google_Model_Block, SumPinballLoss, EarlyStopper, Model_Run, No_Body_Model_Run\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the cross validation set\n",
    "\n",
    "Cross Validation decisions:\n",
    "- It looks like I only have 10 years right now, and if the results are good I can keep it that way (justify by independent years)\n",
    "- Training set of 80% and Validation of 20% is fine, makes sense to make the Validation years adjacent instead of random, probably doesn't matter much but adjacent minimises theyre connection with the years in the training dataset\n",
    "- This means theres only 5 folds which shouldn't take forever to do \n",
    "- There's an issue right now where my validation set is also my test set, how much can I get around this?\n",
    "- I could test a 10-20-10 set up, from the looks of it there won't be that much loss in performance by reducing the training set by 12%? \n",
    "- If I assume the years are independent then it doesn't matter which dates I choose for validation years when I've got a specific testing year\n",
    "- K -fold cross validation means splitting the data in k chunks and choosing a different chunk for each, p-fold involves choosing all possible combinations of size p for the splits\n",
    "\n",
    "Structure of the folders:\n",
    "- Can do Validation_Models/Val_Years/Model/.pth, bs Model/Val_Years/.pth\n",
    "- I think the first makes more sense, I would realy want to ompare models trained over the same years\n",
    "\n",
    "\n",
    "Restructuring Current code:\n",
    "- I want to fit this whole thing into a for loop so I can run it\n",
    "- Alternatively I can have the validation years as a parameter in the config_space and just let the code run as is\n",
    "- It would be nice to make the prep section smaller visually, or hidden somewhere else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydra_Code\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_env():\n",
    "    sp = sys.path[1].split(\"/\")\n",
    "    if \"envs\" in sp:\n",
    "        return sp[sp.index(\"envs\") + 1]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "print(get_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = ['libby_reservoir_inflow',  'owyhee_r_bl_owyhee_dam',  'san_joaquin_river_millerton_reservoir',  'taylor_park_reservoir_inflow',\n",
    " 'boise_r_nr_boise', 'green_r_bl_howard_a_hanson_dam', 'weber_r_nr_oakley', 'detroit_lake_inflow', 'virgin_r_at_virtin', 'dillon_reservoir_inflow',\n",
    " 'pueblo_reservoir_inflow', 'hungry_horse_reservoir_inflow', 'stehekin_r_at_stehekin', 'pecos_r_nr_pecos', 'snake_r_nr_heise', 'yampa_r_nr_maybell',\n",
    " 'colville_r_at_kettle_falls', 'missouri_r_at_toston', 'merced_river_yosemite_at_pohono_bridge', 'animas_r_at_durango','fontenelle_reservoir_inflow', 'boysen_reservoir_inflow']\n",
    "\n",
    "selected_years = range(2000,2024,2)\n",
    "\n",
    "\n",
    "base_dir = \"/data/Hydra_Work/Scaled_Data\"\n",
    "\n",
    "# Define dictionaries and DataFrames\n",
    "dictionaries = ['era5', 'seasonal_forecasts', 'daily_flow', 'climatological_flows']\n",
    "\n",
    "dataframes = ['climate_indices', 'static_variables']\n",
    "\n",
    "# Function to load dictionaries\n",
    "def load_dictionaries(base_dir, names):\n",
    "    loaded_dicts = {}\n",
    "    for name in names:\n",
    "        file_path = os.path.join(base_dir, f\"{name}.pkl\")\n",
    "        with open(file_path, 'rb') as file:\n",
    "            locals()[name] = pickle.load(file)\n",
    "    return locals()\n",
    "\n",
    "# Function to load DataFrames\n",
    "def load_dataframes(base_dir, names):\n",
    "    loaded_dfs = {}\n",
    "    for name in names:\n",
    "        file_path = os.path.join(base_dir, f\"{name}.pkl\")\n",
    "        locals()[name] = pd.read_pickle(file_path)\n",
    "    return locals()\n",
    "\n",
    "saved_dicts = load_dictionaries(base_dir, dictionaries)\n",
    "saved_dfs = load_dataframes(base_dir, dataframes)\n",
    "\n",
    "for name in dictionaries:\n",
    "    locals()[name] = saved_dicts[name]\n",
    "\n",
    "for name in dataframes:\n",
    "    locals()[name] = saved_dfs[name]\n",
    "\n",
    "criterion = SumPinballLoss(quantiles = [0.1, 0.5, 0.9])\n",
    "\n",
    "basin = 'animas_r_at_durango' \n",
    "All_Dates = daily_flow[basin].index[\n",
    "    ((daily_flow[basin].index.month < 6) | ((daily_flow[basin].index.month == 6) & (daily_flow[basin].index.day < 24))) &\n",
    "    ((daily_flow[basin].index.year % 2 == 0) | ((daily_flow[basin].index.month > 10) | ((daily_flow[basin].index.month == 10) & (daily_flow[basin].index.day >= 1))))\n",
    "]\n",
    "All_Dates = All_Dates[All_Dates.year > 1998]\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.\n",
    "                is_available() else 'cpu')\n",
    "\n",
    "criterion = SumPinballLoss(quantiles = [0.1, 0.5, 0.9])\n",
    "\n",
    "basin = 'animas_r_at_durango' \n",
    "All_Dates = daily_flow[basin].index[\n",
    "    ((daily_flow[basin].index.month < 6) | ((daily_flow[basin].index.month == 6) & (daily_flow[basin].index.day < 24))) &\n",
    "    ((daily_flow[basin].index.year % 2 == 0) | ((daily_flow[basin].index.month > 10) | ((daily_flow[basin].index.month == 10) & (daily_flow[basin].index.day >= 1))))\n",
    "]\n",
    "All_Dates = All_Dates[All_Dates.year > 1998]\n",
    "\n",
    "\n",
    "seed = 42 ; torch.manual_seed(seed) ; random.seed(seed) ; np.random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "days  = 90\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning individual basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 0 #3 # THis is about climatology, not climate indices\n",
    "History_Statistics_in_forcings = 0  #5*2\n",
    "\n",
    "forecast_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n",
    "hindcast_input_size = 9 # 17 if we include climate indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retrain_Basins = basins\n",
    "for basin in basins:\n",
    "    loss_path = f'/data/Hydra_Work/Tuning/Week_Ahead_Models_V2/Specific_Week_Ahead_Models/{basin}_specific_loss.txt'\n",
    "    \n",
    "    with open(loss_path, 'r') as file:\n",
    "    # Read the entire contents of the file\n",
    "        Overall_Best_Val_Loss = float(file.read())\n",
    "    \n",
    "    if Overall_Best_Val_Loss < -0.05:\n",
    "        Retrain_Basins = list(set(Retrain_Basins) - set([basin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we want hindcast and forecast num-layers to be different?\n",
    "def define_models(hindcast_input_size, forecast_input_size, hidden_size, num_layers, dropout, bidirectional, learning_rate, copies = 3, forecast_output_size = 3, device = device):\n",
    "    models = {}\n",
    "    params_to_optimize = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    \n",
    "    hindcast_output_size = forecast_output_size\n",
    "    for copy in range(copies):\n",
    "        models[copy] = Google_Model_Block(hindcast_input_size, forecast_input_size, hindcast_output_size, forecast_output_size, hidden_size, num_layers, device, dropout, bidirectional)\n",
    "        \n",
    "        models[copy].to(device)\n",
    "        params_to_optimize[copy] = list(models[copy].parameters())\n",
    "        # Probably should be doing 1e-2 and 10\n",
    "        optimizers[copy] = torch.optim.Adam(params_to_optimize[copy], lr= learning_rate, weight_decay = 1e-4)\n",
    "        schedulers[copy] = lr_scheduler.StepLR(optimizers[copy], step_size= 5000, gamma=0.95) #.CosineAnnealingLR(optimizers[copy], T_max = 100000,)\n",
    "        #\n",
    "        \n",
    "\n",
    "    return models, params_to_optimize, optimizers, schedulers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "import optuna\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 200\n",
    "n_epochs = 1  # Epochs between tests\n",
    "group_lengths = [1] #np.arange(180) 1 Day ahead for streamlined version\n",
    "batch_size = 256\n",
    "copies = 1\n",
    "\n",
    "# parameters to tune\n",
    "hidden_sizes = [128] # 64 converged upon\n",
    "num_layers =  [1]\n",
    "dropout = [0.1]\n",
    "bidirectional = [False] #[True, False]\n",
    "learning_rate = [1e-1, 1e-2] #[1e-3, 1e-5]\n",
    "\n",
    "\n",
    "# Set up configuration space\n",
    "config_space = {\n",
    "\n",
    "    \"hidden_size\": tune.grid_search(hidden_sizes),\n",
    "    \"num_layers\": tune.grid_search(num_layers),\n",
    "    \"dropout\": tune.grid_search(dropout),\n",
    "    \"bidirectional\": tune.grid_search(bidirectional),\n",
    "    \"learning_rate\": tune.grid_search(learning_rate),\n",
    "    \"basin\":  tune.grid_search(basins),\n",
    "    'test_year': tune.grid_search(list(np.arange(2000,2024,2)) )\n",
    "\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "\n",
    "    years = list(np.arange(2000,2024,2))\n",
    "    test_year = config['test_year']\n",
    "    val_years = [years[years.index(test_year)-1], years[years.index(test_year)-2]  ]\n",
    "    train_years = [year for year in years if year not in [test_year] + val_years]\n",
    "    \n",
    "    Test_Dates = All_Dates[All_Dates.year == test_year]\n",
    "    Val_Dates = All_Dates[All_Dates.year.isin(val_years)]\n",
    "    Train_Dates = All_Dates[All_Dates.year.isin(train_years)]\n",
    "\n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "    val_loss = 1000\n",
    "\n",
    "    basin = config[\"basin\"]\n",
    "\n",
    "    save_path = f'/data/Hydra_Work/1_Day_No_Forecast_Validation_Models/{test_year}/Specific_LSTM_Model/{basin}_specific.pth'\n",
    "    loss_path = f'/data/Hydra_Work/1_Day_No_Forecast_Validation_Models/{test_year}/Specific_LSTM_Model/{basin}_specific_loss.txt'\n",
    "\n",
    "    \n",
    "    if os.path.exists(loss_path):\n",
    "        # If the file does not exist, create it and write val_loss to it\n",
    "        with open(loss_path, 'w') as file:\n",
    "            file.write('%f' % val_loss)\n",
    "    \n",
    "    copies = 1\n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "    \n",
    "    models, params_to_optimize, optimizers, schedulers = define_models(hindcast_input_size, forecast_input_size,\n",
    "    config[\"hidden_size\"], config[\"num_layers\"], config[\"dropout\"],\n",
    "    config[\"bidirectional\"], config[\"learning_rate\"], copies=copies, device = device)\n",
    "\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        train_losses = {}\n",
    "        epoch_val_losses = {}\n",
    "\n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_losses[copy], Climate_Loss = No_Body_Model_Run(Train_Dates, [basin], models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, specialised=True)\n",
    "            epoch_val_losses[copy], Climate_Loss = No_Body_Model_Run(Val_Dates, [basin], models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, specialised=True)\n",
    "\n",
    "        loss = np.mean(list(train_losses.values())) - Climate_Loss\n",
    "        \n",
    "\n",
    "        candidate_val_loss = ((np.mean( list(epoch_val_losses.values()) ).mean() - Climate_Loss)[0])/np.mean(Climate_Loss)\n",
    "        val_loss = np.min([val_loss, candidate_val_loss ])\n",
    "        if candidate_val_loss == val_loss:\n",
    "             torch.save(models[0], save_path)\n",
    "             \n",
    "        \n",
    "        # Check best loss so far for this model\n",
    "        with open(loss_path, 'r') as file:\n",
    "            # Read the entire contents of the file\n",
    "            Overall_Best_Val_Loss = float(file.read())\n",
    "\n",
    "        if val_loss < Overall_Best_Val_Loss:\n",
    "            torch.save(models[0], save_path)\n",
    "\n",
    "            with open(loss_path, 'w') as f:\n",
    "                f.write('%f' % val_loss)\n",
    "\n",
    "\n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "        #print(candidate_val_loss)\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 13:06:37,677\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)   \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(static_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='val_loss',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=20,\n",
    "    reduction_factor=2,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "\n",
    "plateau_stopper = TrialPlateauStopper(\n",
    "    metric=\"val_loss\",\n",
    "    num_results = 20,\n",
    "    grace_period=50,\n",
    "    mode=\"min\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-11 13:06:40</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.29        </td></tr>\n",
       "<tr><td>Memory:      </td><td>30.7/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None<br>Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc  </th><th>basin               </th><th>bidirectional  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  test_year</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_71267_00000</td><td>PENDING </td><td>     </td><td>libby_reservoir_fe60</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00001</td><td>PENDING </td><td>     </td><td>owyhee_r_bl_owy_7640</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00002</td><td>PENDING </td><td>     </td><td>san_joaquin_riv_a970</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00003</td><td>PENDING </td><td>     </td><td>taylor_park_res_0350</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00004</td><td>PENDING </td><td>     </td><td>boise_r_nr_boise    </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00005</td><td>PENDING </td><td>     </td><td>green_r_bl_howa_ea10</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00006</td><td>PENDING </td><td>     </td><td>weber_r_nr_oakley   </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00007</td><td>PENDING </td><td>     </td><td>detroit_lake_inflow </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00008</td><td>PENDING </td><td>     </td><td>virgin_r_at_virtin  </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00009</td><td>PENDING </td><td>     </td><td>dillon_reservoi_48a0</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00010</td><td>PENDING </td><td>     </td><td>pueblo_reservoi_4ad0</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00011</td><td>PENDING </td><td>     </td><td>hungry_horse_re_4990</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00012</td><td>PENDING </td><td>     </td><td>stehekin_r_at_s_1ac0</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00013</td><td>PENDING </td><td>     </td><td>pecos_r_nr_pecos    </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00014</td><td>PENDING </td><td>     </td><td>snake_r_nr_heise    </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00015</td><td>PENDING </td><td>     </td><td>yampa_r_nr_maybell  </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "<tr><td>objective_71267_00016</td><td>PENDING </td><td>     </td><td>colville_r_at_k_e2e0</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">            0.1</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Stehekin gives :True\t0.4\t64\t0.001\t3 Even looking at overall min, and for animas r at durango\n",
    "# T-tests suggests: Bidirectional good, dropout unimportant, 16 bad, 64 vs 128 unimportant. All models that imrpvoed loss wre bidirectional\n",
    "# Libby seemed to want an single layer\n",
    "# San Joaqin is just hard, score of 9.4: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'bidirectional': False, 'learning_rate': 1e-05}\n",
    "\n",
    "\n",
    "runs = 12\n",
    "# At weekly:\n",
    "# Animas has {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': False, 'learning_rate': 1e-05}, 64,3,0.1. Results for 64, 1, 0.1, True identical\n",
    "def objective(config):   \n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "    #print('Device available is', device)\n",
    "    \n",
    "\n",
    "    score = train_model(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "#basin = 'stehekin_r_at_stehekin'\n",
    "\n",
    "#, search_alg = optuna_search\n",
    "optuna_tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "running_tune_config = tune.TuneConfig()\n",
    "\n",
    "run_config=train.RunConfig(stop= plateau_stopper)\n",
    "\n",
    "# Note using < 1gb per run stops pylance from crashing I think\n",
    "# Without Optun\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 15/runs, \"gpu\": 1/runs}), param_space=config_space, tune_config = tune_config, run_config = run_config) \n",
    "# With Optuna\n",
    "#tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space = optuna_config_space, tune_config = optuna_tune_config, run_config = run_config) \n",
    "\n",
    "results = tuner.fit()\n",
    "best_config = results.get_best_result(metric=\"val_loss\", mode=\"min\").config\n",
    "print(best_config)\n",
    "\n",
    "\n",
    "\n",
    "# Define the file path where you want to save the best configuration\n",
    "file_path = f\"/data/Hydra_Work/Tuning/Config_Text/{basin}_best_config.txt\"\n",
    "# Open the file in write mode and save the configuration\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(str(best_config))\n",
    "\n",
    "print(\"Best configuration saved to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.get_dataframe()\n",
    "results_df[results_df['val_loss'] < -0.1][['val_loss', 'config/basin', 'config/test_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Safe_Basins = list(results_df[results_df['val_loss'] < -0.05]['config/basin'].values)\n",
    "Retrain_Basins = list(set(basins) - set(Safe_Basins))\n",
    "Retrain_Basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "results_df = results.get_dataframe()\n",
    "columns_to_drop = ['timestamp', 'checkpoint_dir_name', 'done', 'training_iteration', \n",
    "                   'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', \n",
    "                   'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n",
    "\n",
    "# Drop the columns\n",
    "results_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "val_loss_bidirectional_true = results_df[results_df['config/num_layers'] == 3]['val_loss']\n",
    "val_loss_bidirectional_false = results_df[results_df['config/num_layers'] == 1]['val_loss']\n",
    "\n",
    "# Perform a t-test\n",
    "t_statistic, p_value = stats.ttest_ind(val_loss_bidirectional_true, val_loss_bidirectional_false)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Check if the difference in means is statistically significant\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in mean val_loss is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in mean val_loss is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading models\n",
    "Tuned_Models = {}\n",
    "for basin in basins:\n",
    "    Tuned_Models[basin] = torch.load(f'/data/Hydra_Work/Post_Rodeo_Work/Tuned_Single_Models/basin.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 0 #3\n",
    "History_Statistics_in_forcings = 0 #5*2\n",
    "\n",
    "forecast_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n",
    "hindcast_input_size = 8 #8 for no flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 200\n",
    "n_epochs = 1 # Epochs between tests\n",
    "group_lengths = [1] # \n",
    "batch_size = 64\n",
    "copies = 1\n",
    "\n",
    "# parameters to tune\n",
    "# I tuned to 128,2,0.4,False,1e-3 \n",
    "hidden_sizes = [128]\n",
    "num_layers = [1]\n",
    "dropout = [0.1]\n",
    "bidirectional =  [False]\n",
    "learning_rate = [1e-3]\n",
    "\n",
    "config_space = {\n",
    "    \"hidden_size\": tune.grid_search(hidden_sizes),\n",
    "    \"num_layers\": tune.grid_search(num_layers),\n",
    "    \"dropout\": tune.grid_search(dropout),\n",
    "    \"bidirectional\": tune.grid_search(bidirectional),\n",
    "    \"learning_rate\": tune.grid_search(learning_rate),\n",
    "    'test_year': tune.grid_search(list(np.arange(2000,2024,2)) )\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# Places to save info\n",
    "model_dir = '/data/Hydra_Work/Post_Rodeo_Work/Tuned_General_Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_general(config):\n",
    "    \n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    \n",
    "    years = list(np.arange(2000,2024,2))\n",
    "    test_year = config['test_year']\n",
    "    val_years = [years[years.index(test_year)-1], years[years.index(test_year)-2]  ]\n",
    "    train_years = [year for year in years if year not in [test_year] + val_years]\n",
    "    \n",
    "    Test_Dates = All_Dates[All_Dates.year == test_year]\n",
    "    Val_Dates = All_Dates[All_Dates.year.isin(val_years)]\n",
    "    Train_Dates = All_Dates[All_Dates.year.isin(train_years)]\n",
    "    \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "    copies = 1\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "    save_path = f'/data/Hydra_Work/3_Day_No_Forecast_Validation_Models/{test_year}/General_LSTM_No_Flow_Model/General_LSTM.pth'\n",
    "    loss_path = f'/data/Hydra_Work/3_Day_No_Forecast_Validation_Models/{test_year}/General_LSTM_No_Flow_Model/General_LSTM_loss.txt'\n",
    "\n",
    "    val_loss = 1000\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(loss_path):\n",
    "        # If the file does not exist, create it and write val_loss to it\n",
    "        with open(loss_path, 'w') as file:\n",
    "            file.write('%f' % val_loss)\n",
    "    \n",
    "  \n",
    "    models, params_to_optimize, optimizers, schedulers = define_models(hindcast_input_size, forecast_input_size,\n",
    "    config[\"hidden_size\"], config[\"num_layers\"], config[\"dropout\"],\n",
    "    config[\"bidirectional\"], config[\"learning_rate\"], copies=copies, device = device)\n",
    "\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        train_losses = {}\n",
    "        epoch_val_losses = {}\n",
    "\n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_losses[copy], Climate_Loss = No_Body_Model_Run(Train_Dates, basins, models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, specialised=False)\n",
    "            epoch_val_losses[copy], Climate_Loss = No_Body_Model_Run(Val_Dates, basins, models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, specialised=False)\n",
    "\n",
    "        loss = np.mean(list(train_losses.values())) - Climate_Loss\n",
    "\n",
    "\n",
    "        candidate_val_loss = ((np.mean(list(epoch_val_losses.values())).mean() - Climate_Loss)[0])/np.mean(Climate_Loss)\n",
    "        val_loss = np.min([val_loss, candidate_val_loss ])\n",
    "        \n",
    "        # Check best loss so far for this model\n",
    "        with open(loss_path, 'r') as file:\n",
    "            # Read the entire contents of the file\n",
    "            Overall_Best_Val_Loss = float(file.read())\n",
    "\n",
    "        if val_loss < Overall_Best_Val_Loss:\n",
    "            torch.save(models[0], save_path)\n",
    "\n",
    "            with open(loss_path, 'w') as f:\n",
    "                f.write('%f' % val_loss)\n",
    "\n",
    "            \n",
    "               \n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "\n",
    "        losses.append(loss)\n",
    "        val_losses.append(candidate_val_loss)\n",
    "        #print(val_losses)\n",
    "        #print(candidate_val_loss)\n",
    "        #print(loss/np.mean(Climate_Loss))\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:58:15,662\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)  \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(static_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asha_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     metric='val_loss',\n",
    "#     mode='min',\n",
    "#     max_t=100,\n",
    "#     grace_period=20,\n",
    "#     reduction_factor=2,\n",
    "#     brackets=1,\n",
    "# )\n",
    "\n",
    "\n",
    "plateau_stopper = TrialPlateauStopper(\n",
    "    metric=\"val_loss\",\n",
    "    num_results = 20,\n",
    "    grace_period=80,\n",
    "    mode=\"min\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-12 11:39:40</td></tr>\n",
       "<tr><td>Running for: </td><td>00:41:00.71        </td></tr>\n",
       "<tr><td>Memory:      </td><td>40.3/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.25/16 CPUs, 0.08333333333333333/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                   </th><th>bidirectional  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  test_year</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_b9831_00000</td><td>TERMINATED</td><td>136.156.133.98:1461492</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2000</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2456.29</td><td style=\"text-align: right;\"> -0.656336</td></tr>\n",
       "<tr><td>objective_b9831_00001</td><td>TERMINATED</td><td>136.156.133.98:1461493</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2002</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2364.59</td><td style=\"text-align: right;\"> -0.665044</td></tr>\n",
       "<tr><td>objective_b9831_00002</td><td>TERMINATED</td><td>136.156.133.98:1461494</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2004</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2438.34</td><td style=\"text-align: right;\"> -0.648911</td></tr>\n",
       "<tr><td>objective_b9831_00003</td><td>TERMINATED</td><td>136.156.133.98:1461495</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2006</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2448.96</td><td style=\"text-align: right;\"> -0.677184</td></tr>\n",
       "<tr><td>objective_b9831_00004</td><td>TERMINATED</td><td>136.156.133.98:1461497</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2008</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2453.13</td><td style=\"text-align: right;\"> -0.679881</td></tr>\n",
       "<tr><td>objective_b9831_00005</td><td>TERMINATED</td><td>136.156.133.98:1461496</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2010</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2326.55</td><td style=\"text-align: right;\"> -0.561095</td></tr>\n",
       "<tr><td>objective_b9831_00006</td><td>TERMINATED</td><td>136.156.133.98:1461687</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2012</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2455.46</td><td style=\"text-align: right;\"> -0.659958</td></tr>\n",
       "<tr><td>objective_b9831_00007</td><td>TERMINATED</td><td>136.156.133.98:1461941</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2014</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2455.73</td><td style=\"text-align: right;\"> -0.601142</td></tr>\n",
       "<tr><td>objective_b9831_00008</td><td>TERMINATED</td><td>136.156.133.98:1462012</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2016</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2357.04</td><td style=\"text-align: right;\"> -0.643775</td></tr>\n",
       "<tr><td>objective_b9831_00009</td><td>TERMINATED</td><td>136.156.133.98:1462018</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2018</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2374.34</td><td style=\"text-align: right;\"> -0.645212</td></tr>\n",
       "<tr><td>objective_b9831_00010</td><td>TERMINATED</td><td>136.156.133.98:1462028</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2020</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2455.03</td><td style=\"text-align: right;\"> -0.590392</td></tr>\n",
       "<tr><td>objective_b9831_00011</td><td>TERMINATED</td><td>136.156.133.98:1462029</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">       2022</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">         2448.52</td><td style=\"text-align: right;\"> -0.623645</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 11:37:30,028\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '80f16ada')}\n",
      "2024-06-12 11:38:01,054\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '1f98018a')}\n",
      "2024-06-12 11:38:07,772\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '6269ca81')}\n",
      "2024-06-12 11:38:18,458\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '93632d75')}\n",
      "2024-06-12 11:39:21,540\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', 'd31ea24e')}\n",
      "2024-06-12 11:39:32,286\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '77ade844')}\n",
      "2024-06-12 11:39:32,533\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', 'de5d0d51')}\n",
      "2024-06-12 11:39:36,876\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '5a92826b')}\n",
      "2024-06-12 11:39:39,181\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', 'd0c36a7a')}\n",
      "2024-06-12 11:39:39,658\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '52467d93')}\n",
      "2024-06-12 11:39:39,684\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '34b3c1e4')}\n",
      "2024-06-12 11:39:40,069\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '56d80434')}\n",
      "2024-06-12 11:39:40,100\tINFO tune.py:1042 -- Total run time: 2460.74 seconds (2460.70 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 128, 'num_layers': 1, 'dropout': 0.1, 'bidirectional': False, 'learning_rate': 0.001, 'test_year': 2008}\n",
      "Best configuration saved to: /data/Hydra_Work/Tuning/Config_Text/General_Model_best_config.txt\n"
     ]
    }
   ],
   "source": [
    "# {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': True, 'learning_rate': 0.001}\n",
    "# 7 Days:  128\t2\t0.4\tFalse\t0.001\n",
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "    #print('Device available is', device)\n",
    "    \n",
    "\n",
    "    score = train_model_general(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "\n",
    "#, search_alg = optuna_search\n",
    "# optuna_tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "# tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "run_config=train.RunConfig(stop= plateau_stopper)\n",
    "\n",
    "runs = 12\n",
    "# Without Optuna\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 15/runs , \"gpu\": 1/runs }), param_space=config_space, run_config = run_config) \n",
    "# With Optuna\n",
    "#tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space = optuna_config_space, tune_config = optuna_tune_config, run_config = run_config) \n",
    "\n",
    "results = tuner.fit()\n",
    "# try get_best_checkpoint, or change val to be maximum of current val_loss and previous ones\n",
    "best_config = results.get_best_result(metric=\"val_loss\", mode=\"min\").config\n",
    "print(best_config)\n",
    "file_path = f\"/data/Hydra_Work/Tuning/Config_Text/General_Model_best_config.txt\"\n",
    "\n",
    "# Open the file in write mode and save the configuration\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(str(best_config))\n",
    "\n",
    "print(\"Best configuration saved to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.get_dataframe()\n",
    "results_df[results_df['val_loss'] < -0.15] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_Model = torch.load('/data/Hydra_Work/Post_Rodeo_Work/Tuned_General_Model/General_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hydra Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models_hydra(body_hindcast_input_size, body_forecast_input_size, body_output_size, body_hidden_size, body_num_layers, body_dropout,\n",
    "                        head_hidden_size, head_num_layers, head_forecast_output_size, head_dropout, bidirectional, basins,\n",
    "                        learning_rate_general_head, learning_rate_head, learning_rate_body, LR = 1e-3, \n",
    "                        additional_specific_head_hindcast_input_size = 1, additional_specific_head_forecast_input_size = 0,\n",
    "                        copies=1, device=None):\n",
    "    Hydra_Bodys = {}\n",
    "    Basin_Heads = {}\n",
    "    General_Heads = {}   \n",
    "    general_optimizers = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    \n",
    "    body_forecast_output_size = body_output_size\n",
    "    body_hindcast_output_size = body_output_size\n",
    "    \n",
    "    # Define head hindcast size as head-forecast for simplicty\n",
    "    head_hindcast_output_size = head_forecast_output_size\n",
    "    specific_head_hindcast_output_size = head_forecast_output_size\n",
    "    specific_head_forecast_output_size = head_forecast_output_size\n",
    "    specific_head_hidden_size = head_hidden_size\n",
    "    specific_head_num_layers = head_num_layers\n",
    "    \n",
    "    # Head takes Body as inputs\n",
    "    #head_hindcast_input_size = body_hindcast_input_size \n",
    "    head_hindcast_input_size = body_hindcast_output_size\n",
    "    head_forecast_input_size = body_forecast_output_size\n",
    "    \n",
    "    # Specific input size\n",
    "    specific_head_hindcast_input_size = head_hindcast_input_size + additional_specific_head_hindcast_input_size\n",
    "    specific_head_forecast_input_size = head_forecast_input_size + additional_specific_head_forecast_input_size\n",
    "    \n",
    "    for copy in range(copies):\n",
    "        Hydra_Bodys[copy] = Google_Model_Block(body_hindcast_input_size, body_forecast_input_size, body_hindcast_output_size, body_forecast_output_size, body_hidden_size, body_num_layers, device, body_dropout, bidirectional)\n",
    "        General_Heads[copy] = Google_Model_Block(head_hindcast_input_size, head_forecast_input_size, head_hindcast_output_size, head_forecast_output_size, head_hidden_size, head_num_layers, device, head_dropout, bidirectional)\n",
    "        Basin_Heads[copy] = Specific_Heads(basins, specific_head_hindcast_input_size, specific_head_forecast_input_size, specific_head_hindcast_output_size, specific_head_forecast_output_size, specific_head_hidden_size, specific_head_num_layers, device, head_dropout, bidirectional)\n",
    "\n",
    "\n",
    "        specific_head_parameters = list()\n",
    "        for basin, model in Basin_Heads[copy].items():\n",
    "            specific_head_parameters += list(model.parameters())\n",
    "\n",
    "        optimizers[copy] = torch.optim.Adam(\n",
    "        # Extra LR is the global learning rate, not really important\n",
    "        [\n",
    "            {\"params\": General_Heads[copy].parameters(), \"lr\": learning_rate_general_head},\n",
    "            {\"params\": specific_head_parameters, \"lr\": learning_rate_head},\n",
    "            {\"params\": Hydra_Bodys[copy].parameters(), \"lr\": learning_rate_body},\n",
    "        ],\n",
    "        lr=LR, weight_decay = 1e-4) #1e-4 good so far, 3 not so food\n",
    "\n",
    "        general_optimizers[copy] = torch.optim.Adam(\n",
    "        # Extra LR is the global learning rate, not really important\n",
    "        [\n",
    "            {\"params\": General_Heads[copy].parameters(), \"lr\": learning_rate_general_head},\n",
    "            {\"params\": Hydra_Bodys[copy].parameters(), \"lr\": learning_rate_body},\n",
    "        ],\n",
    "        lr=LR, )\n",
    "        schedulers[copy] = lr_scheduler.StepLR(optimizers[copy], 1, gamma=0.99) #.CosineAnnealingLR(optimizers[copy], T_max= 100000, eta_min= 1e-4,)\n",
    "         #\n",
    "        \n",
    "    return Hydra_Bodys, General_Heads, Basin_Heads, optimizers, schedulers, general_optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 0 #3\n",
    "History_Statistics_in_forcings = 0 # 5*2\n",
    "\n",
    "forecast_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n",
    "body_hindcast_input_size = 8\n",
    "body_forecast_input_size = forecast_input_size\n",
    "\n",
    "\n",
    "Overall_Best_Val_Loss = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 200\n",
    "n_epochs = 1 # Epochs between tests\n",
    "group_lengths = [1] #np.arange(180)\n",
    "\n",
    "copies = 1\n",
    "head_output_size = 3\n",
    "\n",
    "# parameters to tune\n",
    "# chose 128, 2, 0.1, 1e-3, 6, 32, 1, 0.4, 1e-3\n",
    "body_hidden_sizes =  [128]\n",
    "body_num_layers = [1]\n",
    "body_dropouts = [0.0] #[0.1, 0.4]\n",
    "body_learning_rates = [1e-3] \n",
    "body_outputs = [4] # Say hindcast and forecasts have same outputrs body_hindcast_output_size\n",
    "\n",
    "\n",
    "head_hidden_sizes = [32]\n",
    "head_num_layers = [1]\n",
    "head_dropouts = [0.0] #[0.1, 0.4, 0.7]\n",
    "head_learning_rates = [1e-2] # May be 1e-3?\n",
    "batch_size = [256]\n",
    "LR = 1e-3\n",
    "bidirectionals = [False]\n",
    "spec_multiplier = [0.5]\n",
    "warmup = [5]\n",
    "\n",
    "config_space = {\n",
    "    \"body_hidden_size\": tune.grid_search(body_hidden_sizes),\n",
    "    \"body_num_layer\": tune.grid_search(body_num_layers),\n",
    "    \"body_dropout\": tune.grid_search(body_dropouts),\n",
    "    \"bidirectional\": tune.grid_search(bidirectionals),\n",
    "    \"body_output\": tune.grid_search(body_outputs),\n",
    "    \"body_learning_rate\": tune.grid_search(body_learning_rates),\n",
    "    \"head_hidden_size\": tune.grid_search(head_hidden_sizes),\n",
    "    \"head_num_layer\": tune.grid_search(head_num_layers),\n",
    "    \"head_dropout\": tune.grid_search(head_dropouts),\n",
    "    \"head_learning_rate\": tune.grid_search(head_learning_rates),\n",
    "    \"spec_multiplier\": tune.grid_search(spec_multiplier),\n",
    "    'batch_size': tune.grid_search(batch_size),\n",
    "    'test_year': tune.grid_search(list(np.arange(2000,2024,2))), #\n",
    "    'warmup': tune.grid_search(warmup),\n",
    "    #\"general_head_learning_rate\": tune.grid_search(head_learning_rates),\n",
    "}\n",
    "\n",
    "# Places to save info\n",
    "model_dir = '/data/Hydra_Work/Post_Rodeo_Work/Tuned_Hydra_Model/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_hydra(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    \n",
    "    \n",
    "    years = list(np.arange(2000,2024,2))\n",
    "    test_year = config['test_year']\n",
    "    val_years = [years[years.index(test_year)-1], years[years.index(test_year)-2]  ]\n",
    "    train_years = [year for year in years if year not in [test_year] + val_years]\n",
    "    \n",
    "    Test_Dates = All_Dates[All_Dates.year == test_year]\n",
    "    Val_Dates = All_Dates[All_Dates.year.isin(val_years)]\n",
    "    Train_Dates = All_Dates[All_Dates.year.isin(train_years)]\n",
    "\n",
    "    \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)  \n",
    "  \n",
    "                        \n",
    "    body_save_path = f'/data/Hydra_Work/3_Day_No_Forecast_Validation_Models/{test_year}/General_Head_Model/Hydra_Body_LSTM.pth'\n",
    "    head_save_path = f'/data/Hydra_Work/3_Day_No_Forecast_Validation_Models/{test_year}/General_Head_Model/Hydra_Head_LSTM.pth'\n",
    "    basin_heads_save_path = f'/data/Hydra_Work/3_Day_No_Forecast_Validation_Models/{test_year}/Basin_Head_Model'\n",
    "    \n",
    "    loss_path = f'/data/Hydra_Work/3_Day_No_Forecast_Validation_Models/{test_year}/General_Head_Model/Hydra_LSTM_loss.txt'\n",
    "\n",
    "    val_loss = 1000\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(loss_path):\n",
    "        # If the file does not exist, create it and write val_loss to it\n",
    "        with open(loss_path, 'w') as file:\n",
    "            file.write('%f' % val_loss)\n",
    "\n",
    "\n",
    "    copies = 1\n",
    "    warmup = config['warmup']\n",
    "    best_val_loss = 999\n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "   \n",
    "\n",
    "    general_head_learning_rate = config['body_learning_rate']\n",
    "    Hydra_Bodys, General_Hydra_Heads, model_heads, optimizers, schedulers, general_optimizers  = define_models_hydra(body_hindcast_input_size, body_forecast_input_size, config['body_output'],\n",
    "                                config['body_hidden_size'], config['body_num_layer'], config['body_dropout'], \n",
    "                                config['head_hidden_size'], config['head_num_layer'], 3, config['head_dropout'], config['bidirectional'], basins,\n",
    "                                general_head_learning_rate, config['head_learning_rate'], config['body_learning_rate'], LR, device = device\n",
    "                                )\n",
    "     \n",
    "\n",
    "    batch_size = config['batch_size']\n",
    "                                                \n",
    "    general_losses, specific_losses, general_val_losses, specific_val_losses, val_losses = [], [], [], [], []\n",
    "\n",
    "    # Initialise, with dummy scheduler\n",
    "    for copy in range(copies):\n",
    "        # Initialise\n",
    "        dummy_scheduler = lr_scheduler.StepLR(optimizers[copy],step_size = warmup, gamma = 0.8)\n",
    "\n",
    "        Model_Run(Train_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "            Static_variables, general_optimizers[copy], dummy_scheduler, criterion, early_stopper= None, n_epochs= warmup,\n",
    "            batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, feed_forcing = False)\n",
    "\n",
    "            \n",
    "    for epoch in range(total_epochs):\n",
    "        train_general_losses = {}\n",
    "        train_specific_losses = {}\n",
    "        train_climate_losses = {}\n",
    "        epoch_val_general_losses = {}\n",
    "        epoch_val_specific_losses = {}\n",
    "        climate_losses = {}\n",
    "        \n",
    "        for copy in range(copies):\n",
    "                        \n",
    "\n",
    "            # Full Training\n",
    "            train_general_losses[copy], train_specific_losses[copy], train_climate_losses[copy] = Model_Run(Train_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs= n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, feed_forcing = False, spec_multiplier = config[\"spec_multiplier\"])\n",
    "            epoch_val_general_losses[copy], epoch_val_specific_losses[copy], climate_losses[copy] = Model_Run(Val_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs= n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, feed_forcing = False)\n",
    "\n",
    "        general_loss = np.mean(list(train_general_losses.values()))\n",
    "        specific_loss = np.mean(list(train_specific_losses.values()))\n",
    "        train_climate_loss = np.mean(list(train_climate_losses.values()))\n",
    "        climate_loss = np.mean(list(climate_losses.values()))\n",
    "        \n",
    "        epoch_val_general_loss = np.mean(list(epoch_val_general_losses.values())).mean()\n",
    "        epoch_val_specific_loss = np.mean(list(epoch_val_specific_losses.values())).mean()\n",
    "        \n",
    "        \n",
    "        general_losses.append(general_loss)\n",
    "        specific_losses.append(specific_loss)\n",
    "        specific_val_losses.append(epoch_val_specific_loss)\n",
    "        general_val_losses.append(epoch_val_general_loss)\n",
    "\n",
    "        val_loss = 0.5*(epoch_val_general_loss + epoch_val_specific_loss)\n",
    "        candidate_val_loss = ((val_loss.mean() - climate_loss))/np.mean(climate_loss)\n",
    "        best_val_loss = np.min([best_val_loss, candidate_val_loss ])\n",
    "         \n",
    "        with open(loss_path, 'r') as file:\n",
    "            # Read the entire contents of the file\n",
    "            Overall_Best_Val_Loss = float(file.read())\n",
    "\n",
    "        if best_val_loss < Overall_Best_Val_Loss:\n",
    "            with open(loss_path, 'w') as f:\n",
    "                f.write('%f' % best_val_loss)\n",
    "\n",
    "            torch.save(Hydra_Bodys[0], body_save_path)\n",
    "            torch.save(General_Hydra_Heads[0], head_save_path)\n",
    "            for basin in basins:\n",
    "                torch.save(model_heads[0][basin], f\"{basin_heads_save_path}/{basin}.path\")\n",
    "                \n",
    "            \n",
    "               \n",
    "        ray.train.report({'val_loss' : best_val_loss})\n",
    "        #print('Validation Loss', val_losses)\n",
    "        #print('Training Loss', general_losses/train_climate_loss )\n",
    "        #print(candidate_val_loss)\n",
    "        val_losses.append(candidate_val_loss)\n",
    "\n",
    "    return best_val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 12:10:56,736\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)  \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(static_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='val_loss',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=20,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "\n",
    "plateau_stopper = TrialPlateauStopper(\n",
    "    metric=\"val_loss\",\n",
    "    num_results = 100,\n",
    "    grace_period=20,\n",
    "    mode=\"min\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-06-12 13:51:20</td></tr>\n",
       "<tr><td>Running for: </td><td>01:40:13.76        </td></tr>\n",
       "<tr><td>Memory:      </td><td>36.7/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.25/16 CPUs, 0.08333333333333333/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status    </th><th>loc                   </th><th style=\"text-align: right;\">  batch_size</th><th>bidirectional  </th><th style=\"text-align: right;\">  body_dropout</th><th style=\"text-align: right;\">  body_hidden_size</th><th style=\"text-align: right;\">  body_learning_rate</th><th style=\"text-align: right;\">  body_num_layer</th><th style=\"text-align: right;\">  body_output</th><th style=\"text-align: right;\">  head_dropout</th><th style=\"text-align: right;\">  head_hidden_size</th><th style=\"text-align: right;\">  head_learning_rate</th><th style=\"text-align: right;\">  head_num_layer</th><th style=\"text-align: right;\">  spec_multiplier</th><th style=\"text-align: right;\">  test_year</th><th style=\"text-align: right;\">  warmup</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_d8d20_00000</td><td>TERMINATED</td><td>136.156.133.98:1464642</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2000</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5979.72</td><td style=\"text-align: right;\"> -0.701211</td></tr>\n",
       "<tr><td>objective_d8d20_00001</td><td>TERMINATED</td><td>136.156.133.98:1464755</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2002</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         6003.13</td><td style=\"text-align: right;\"> -0.576024</td></tr>\n",
       "<tr><td>objective_d8d20_00002</td><td>TERMINATED</td><td>136.156.133.98:1464764</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2004</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   188</td><td style=\"text-align: right;\">         5514.42</td><td style=\"text-align: right;\"> -0.55342 </td></tr>\n",
       "<tr><td>objective_d8d20_00003</td><td>TERMINATED</td><td>136.156.133.98:1464771</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2006</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   143</td><td style=\"text-align: right;\">         4592.72</td><td style=\"text-align: right;\"> -0.563158</td></tr>\n",
       "<tr><td>objective_d8d20_00004</td><td>TERMINATED</td><td>136.156.133.98:1464786</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2008</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5932.31</td><td style=\"text-align: right;\"> -0.599275</td></tr>\n",
       "<tr><td>objective_d8d20_00005</td><td>TERMINATED</td><td>136.156.133.98:1464791</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2010</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5791.21</td><td style=\"text-align: right;\"> -0.50289 </td></tr>\n",
       "<tr><td>objective_d8d20_00006</td><td>TERMINATED</td><td>136.156.133.98:1464796</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2012</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         6004.36</td><td style=\"text-align: right;\"> -0.546107</td></tr>\n",
       "<tr><td>objective_d8d20_00007</td><td>TERMINATED</td><td>136.156.133.98:1464797</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2014</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5977.76</td><td style=\"text-align: right;\"> -0.538172</td></tr>\n",
       "<tr><td>objective_d8d20_00008</td><td>TERMINATED</td><td>136.156.133.98:1464806</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2016</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         5802.96</td><td style=\"text-align: right;\"> -0.545155</td></tr>\n",
       "<tr><td>objective_d8d20_00009</td><td>TERMINATED</td><td>136.156.133.98:1464807</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2018</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         6008.18</td><td style=\"text-align: right;\"> -0.535667</td></tr>\n",
       "<tr><td>objective_d8d20_00010</td><td>TERMINATED</td><td>136.156.133.98:1464808</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2020</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   171</td><td style=\"text-align: right;\">         5071.62</td><td style=\"text-align: right;\"> -0.517608</td></tr>\n",
       "<tr><td>objective_d8d20_00011</td><td>TERMINATED</td><td>136.156.133.98:1464813</td><td style=\"text-align: right;\">         256</td><td>False          </td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">               128</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">                0.01</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">              0.5</td><td style=\"text-align: right;\">       2022</td><td style=\"text-align: right;\">       5</td><td style=\"text-align: right;\">   201</td><td style=\"text-align: right;\">         6002.32</td><td style=\"text-align: right;\"> -0.573673</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=1464764)\u001b[0m /home/gbmc/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.16285161221881664\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.1733374092708777\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.1951683893027131\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.10865385759322024\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.17113077357434778\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.16126042722810627\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.25523140579377734\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.0871495803893476\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.19898864629234267\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.17567766926766817\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.17741306868127085\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.16118262604667097\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.1752926255681611\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.22522510943502144\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3040199298095212\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.16574634268440436\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.1561727789965054\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.16286789381357847\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.19468018043952878\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.29666393367834687\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.19384255913411555\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.36426817728530075\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.24396262168374433\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.22179521533756152\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.21255368522752538\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.2054422392276505\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.21691108322326316\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.17818616253171568\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.3446816217376655\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.2839926903504256\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.10936083979790064\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.22363429959355607\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.16755751296829227\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.3506386869021932\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.33141637279418285\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.24219767127271227\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.2652282203092282\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3376377827179877\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.17183221065245338\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.34698494202703783\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.2536777836538175\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.1629850433268426\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3122195933490996\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3999788433609253\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.24304617756480887\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.17676874365731648\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.1382666627622746\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3387478226788755\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.21956376455026083\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.360597596945744\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.19657807359362198\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3018181216737116\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.24062911735086498\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.23095470654318184\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.28999769660808594\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.34908579773076953\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2545524774332843\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.24493585671840945\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.29889552819956733\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.23347470068473777\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3082969202496735\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.2761790150856512\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2855860701465517\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3756080214136701\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3863864534530473\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2516986843443984\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.20728423206276675\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2908875798765378\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.38518104626126387\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3635490041973392\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.32666055654363896\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.3130294318842597\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.2685348640029204\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2843488242312099\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3145279000600528\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3805987477137106\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.37460886522202397\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.32200122045642804\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.2992898737490976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.23395185011642844\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.36803683014207056\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3165006896320644\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.35436161049281617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3534541144413366\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.31988943899488453\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.27371344354880445\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.34382927284613907\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.26433386646075485\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.24481028455789533\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3960223130075031\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.42766493408122813\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.2836752005859938\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.18092114661771216\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.266797613464963\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2928241915224499\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.28984400636974467\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.2528930477598664\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2963535482866561\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.31483186174764544\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.30402079836804974\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.34004134784137935\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3423132450935388\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.19377398916157987\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.25175852726565223\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.31106370352670976\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.2926562124501957\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.16188328020264298\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3890780543314855\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3974808920083082\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.41192715031797394\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.2760153619693861\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3146447167656261\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.2909775651467769\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.37717242810610535\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.39035612979130213\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.34769421823348345\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2929037105031719\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.2796668041976458\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3235154071320731\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3528399111146067\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3204900693713785\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3028150610773993\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3478498118012731\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.29344588583096776\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.31007298418523127\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3925803088939736\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2806449899555336\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.37459822843223545\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.32610101442532674\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3764934506160443\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.31064773717434513\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3126762147333393\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.42363444877143663\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.48805866387339053\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.3998885266463977\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.34646375766653525\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3635137999065361\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3976214561795171\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.23908886389999814\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.35377870323033117\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.245546263707587\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3572796837066862\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3014234661910917\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.33176632758227315\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4118283568918069\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3098776170420461\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3825715798617416\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.37696225810461537\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3372506822685507\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3055752659040689\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.33609344136376457\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4067222251286546\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.20449692711501366\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4293146976449687\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4135836291850342\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.35516712493658564\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.35134940255341596\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3183568307211808\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3967466796563195\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.47170273802227\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3027619416443753\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3632427053472626\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3447111788226472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4346415325342811\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.39554185951270865\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3580834502161183\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.300713246776505\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3631090304910882\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.34669028443137834\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2926157181379763\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.37852014730170525\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.38477012704993985\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4305952512510616\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.33204665305373476\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4264851501129811\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.38406240946115955\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.399644705111705\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3637977846795398\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3413219550532051\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.40104271126565516\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3589361799258801\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3599355061052472\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.45330639156707475\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.36334738884428003\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3736914832121822\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.49883819072488655\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3445052900884158\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3543449748462288\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.290844544642083\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.2761438010834398\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3473435908208271\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3816666315524128\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3623325072989511\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2687861964091133\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.35317089993256473\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.41281390925885175\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.33794238618051897\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.39393198161041915\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2839869601854689\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.4240747366916723\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5631583822358489\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3689293027427121\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3144758491552411\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3318479666842169\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.39389861534753584\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3762801138399299\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3990476544318614\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3170606040219269\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.327737490351845\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3848161337079255\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3440596822283283\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.42054356187250214\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.30460375028464953\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.37214349222874493\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.2900994639937725\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.44081489751294844\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.41425665923067934\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.35958010541903435\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.40864618088201365\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2736493120784395\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.30382938663077375\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.32283684534093243\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3859077866321217\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4818374169592234\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.3038033991681116\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.16671378335912293\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3694076676788792\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4201077506234038\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.356421623388329\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.4002524541176739\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4250735672164045\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.44906025103213915\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.43358241936273983\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.38507271087334477\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.34015682570976163\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.39586145271901946\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.353327964758661\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.41252665645013464\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3714642867965025\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4050818564954127\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4467745693066587\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3856169789220212\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.35356124821707746\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.38611738250547073\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.40818340985541285\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4696565531084727\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3338796472079314\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3785273863276489\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.37611390508952075\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3385133408223091\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3910777693486571\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.417123590926158\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.43343536823426176\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.37907804190821714\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3349379848702788\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3540066031106851\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.47424176369683935\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4101906610848912\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.401145049179313\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.2767403767673426\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3422786525137469\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4230041543970146\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.29275334624387583\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.3798332339952099\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3837078495584681\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.49324455028099984\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4192507976034533\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3732175305349385\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.41987438369777774\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.38591312633024993\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.17950260048976974\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5271594987414036\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3559474914373024\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.453508264254126\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.36425123064414844\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4408493004101588\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.4260294107061268\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4404192883318756\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4240751210093961\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.42555107897725913\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.47117748218652367\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4016577214389441\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.482759357452566\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4165007234799577\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.35679989853389255\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.47827037687380786\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2961584860055083\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.2921040357682672\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4336662864258841\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.515733343872803\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.34305720655825506\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.37764189664001047\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4249908237559035\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4265109123191479\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4035697813632274\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5032681133510618\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.48587843216052146\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3411026859316964\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.44668354885768985\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.450808412508939\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.33898389570162435\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.37736197077314493\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.42768153776460327\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.45486993150816324\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.42750897548696976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4540038511609158\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.47356618444160553\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m \n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.2857421622491979\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3786313684505467\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3688154352911265\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4093710496669491\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.34385295077173184\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.35800193231794836\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.24251014592943018\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4822648627755842\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3832844535739075\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4364564319412385\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.40265210264742457\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3952323179807621\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3880175443170341\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4431286143114101\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.38373722292597895\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5306603529970775\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3880390352473418\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.3867917514759451\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.44644202977420466\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.44094627869405273\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.42627144604795025\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3031699318298334\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.42750511634581057\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.47701828555454623\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.39154411025900027\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.33481353167621875\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4300408637491011\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.45344541173481595\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.39647672771217624\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.29087387309983836\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4249840866141936\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4068145872916508\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4369297950636306\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4174824048724026\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.48445014766861466\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3673112390831919\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4760853680055555\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.3829511253647622\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3058627494051727\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3998399388435863\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4173697654240643\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.37711196048458223\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3852324067509963\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2795620665562963\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3990204372840396\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.40334182351615655\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.42820446609721735\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.31681728295082057\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.35457614636580687\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.33231647487048666\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.45909089212774706\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4277675247544684\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.38797271309616527\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4286383566786866\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3217563354933847\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4106980546872557\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3210476788442621\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.41333563008115176\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.3578462698514356\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.38919893054619653\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.34266679240051146\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4377844929607122\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.37477674429892016\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3298928589883417\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.2917167498288581\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4000918267520771\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.32878539202048723\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3417593820039643\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4278109753880415\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.425598139189768\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4550207410664191\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.41792368360840876\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4891982896993341\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.40571045078178775\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.39673128508637207\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4448738379541985\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.41643359271834535\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5000725516273514\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4400813060113619\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.46949182975506054\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3468802951502294\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4702750735606598\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.40388829511336993\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3592530742532744\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3995205118728986\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4236559027756129\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.357029575713527\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.25969234595093665\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3661682996272549\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.42264906703236066\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4207187941203039\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3992353488101073\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4966897943949313\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4862864320857317\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4095653137844623\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3152245455760653\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.40247121193451374\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3622220626168688\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4475504118014842\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4844737821883837\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.412961529101505\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4318591861455895\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3806209129193698\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.45147719909324885\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.48341942465643967\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.48522091537109896\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.474987113086412\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.30385474233941223\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3850110830532036\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.41396032300294405\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4369571800439315\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.488593534636061\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3896321807711243\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4560796309908636\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4236689923045898\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.5069317389474697\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3764064142856713\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.42946730491292406\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.3801511070603771\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.5103095600831322\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.30276817745049384\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.34708179135608797\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.38564932102620747\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.41036671766341615\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3286597202335236\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4304612093863067\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3956289267432045\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.39201382751609837\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.26613250871674904\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3328546874235448\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3794501103986755\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.47082624990733934\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.44132068514214406\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.46456572380208605\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.35412412536706084\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5419566373119525\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.34096308294810895\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.38058619686256867\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.33102976073005197\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4892308327198194\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4496706041404952\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.38999453930074274\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.43427222899960927\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4315500076816625\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4394565710635604\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.34113308426447997\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.38315450311246296\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.43143295947184546\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.40851328302262907\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.27156887015186043\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.34627760728655776\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.48734961708873314\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4522489664688162\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.39458448528055423\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2861120604000283\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.46573458140229346\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5057852492825521\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4145178779477412\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.46445160638028093\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3871947138004691\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.477716833352176\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.38896022973530314\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4777087801221094\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.38411543009805266\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.355094184751663\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4624020881511576\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.499684251136827\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4462090172792133\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4529267317560972\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.384990925488791\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.43467901530813774\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4325372939794144\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.45290664388370194\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4224491337665174\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.32688935740818226\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.31608561896271703\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3657310810219628\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4010049413704486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4459462209689128\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.44343267077187015\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.42229759090614066\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4933016513004792\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.42471096312121814\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4552270725913212\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4206846361075456\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5227642685963725\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.44933504509820876\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4748695721626233\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.45933821179776513\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4191565664881384\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.43869788066915677\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.38228362578557756\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.506202008583889\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4489455068732377\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.42003755146876426\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.42150607328359263\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4114429302878607\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4616504249007626\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.281333068582537\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2520492277667022\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.5111149973061705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.39114238520968336\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3693551126900673\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.43788622309153363\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.3773666146258357\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5335586134230271\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.30035085797605265\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4097763832597401\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4484339905069153\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.501810132930265\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4585144588925874\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.24260181772904024\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4358440592030735\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.44407172709374765\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3914470037043897\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4161563831388258\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4287080932824981\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.45643831721506517\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.36769059024540685\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.36914614907114385\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.49747998782255987\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.31896743192539173\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.41950807928314976\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.536392397058656\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.32878570124183476\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.33099511287871447\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5946371184916288\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4808208322077923\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.36326455842380323\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.42369949437681953\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.42315846882219726\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.38820052240005987\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2814547818915221\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2195886608246138\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4398546376446152\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.47129867478070214\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.48118387140667557\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.26482219837795046\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.41094542171590576\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.43511494577397336\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.48073268943294456\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.45904383653343656\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5543698082573035\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.45738713921911195\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4347387657785263\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4927453638467357\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.47563557528033823\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3939635758270991\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4720292701869089\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3999129431561617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.3552652838904859\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.36132314703387214\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.48727501077668867\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.37726514901091013\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.47948589825052595\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4130261202684184\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.45228167613291503\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.27379119297790333\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.42948627380575594\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.40498969226688314\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.467018957559243\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3401921954307233\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.49728341195695663\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.26392084510156066\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4536303587436384\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.46515716669404605\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.48844556015262464\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.23987059041776151\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.43956527643741167\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.5110601757526085\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4998144720335012\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.388486608689865\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.46641894497523784\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.41622154749395573\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.49219005606002797\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3997969118846578\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.486188520710372\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4306007735447588\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5130737208617839\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5736728302593965\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.43076572527722523\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4431572692488829\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.40842373848443386\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.3173577893332566\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4928352646145089\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.35624474642172593\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.41422544834092395\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.48977198533480903\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.48441699079550726\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4278703057090539\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3520383803327201\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.452708275699128\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.46490570833223344\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5640375481943298\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3486284837582142\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.2967581264373076\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4063451974643357\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4378527993825009\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3782702369936705\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.30134934417148823\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5325964364599834\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.44322122766302136\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.47498018124821506\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.38539605151040285\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.29474205261116415\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.5352682516175113\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.40834989478809547\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.34226706539462737\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.46567382000021057\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.35697682799015407\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.4687304380404509\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.38690016281520656\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3565829842026217\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5508528234768029\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.38209450315356164\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464771)\u001b[0m -0.48705394949390574\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4110698506319366\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.45255528775451626\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4396789637238829\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4905253879108421\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.49313680300278573\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4890220108420369\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.41636901357775724\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.5176075588101772\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3895019281177753\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.49396635688366985\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.373106441735159\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4704875668447536\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.43165415090418924\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.39100035184508886\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.43123949031851283\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.46642375286343213\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.26075729921842256\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4708527302604674\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4387891003042382\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4882130041868595\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.4905788354612233\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.36384287387062325\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3839336653694224\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.27571631779360173\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4451317468871242\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.49626151964689524\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.45519894986297504\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.46059590740161166\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4464002001472301\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.431908247903253\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3929052218811138\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.27803087187149644\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5160538277535517\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.38220507750247745\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.4573656234202546\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.42731734252870274\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.1465260311992583\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.47739813931369773\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4198976138574973\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.45809500252773333\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.32629691254337195\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.33783687638785775\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4701601483922985\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.30637381266909347\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.4879640448626339\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4744702047721477\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.45054168455204185\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4110792587728495\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.5036824293513634\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.49139047931997415\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5019615606321611\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.37974863574132234\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.5217007664070621\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3746419875418331\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.47685601040465464\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.41579960418576056\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.47927167970569523\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.34037586437349676\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3393770922098029\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5548389066129091\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.38714134350548707\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.44419062943725895\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.4649581695458145\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3898545448522911\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464808)\u001b[0m -0.36381898135936336\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.23191808768112052\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.41503813049359933\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m 0.014080332246673825\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.44491643723272883\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.416022549212453\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4150969504606761\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.3151026136680901\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.42321948091318334\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.23699997506645168\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.41432685934615704\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5668741764672764\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4570924674390144\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4214525172660734\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4696010487406068\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.352912920418856\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.37830830646085767\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.37357916766196053\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.49833838105942696\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.507611327688619\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.35485481873064706\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4613013640108973\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.42024072159104553\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.36499489070303237\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.49159835031013105\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4062253022374956\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4250161721758872\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.43523595151865285\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3999530880502838\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3920572785261055\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3682008092732946\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5533791856835004\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.38967274504752064\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.45820399963298836\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4207169778975689\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.49560402194436204\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.37786305200249537\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.48887240909096685\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.3062515732698032\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.4443877729003336\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5102396615169665\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4561950268250671\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.47993139543336116\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.48899263968905393\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.44678221745679886\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5147726688917158\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.39231523358124704\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.38081706447824754\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4642233938577107\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.41252478640651086\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5063904993306821\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4099270975057791\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3619056520693112\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.40742161453176806\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4394434858008323\n",
      "\u001b[36m(objective pid=1464764)\u001b[0m -0.49629899292504576\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.44905187859101847\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.24361587859274306\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4603496633262006\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.41169198689102904\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3850177410070325\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3478142865207105\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4901254955553669\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.47338770622281745\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.37210036288449166\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.38433011681137763\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.425171133211255\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464797)\u001b[0m -0.4956242606433596\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.49113264979878984\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.5197924291490439\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.3471638366878963\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.35763557425368847\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.477040235407317\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4310530915009309\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.39004972128333265\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4052872521407505\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.57462404614687\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4762414180430978\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.42142269200812615\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4493834815319268\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4089865378033061\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.27338146781101413\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.47003802204667383\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.3654056435749911\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.45603535892598385\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.5166732047541363\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5100992885000302\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3811456511641672\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.39685527597039605\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.5188364698361784\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.495244059255889\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4119656770147117\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.44419488188717204\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.2269370903541219\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.48505152843624033\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.6410005387050837\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4493531056315391\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4921335906773507\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464786)\u001b[0m -0.5222910656065715\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.42716008568357744\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.4336297638876791\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.40107928880160426\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5042808497127561\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.48250128951712157\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3981108835145587\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.5286533368640235\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4385226628348535\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.46730009029941744\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.5204288985411685\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.4501068749024838\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.3696442503322655\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5467830789344964\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.3851312695348497\n",
      "\u001b[36m(objective pid=1464642)\u001b[0m -0.5202869669400451\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.46821393202541123\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.3536201206185353\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464796)\u001b[0m -0.4281050162335673\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464791)\u001b[0m -0.5028900981699381\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4105061177802659\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464806)\u001b[0m -0.5157415836646374\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5193830203358805\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.512034439298953\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4336410355877204\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.487136152987428\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.5356665928460583\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.5040833754980019\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4018895787709\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4282266773179574\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.36858133732717985\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4613567861910875\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.515960875897822\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.509919025357388\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5081102623881503\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.5129111759987304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.478946372846359\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.53313539476351\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.46508808215387965\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3859351427048294\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5561226454343497\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.5300857739667784\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.48681402453177974\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4442109760171609\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.3779477399526476\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.3658300767785697\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5193586349579887\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.39659265833127183\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4079975243932673\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4128164733846918\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.4128829621959427\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464813)\u001b[0m -0.4654453566286741\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.5760244372192778\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.5010060798544868\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4776424360061193\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.45919359980177626\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464755)\u001b[0m -0.4578610946190347\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(objective pid=1464807)\u001b[0m -0.40491700874268133\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:27:44,713\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '77ade844')}\n",
      "2024-06-12 13:35:43,672\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', 'd0c36a7a')}\n",
      "2024-06-12 13:43:06,251\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', 'd31ea24e')}\n",
      "2024-06-12 13:47:43,532\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '80f16ada')}\n",
      "2024-06-12 13:47:54,946\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '1f98018a')}\n",
      "2024-06-12 13:50:04,229\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '5a92826b')}\n",
      "2024-06-12 13:50:50,097\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '56d80434')}\n",
      "2024-06-12 13:50:51,910\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '52467d93')}\n",
      "2024-06-12 13:51:14,280\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', 'de5d0d51')}\n",
      "2024-06-12 13:51:15,270\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '6269ca81')}\n",
      "2024-06-12 13:51:17,091\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '34b3c1e4')}\n",
      "2024-06-12 13:51:20,619\tINFO tensorboardx.py:275 -- Removed the following hyperparameter values when logging to tensorboard: {'test_year': ('__ref_ph', '93632d75')}\n",
      "2024-06-12 13:51:20,636\tINFO tune.py:1042 -- Total run time: 6013.78 seconds (6013.75 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body_hidden_size': 128, 'body_num_layer': 1, 'body_dropout': 0.0, 'bidirectional': False, 'body_output': 4, 'body_learning_rate': 0.001, 'head_hidden_size': 32, 'head_num_layer': 1, 'head_dropout': 0.0, 'head_learning_rate': 0.01, 'spec_multiplier': 0.5, 'batch_size': 256, 'test_year': 2000, 'warmup': 5}\n",
      "Best configuration saved to: /data/Hydra_Work/Tuning/Config_Text/Hydral_Model_best_config.txt\n"
     ]
    }
   ],
   "source": [
    "runs_per_iteration = 12\n",
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "\n",
    "    score = train_model_hydra(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "\n",
    "run_config=train.RunConfig(stop= plateau_stopper)\n",
    "# Can use fractions of GPU\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 15/runs_per_iteration, \"gpu\": 1/(runs_per_iteration)}), param_space=config_space, run_config = run_config) \n",
    "\n",
    "results = tuner.fit()\n",
    "best_config = results.get_best_result(metric=\"val_loss\", mode=\"min\").config\n",
    "print(best_config)\n",
    "file_path = f\"/data/Hydra_Work/Tuning/Config_Text/Hydral_Model_best_config.txt\"\n",
    "\n",
    "# Open the file in write mode and save the configuration\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(str(best_config))\n",
    "\n",
    "print(\"Best configuration saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[results_df['val_loss'] < -0.1]#[['val_loss', 'config/body_output']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hydra_Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
