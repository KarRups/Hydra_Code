{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/Hydra_Work/Competition_Functions') \n",
    "from Processing_Functions import process_forecast_date, process_seasonal_forecasts\n",
    "from Data_Transforming import read_nested_csvs, generate_daily_flow, use_USGS_flow_data, USGS_to_daily_df_yearly\n",
    "\n",
    "sys.path.append('/data/Hydra_Work/Pipeline_Functions')\n",
    "from Folder_Work import filter_rows_by_year, csv_dictionary, add_day_of_year_column\n",
    "\n",
    "sys.path.append('/data/Hydra_Work/Post_Rodeo_Work/ML_Functions.py')\n",
    "from Full_LSTM_ML_Functions import Specific_Heads, Google_Model_Block, SumPinballLoss, EarlyStopper, Model_Run, No_Body_Model_Run\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydra_Code\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "def get_env():\n",
    "    sp = sys.path[1].split(\"/\")\n",
    "    if \"envs\" in sp:\n",
    "        return sp[sp.index(\"envs\") + 1]\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "print(get_env())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHELL: /bin/bash\n",
      "IP_INTERNAL: 136.156.133.98\n",
      "CONDA_EXE: /home/gbmc/miniforge3/bin/conda\n",
      "_CE_M: \n",
      "INSTANCE_HOSTNAME: floodrodeo\n",
      "XML_CATALOG_FILES: file:///home/gbmc/miniforge3/envs/Hydra_Code/etc/xml/catalog file:///etc/xml/catalog\n",
      "PWD: /home/gbmc\n",
      "LOGNAME: gbmc\n",
      "XDG_SESSION_TYPE: tty\n",
      "CONDA_PREFIX: /home/gbmc/miniforge3/envs/Hydra_Code\n",
      "MOTD_SHOWN: pam\n",
      "HOME: /home/gbmc\n",
      "LANG: C.UTF-8\n",
      "SSL_CERT_DIR: /etc/pki/tls/certs\n",
      "CONDA_PROMPT_MODIFIER: (Hydra_Code) \n",
      "VSCODE_AGENT_FOLDER: /home/gbmc/.vscode-server\n",
      "SSH_CONNECTION: 86.136.213.73 51810 136.156.133.98 22\n",
      "HOST_INTERNAL: container358047\n",
      "XDG_SESSION_CLASS: user\n",
      "SELINUX_ROLE_REQUESTED: \n",
      "_CE_CONDA: \n",
      "LESSOPEN: ||/usr/bin/lesspipe.sh %s\n",
      "USER: gbmc\n",
      "CONDA_SHLVL: 2\n",
      "SELINUX_USE_CURRENT_RANGE: \n",
      "SHLVL: 2\n",
      "XDG_SESSION_ID: 234\n",
      "HOST_EXTERNAL: floodrodeo\n",
      "CONDA_PYTHON_EXE: /home/gbmc/miniforge3/bin/python\n",
      "XDG_RUNTIME_DIR: /run/user/1000\n",
      "SSL_CERT_FILE: /etc/pki/ca-trust/extracted/pem/tls-ca-bundle.pem\n",
      "SSH_CLIENT: 86.136.213.73 51810 22\n",
      "CONDA_DEFAULT_ENV: Hydra_Code\n",
      "DEBUGINFOD_URLS: https://debuginfod.centos.org/ \n",
      "VSCODE_CLI_REQUIRE_TOKEN: 98458fa3-18cf-44fc-9678-37f7fdc5db72\n",
      "which_declare: declare -f\n",
      "XDG_DATA_DIRS: /home/gbmc/.local/share/flatpak/exports/share:/var/lib/flatpak/exports/share:/usr/local/share:/usr/share\n",
      "PATH: /home/gbmc/miniforge3/envs/Hydra_Code/bin:/home/gbmc/.vscode-server/cli/servers/Stable-e170252f762678dec6ca2cc69aba1570769a5d39/server/bin/remote-cli:/home/gbmc/miniforge3/envs/Hydra_Code/bin:/home/gbmc/miniforge3/condabin:/home/gbmc/.local/bin:/home/gbmc/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin\n",
      "SELINUX_LEVEL_REQUESTED: \n",
      "DBUS_SESSION_BUS_ADDRESS: unix:path=/run/user/1000/bus\n",
      "IP_PUBLIC: 136.156.133.98\n",
      "BASH_FUNC_which%%: () {  ( alias;\n",
      " eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot $@\n",
      "}\n",
      "_: /home/gbmc/miniforge3/envs/Hydra_Code/bin/python\n",
      "VSCODE_HANDLES_SIGPIPE: true\n",
      "HISTCONTROL: ignoredups\n",
      "HISTSIZE: 1000\n",
      "HOSTNAME: floodrodeo.novalocal\n",
      "MAIL: /var/spool/mail/gbmc\n",
      "VSCODE_AMD_ENTRYPOINT: vs/workbench/api/node/extensionHostProcess\n",
      "VSCODE_HANDLES_UNCAUGHT_ERRORS: true\n",
      "VSCODE_NLS_CONFIG: {\"locale\":\"en\",\"osLocale\":\"en\",\"availableLanguages\":{}}\n",
      "BROWSER: /home/gbmc/.vscode-server/cli/servers/Stable-e170252f762678dec6ca2cc69aba1570769a5d39/server/bin/helpers/browser.sh\n",
      "VSCODE_CWD: /home/gbmc\n",
      "ELECTRON_RUN_AS_NODE: 1\n",
      "VSCODE_IPC_HOOK_CLI: /run/user/1000/vscode-ipc-429b4d24-222b-4e6e-8c50-6fcded4269d1.sock\n",
      "APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL: 1\n",
      "PYTHONUNBUFFERED: 1\n",
      "CONDA_MKL_INTERFACE_LAYER_BACKUP: \n",
      "GSETTINGS_SCHEMA_DIR: /home/gbmc/miniforge3/envs/Hydra_Code/share/glib-2.0/schemas\n",
      "CONDA_ROOT: /home/gbmc/miniforge3\n",
      "GSETTINGS_SCHEMA_DIR_CONDA_BACKUP: \n",
      "PYTHONIOENCODING: utf-8\n",
      "CONDA_PREFIX_1: /home/gbmc/miniforge3\n",
      "MKL_INTERFACE_LAYER: LP64,GNU\n",
      "PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING: 1\n",
      "PYDEVD_USE_FRAME_EVAL: NO\n",
      "TERM: xterm-color\n",
      "CLICOLOR: 1\n",
      "FORCE_COLOR: 1\n",
      "CLICOLOR_FORCE: 1\n",
      "PAGER: cat\n",
      "GIT_PAGER: cat\n",
      "MPLBACKEND: module://matplotlib_inline.backend_inline\n",
      "KMP_INIT_AT_FORK: FALSE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get a dictionary containing all environment variables\n",
    "env_vars = os.environ\n",
    "\n",
    "# Print each environment variable and its value\n",
    "for var, val in env_vars.items():\n",
    "    print(f\"{var}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the prep\n",
    "monthly_basins = ['animas_r_at_durango', 'boise_r_nr_boise', 'boysen_reservoir_inflow', 'colville_r_at_kettle_falls', 'detroit_lake_inflow', 'dillon_reservoir_inflow',\n",
    "    'fontenelle_reservoir_inflow', 'green_r_bl_howard_a_hanson_dam', 'hungry_horse_reservoir_inflow', 'libby_reservoir_inflow',\n",
    "    'missouri_r_at_toston','owyhee_r_bl_owyhee_dam', 'pecos_r_nr_pecos', 'pueblo_reservoir_inflow',\n",
    "    'ruedi_reservoir_inflow', 'skagit_ross_reservoir', 'snake_r_nr_heise', 'stehekin_r_at_stehekin', 'sweetwater_r_nr_alcova',\n",
    "    'taylor_park_reservoir_inflow', 'virgin_r_at_virtin', 'weber_r_nr_oakley', 'yampa_r_nr_maybell',\n",
    "]\n",
    "\n",
    "\n",
    "USGS_basins = ['animas_r_at_durango', 'boise_r_nr_boise', 'boysen_reservoir_inflow', 'colville_r_at_kettle_falls', 'detroit_lake_inflow', 'dillon_reservoir_inflow',   \n",
    "    'green_r_bl_howard_a_hanson_dam', 'hungry_horse_reservoir_inflow', 'libby_reservoir_inflow', 'merced_river_yosemite_at_pohono_bridge', 'missouri_r_at_toston',\n",
    "    'owyhee_r_bl_owyhee_dam', 'pecos_r_nr_pecos', 'pueblo_reservoir_inflow',    'san_joaquin_river_millerton_reservoir', 'snake_r_nr_heise', 'stehekin_r_at_stehekin',\n",
    "    'sweetwater_r_nr_alcova', 'taylor_park_reservoir_inflow', 'virgin_r_at_virtin', 'weber_r_nr_oakley', 'yampa_r_nr_maybell',\n",
    "]\n",
    "\n",
    "basins = list(set(monthly_basins + USGS_basins))\n",
    "\n",
    "\n",
    "selected_years = range(2000,2024,2)\n",
    "\n",
    "era5_folder = '/data/Hydra_Work/Rodeo_Data/era5'\n",
    "era5 = csv_dictionary(era5_folder, basins, years=selected_years)\n",
    "era5 = add_day_of_year_column(era5)\n",
    "\n",
    "flow_folder = '/data/Hydra_Work/Rodeo_Data/train_monthly_naturalized_flow'\n",
    "flow = csv_dictionary(flow_folder, monthly_basins)\n",
    "flow = filter_rows_by_year(flow, 1998)\n",
    "\n",
    "climatology_file_path = '/data/Hydra_Work/Rodeo_Data/climate_indices.csv'\n",
    "climate_indices = pd.read_csv(climatology_file_path)\n",
    "climate_indices['date'] = pd.to_datetime(climate_indices['date'])\n",
    "climate_indices.set_index('date', inplace = True)\n",
    "climate_indices.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "climate_indices = climate_indices[~climate_indices.index.duplicated(keep='first')]\n",
    "\n",
    "root_folder = '/data/Hydra_Work/Rodeo_Data/seasonal_forecasts'\n",
    "seasonal_forecasts = read_nested_csvs(root_folder)\n",
    "\n",
    "USGS_flow_folder = '/data/Hydra_Work/Rodeo_Data/USGS_streamflows'\n",
    "USGS_flow = csv_dictionary(USGS_flow_folder, USGS_basins)\n",
    "\n",
    "Static_variables = pd.read_csv('/data/Hydra_Work/Rodeo_Data/static_indices.csv', index_col= 'site_id')\n",
    "\n",
    "# Convert monthly flow values to daily flow estimates\n",
    "daily_flow = {}\n",
    "\n",
    "# Iterate through the dictionary and apply generate_daily_flow to each DataFrame\n",
    "for key, df in flow.items():\n",
    "    daily_flow[key] = generate_daily_flow(df, persistence_factor=0.7)\n",
    "\n",
    "# Replacing monhtly data for normalised USGS when available\n",
    "daily_flow = use_USGS_flow_data(daily_flow, USGS_flow)\n",
    "\n",
    "# Need to only do basins which have daily flow if we want to train this model for weekly\n",
    "normalising_basins = ['san_joaquin_river_millerton_reservoir', 'merced_river_yosemite_at_pohono_bridge', 'detroit_lake_inflow']\n",
    "for basin in normalising_basins:\n",
    "    path = f'/data/Hydra_Work/Rodeo_Data/USGS_streamflows/{basin}.csv' \n",
    "    normalising_path = f'/data/Hydra_Work/Rodeo_Data/train_yearly/{basin}.csv'\n",
    "    USGS_to_daily_df_yearly(daily_flow, path, basin, normalising_path)\n",
    "\n",
    "climate_scaler_filename = '/data/Hydra_Work/Rodeo_Data/scalers/climate_normalization_scaler.save'\n",
    "climate_scaler = joblib.load(climate_scaler_filename) \n",
    "climate_indices = pd.DataFrame(climate_scaler.transform(climate_indices), columns=climate_indices.columns, index=climate_indices.index)\n",
    "\n",
    "era5_scaler_filename = '/data/Hydra_Work/Rodeo_Data/scalers/era5_scaler.save'\n",
    "era5_scaler = joblib.load(era5_scaler_filename) \n",
    "era5 = {key: pd.DataFrame(era5_scaler.transform(df), columns=df.columns, index=df.index) for key, df in era5.items()}\n",
    "\n",
    "for basin, df in daily_flow.items(): \n",
    "    flow_scaler_filename = f'/data/Hydra_Work/Rodeo_Data/scalers/flows/{basin}_flow_scaler.save'\n",
    "    flow_scaler = joblib.load(flow_scaler_filename) \n",
    "    daily_flow[basin] = pd.DataFrame(flow_scaler.transform(df), columns=df.columns, index=df.index)\n",
    "\n",
    "seasonal_scaler_filename = \"/data/Hydra_Work/Rodeo_Data/scalers/seasonal_scaler.save\"\n",
    "seasonal_scaler = joblib.load(seasonal_scaler_filename)\n",
    "seasonal_forecasts = {key: pd.DataFrame(seasonal_scaler.transform(df), columns=df.columns, index=df.index ) for key, df in seasonal_forecasts.items()}\n",
    "\n",
    "static_scaler_filename = '/data/Hydra_Work/Rodeo_Data/scalers/static_scaler.save'\n",
    "static_scaler = joblib.load(static_scaler_filename) \n",
    "Static_variables = pd.DataFrame(static_scaler.transform(Static_variables), columns=Static_variables.columns, index=Static_variables.index)\n",
    "\n",
    "climatological_flows = {}\n",
    "\n",
    "for basin, df in daily_flow.items():\n",
    "    # Extract day of year and flow values\n",
    "    df['day_of_year'] = df.index.dayofyear\n",
    "\n",
    "    grouped = df.groupby('day_of_year')['daily_flow'].quantile([0.1, 0.5, 0.9]).unstack(level=1)\n",
    "\n",
    "    climatological_flows[basin] = pd.DataFrame({\n",
    "        'day_of_year': grouped.index,\n",
    "        '10th_percentile_flow': grouped[0.1],\n",
    "        '50th_percentile_flow': grouped[0.5],\n",
    "        '90th_percentile_flow': grouped[0.9]\n",
    "    })\n",
    "    \n",
    "    climatological_flows[basin].set_index('day_of_year', inplace=True)\n",
    "\n",
    "    # Drop the temporary 'day_of_year' column from the original dataframe\n",
    "    df.drop(columns='day_of_year', inplace=True)\n",
    "\n",
    "criterion = SumPinballLoss(quantiles = [0.1, 0.5, 0.9])\n",
    "\n",
    "basin = 'animas_r_at_durango' \n",
    "All_Dates = daily_flow[basin].index[\n",
    "    ((daily_flow[basin].index.month < 6) | ((daily_flow[basin].index.month == 6) & (daily_flow[basin].index.day < 24))) &\n",
    "    ((daily_flow[basin].index.year % 2 == 0) | ((daily_flow[basin].index.month > 10) | ((daily_flow[basin].index.month == 10) & (daily_flow[basin].index.day >= 1))))\n",
    "]\n",
    "All_Dates = All_Dates[All_Dates.year > 1998]\n",
    "\n",
    "\n",
    "# Validation Year\n",
    "Val_Dates = All_Dates[All_Dates.year >= 2020]\n",
    "All_Dates = All_Dates[All_Dates.year < 2020]\n",
    "\n",
    "\n",
    "basin_to_remove = 'sweetwater_r_nr_alcova'\n",
    "\n",
    "if basin_to_remove in basins:\n",
    "    basins.remove(basin_to_remove)\n",
    "\n",
    "\n",
    "seed = 42 ; torch.manual_seed(seed) ; random.seed(seed) ; np.random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "days  = 90\n",
    "hindcast_input_size = 17\n",
    "\n",
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 5*2\n",
    "\n",
    "head_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "head_output_size = 3\n",
    "\n",
    "# Only include daily flow basins\n",
    "basin = list(set(basins) - set(['ruedi_reservoir_inflow', 'skagit_ross_reservoir']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning individual basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 0  #5*2\n",
    "\n",
    "forecast_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n",
    "hindcast_input_size = 17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we want hindcast and forecast num-layers to be different?\n",
    "def define_models(hindcast_input_size, forecast_input_size, hidden_size, num_layers, dropout, bidirectional, learning_rate, copies = 3, forecast_output_size = 3, device = device):\n",
    "    models = {}\n",
    "    params_to_optimize = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    \n",
    "    hindcast_output_size = forecast_output_size\n",
    "    for copy in range(copies):\n",
    "        models[copy] = Google_Model_Block(hindcast_input_size, forecast_input_size, hindcast_output_size, forecast_output_size, hidden_size, num_layers, device, dropout, bidirectional)\n",
    "        \n",
    "        models[copy].to(device)\n",
    "        params_to_optimize[copy] = list(models[copy].parameters())\n",
    "        # Probably should be doing 1e-2 and 10\n",
    "        optimizers[copy] = torch.optim.Adam(params_to_optimize[copy], lr= learning_rate, weight_decay = 1e-2)\n",
    "        schedulers[copy] = lr_scheduler.CosineAnnealingLR(optimizers[copy], T_max=100)\n",
    "\n",
    "    return models, params_to_optimize, optimizers, schedulers\n",
    "\n",
    "def update_final_parameters(Final_Parameters, basin, min_val_loss_parameters, min_val_loss):\n",
    "    Final_Parameters['basin'].append(basin)\n",
    "    Final_Parameters['hidden_size'].append(min_val_loss_parameters[0])\n",
    "    Final_Parameters['num_layers'].append(min_val_loss_parameters[1])\n",
    "    Final_Parameters['dropout'].append(min_val_loss_parameters[2])\n",
    "    Final_Parameters['bidirectional'].append(min_val_loss_parameters[3])\n",
    "    Final_Parameters['learning_rate'].append(min_val_loss_parameters[4])\n",
    "    Final_Parameters['val_loss'].append(min_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Retrain_Basins = ['dillon_reservoir_inflow', 'stehekin_r_at_stehekin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "import optuna\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 15\n",
    "n_epochs = 1  # Epochs between tests\n",
    "group_lengths = [7] #np.arange(180) 7 Day ahead for streamlined version\n",
    "batch_size = 1\n",
    "copies = 3\n",
    "\n",
    "# parameters to tune\n",
    "hidden_sizes = [64, 128] # 64 converged upon\n",
    "num_layers =  [1, 3]\n",
    "dropout = [0.1]\n",
    "bidirectional = [False, True] #[True, False]\n",
    "learning_rate = [1e-3, 1e-4] #[1e-3, 1e-5]\n",
    "\n",
    "# Set up configuration space\n",
    "config_space = {\n",
    "\n",
    "    \"hidden_size\": tune.grid_search(hidden_sizes),\n",
    "    \"num_layers\": tune.grid_search(num_layers),\n",
    "    \"dropout\": tune.grid_search(dropout),\n",
    "    \"bidirectional\": tune.grid_search(bidirectional),\n",
    "    \"learning_rate\": tune.grid_search(learning_rate)\n",
    "    #,\"basin\":  tune.grid_search(Retrain_Basins)\n",
    "}\n",
    "\n",
    "# def define_optuna_search_space(trial: optuna.Trial):\n",
    "#     trial.suggest_categorical(\"hidden_size\", hidden_sizes)\n",
    "#     trial.suggest_categorical(\"num_layers\", num_layers)\n",
    "#     trial.suggest_categorical(\"dropout\", dropout)\n",
    "#     trial.suggest_categorical(\"bidirectional\", bidirectional)\n",
    "#     trial.suggest_categorical(\"learning_rate\", learning_rate)\n",
    "\n",
    "# optuna_config_space = {\n",
    "#     \"hidden_size\": tune.lograndint(16,128),\n",
    "#     \"num_layers\": tune.randint(1,3),\n",
    "#     \"dropout\": tune.uniform(0.1,0.7),\n",
    "#     \"bidirectional\": tune.choice(bidirectional),\n",
    "#     \"learning_rate\": tune.loguniform(1e-3, 1e-5)\n",
    "# }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    Val_Dates = ray.get(Val_Dates_id)  \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "    val_loss = 1000\n",
    "\n",
    "    #basin = config[\"basin\"]\n",
    "    copies = 3\n",
    "    save_path = f'/data/Hydra_Work/Tuning/Week_Ahead_Models/{basin}_specific.pth'\n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "    \n",
    "    models, params_to_optimize, optimizers, schedulers = define_models(hindcast_input_size, forecast_input_size,\n",
    "    config[\"hidden_size\"], config[\"num_layers\"], config[\"dropout\"],\n",
    "    config[\"bidirectional\"], config[\"learning_rate\"], copies=copies, device = device)\n",
    "\n",
    "\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        train_losses = {}\n",
    "        epoch_val_losses = {}\n",
    "\n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_losses[copy], Climate_Loss = No_Body_Model_Run(All_Dates, [basin], models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, specialised=False)\n",
    "            epoch_val_losses[copy], Climate_Loss = No_Body_Model_Run(Val_Dates, [basin], models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, specialised=False)\n",
    "\n",
    "        loss = np.mean(list(train_losses.values())) - Climate_Loss\n",
    "        \n",
    "\n",
    "        candidate_val_loss = ((np.mean(list(epoch_val_losses.values())).mean() - Climate_Loss)[0])/np.mean(Climate_Loss)\n",
    "        val_loss = np.min([val_loss, candidate_val_loss ])\n",
    "        if candidate_val_loss == val_loss:\n",
    "            torch.save(models[1], save_path)\n",
    "            \n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    return val_loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 08:20:15,334\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train, tune\n\u001b[1;32m      4\u001b[0m ray\u001b[38;5;241m.\u001b[39mshutdown()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_env\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv_vars\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m   \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPYTHONPATH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/Hydra_Work/Competition_Functions/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m All_Dates_id \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(All_Dates)  \n\u001b[1;32m      8\u001b[0m Val_Dates_id \u001b[38;5;241m=\u001b[39m ray\u001b[38;5;241m.\u001b[39mput(Val_Dates)  \n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/ray/_private/worker.py:1726\u001b[0m, in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, labels, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, **kwargs)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1724\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(info_str)\n\u001b[0;32m-> 1726\u001b[0m \u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_global_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_global_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_to_driver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_to_driver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver_object_store_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_driver_object_store_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjob_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_private\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_entrypoint_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_config \u001b[38;5;129;01mand\u001b[39;00m job_config\u001b[38;5;241m.\u001b[39mcode_search_path:\n\u001b[1;32m   1739\u001b[0m     global_worker\u001b[38;5;241m.\u001b[39mset_load_code_from_local(\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/ray/_private/worker.py:2342\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(node, session_name, mode, log_to_driver, worker, driver_object_store_memory, job_id, namespace, job_config, runtime_env_hash, startup_token, ray_debugger_external, entrypoint, worker_launch_time_ms, worker_launched_time_ms)\u001b[0m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2340\u001b[0m     logs_dir \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mget_logs_dir_path()\n\u001b[0;32m-> 2342\u001b[0m worker\u001b[38;5;241m.\u001b[39mcore_worker \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raylet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCoreWorker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplasma_store_socket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraylet_socket_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgcs_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogs_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_ip_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_manager_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraylet_ip_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLOCAL_MODE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stdout_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stderr_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserialized_job_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics_agent_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mruntime_env_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartup_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSCRIPT_MODE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker_launch_time_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker_launched_time_ms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;66;03m# Notify raylet that the core worker is ready.\u001b[39;00m\n\u001b[1;32m   2368\u001b[0m worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mnotify_raylet()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)  \n",
    "Val_Dates_id = ray.put(Val_Dates)  \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(Static_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_flow</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-01-01</th>\n",
       "      <td>-0.336803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-02</th>\n",
       "      <td>-0.308327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-03</th>\n",
       "      <td>-0.343824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-04</th>\n",
       "      <td>-0.370990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-01-05</th>\n",
       "      <td>-0.378567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26</th>\n",
       "      <td>1.113268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-27</th>\n",
       "      <td>1.113268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-28</th>\n",
       "      <td>1.113268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-29</th>\n",
       "      <td>1.120673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-30</th>\n",
       "      <td>1.120673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4282 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            daily_flow\n",
       "date                  \n",
       "1998-01-01   -0.336803\n",
       "1998-01-02   -0.308327\n",
       "1998-01-03   -0.343824\n",
       "1998-01-04   -0.370990\n",
       "1998-01-05   -0.378567\n",
       "...                ...\n",
       "2022-06-26    1.113268\n",
       "2022-06-27    1.113268\n",
       "2022-06-28    1.113268\n",
       "2022-06-29    1.120673\n",
       "2022-06-30    1.120673\n",
       "\n",
       "[4282 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='val_loss',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=2,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "\n",
    "plateau_stopper = TrialPlateauStopper(\n",
    "    metric=\"val_loss\",\n",
    "    num_results = 3,\n",
    "    grace_period=10,\n",
    "    mode=\"min\",\n",
    ")\n",
    "daily_flow['taylor_park_reservoir_inflow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-28 09:53:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:00.20        </td></tr>\n",
       "<tr><td>Memory:      </td><td>11.1/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 80.000: None | Iter 40.000: None | Iter 20.000: None | Iter 10.000: None<br>Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc  </th><th>bidirectional  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_2385b_00000</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00001</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00002</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00003</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00004</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00005</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00006</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00007</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           1</td></tr>\n",
       "<tr><td>objective_2385b_00008</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00009</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00010</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00011</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.001 </td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00012</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00013</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00014</td><td>PENDING </td><td>     </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "<tr><td>objective_2385b_00015</td><td>PENDING </td><td>     </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">         0.0001</td><td style=\"text-align: right;\">           3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=1652035)\u001b[0m /home/gbmc/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "\u001b[36m(objective pid=1652035)\u001b[0m   warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 09:54:00,799\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-04-28 09:54:10,857\tINFO tune.py:1042 -- Total run time: 53.00 seconds (42.92 seconds for the tuning loop).\n",
      "2024-04-28 09:54:10,859\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/gbmc/ray_results/objective_2024-04-28_09-53-17\", trainable=...)\n",
      "2024-04-28 09:54:10,867\tWARNING experiment_analysis.py:193 -- Failed to fetch metrics for 6 trial(s):\n",
      "- objective_2385b_00010: FileNotFoundError('Could not fetch metrics for objective_2385b_00010: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-28_09-53-17/objective_2385b_00010_10_bidirectional=False,dropout=0.1000,hidden_size=128,learning_rate=0.0010,num_layers=3_2024-04-28_09-53-17')\n",
      "- objective_2385b_00011: FileNotFoundError('Could not fetch metrics for objective_2385b_00011: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-28_09-53-17/objective_2385b_00011_11_bidirectional=True,dropout=0.1000,hidden_size=128,learning_rate=0.0010,num_layers=3_2024-04-28_09-53-17')\n",
      "- objective_2385b_00012: FileNotFoundError('Could not fetch metrics for objective_2385b_00012: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-28_09-53-17/objective_2385b_00012_12_bidirectional=False,dropout=0.1000,hidden_size=64,learning_rate=0.0001,num_layers=3_2024-04-28_09-53-17')\n",
      "- objective_2385b_00013: FileNotFoundError('Could not fetch metrics for objective_2385b_00013: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-28_09-53-17/objective_2385b_00013_13_bidirectional=True,dropout=0.1000,hidden_size=64,learning_rate=0.0001,num_layers=3_2024-04-28_09-53-17')\n",
      "- objective_2385b_00014: FileNotFoundError('Could not fetch metrics for objective_2385b_00014: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-28_09-53-17/objective_2385b_00014_14_bidirectional=False,dropout=0.1000,hidden_size=128,learning_rate=0.0001,num_layers=3_2024-04-28_09-53-17')\n",
      "- objective_2385b_00015: FileNotFoundError('Could not fetch metrics for objective_2385b_00015: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-28_09-53-17/objective_2385b_00015_15_bidirectional=True,dropout=0.1000,hidden_size=128,learning_rate=0.0001,num_layers=3_2024-04-28_09-53-17')\n",
      "2024-04-28 09:54:10,868\tWARNING experiment_analysis.py:584 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# With Optuna\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space = optuna_config_space, tune_config = optuna_tune_config, run_config = run_config) \u001b[39;00m\n\u001b[1;32m     36\u001b[0m results \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m---> 37\u001b[0m best_config \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_config)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Define the file path where you want to save the best configuration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/ray/tune/result_grid.py:162\u001b[0m, in \u001b[0;36mResultGrid.get_best_result\u001b[0;34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[0m\n\u001b[1;32m    151\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo best trial found for the given metric: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment_analysis\u001b[38;5;241m.\u001b[39mdefault_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis means that no trial has reported this metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    155\u001b[0m     )\n\u001b[1;32m    156\u001b[0m     error_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trial_to_result(best_trial)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No best trial found for the given metric: val_loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "# Stehekin gives :True\t0.4\t64\t0.001\t3 Even looking at overall min, and for animas r at durango\n",
    "# T-tests suggests: Bidirectional good, dropout unimportant, 16 bad, 64 vs 128 unimportant. All models that imrpvoed loss wre bidirectional\n",
    "# Libby seemed to want an single layer\n",
    "# San Joaqin is just hard, score of 9.4: {'hidden_size': 64, 'num_layers': 1, 'dropout': 0.4, 'bidirectional': False, 'learning_rate': 1e-05}\n",
    "\n",
    "\n",
    "\n",
    "# At weekly:\n",
    "# Animas has {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': False, 'learning_rate': 1e-05}, 64,3,0.1. Results for 64, 1, 0.1, True identical\n",
    "def objective(config):   \n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "    #print('Device available is', device)\n",
    "    \n",
    "\n",
    "    score = train_model(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "basin = 'stehekin_r_at_stehekin'\n",
    "\n",
    "#, search_alg = optuna_search\n",
    "optuna_tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "running_tune_config = tune.TuneConfig()\n",
    "\n",
    "run_config=train.RunConfig(stop= plateau_stopper)\n",
    "\n",
    "# Note using < 1gb per run stops pylance from crashing I think\n",
    "# Without Optun\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 14/16, \"gpu\": 1/10}), param_space=config_space, tune_config = tune_config, run_config = run_config) \n",
    "# With Optuna\n",
    "#tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space = optuna_config_space, tune_config = optuna_tune_config, run_config = run_config) \n",
    "\n",
    "results = tuner.fit()\n",
    "best_config = results.get_best_result(metric=\"val_loss\", mode=\"min\").config\n",
    "print(best_config)\n",
    "\n",
    "\n",
    "\n",
    "# Define the file path where you want to save the best configuration\n",
    "file_path = f\"/data/Hydra_Work/Tuning/Config_Text/{basin}_best_config.txt\"\n",
    "# Open the file in write mode and save the configuration\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(str(best_config))\n",
    "\n",
    "print(\"Best configuration saved to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: cd: /libstdc++: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cd libstdc++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['config/basin'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mget_dataframe()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresults_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m0.07\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig/basin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/pandas/core/frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['config/basin'] not in index\""
     ]
    }
   ],
   "source": [
    "#results_df = results.get_dataframe()\n",
    "#results_df[results_df['val_loss'] < -0.07][['val_loss', 'config/basin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Safe_Basins = list(results_df[results_df['val_loss'] < -0.07]['config/basin'].values)\n",
    "Retrain_Basins = list(set(Retrain_Basins) - set(Safe_Basins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: nan\n",
      "P-Value: nan\n",
      "The difference in mean val_loss is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "results_df = results.get_dataframe()\n",
    "columns_to_drop = ['timestamp', 'checkpoint_dir_name', 'done', 'training_iteration', \n",
    "                   'trial_id', 'date', 'time_this_iter_s', 'time_total_s', 'pid', \n",
    "                   'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore']\n",
    "\n",
    "# Drop the columns\n",
    "results_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "val_loss_bidirectional_true = results_df[results_df['config/num_layers'] == 3]['val_loss']\n",
    "val_loss_bidirectional_false = results_df[results_df['config/num_layers'] == 1]['val_loss']\n",
    "\n",
    "# Perform a t-test\n",
    "t_statistic, p_value = stats.ttest_ind(val_loss_bidirectional_true, val_loss_bidirectional_false)\n",
    "\n",
    "# Print the results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"P-Value:\", p_value)\n",
    "\n",
    "# Check if the difference in means is statistically significant\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in mean val_loss is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in mean val_loss is not statistically significant.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/Hydra_Work/Post_Rodeo_Work/Tuned_Single_Models/basin.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m Tuned_Models \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m basin \u001b[38;5;129;01min\u001b[39;00m basins:\n\u001b[0;32m----> 4\u001b[0m     Tuned_Models[basin] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/data/Hydra_Work/Post_Rodeo_Work/Tuned_Single_Models/basin.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniforge3/envs/Hydra_Code/lib/python3.11/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/Hydra_Work/Post_Rodeo_Work/Tuned_Single_Models/basin.pth'"
     ]
    }
   ],
   "source": [
    "# Loading models\n",
    "Tuned_Models = {}\n",
    "for basin in basins:\n",
    "    Tuned_Models[basin] = torch.load(f'/data/Hydra_Work/Post_Rodeo_Work/Tuned_Single_Models/basin.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning General Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 0 #5*2\n",
    "\n",
    "forecast_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_final_parameters_general(Final_Parameters, min_val_loss_parameters, min_val_loss):\n",
    "    Final_Parameters['hidden_size'].append(min_val_loss_parameters[0])\n",
    "    Final_Parameters['num_layers'].append(min_val_loss_parameters[1])\n",
    "    Final_Parameters['dropout'].append(min_val_loss_parameters[2])\n",
    "    Final_Parameters['bidirectional'].append(min_val_loss_parameters[3])\n",
    "    Final_Parameters['learning_rate'].append(min_val_loss_parameters[4])\n",
    "    Final_Parameters['val_loss'].append(min_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 15\n",
    "n_epochs = 1 # Epochs between tests\n",
    "group_lengths = np.arange(180)\n",
    "batch_size = 1\n",
    "copies = 2\n",
    "\n",
    "# parameters to tune\n",
    "# I tuned to 128,2,0.1,False,1e-3 \n",
    "hidden_sizes = [64, 128, 256]\n",
    "num_layers = [2,3]\n",
    "dropout = [0.1, 0.4]\n",
    "bidirectional =  [False,True]\n",
    "learning_rate = [1e-3, 1e-5]\n",
    "\n",
    "config_space = {\n",
    "    \"hidden_size\": tune.grid_search(hidden_sizes),\n",
    "    \"num_layers\": tune.grid_search(num_layers),\n",
    "    \"dropout\": tune.grid_search(dropout),\n",
    "    \"bidirectional\": tune.grid_search(bidirectional),\n",
    "    \"learning_rate\": tune.grid_search(learning_rate)\n",
    "}\n",
    "\n",
    "\n",
    "# Places to save info\n",
    "model_dir = '/data/Hydra_Work/Post_Rodeo_Work/Tuned_General_Model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_general(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    Val_Dates = ray.get(Val_Dates_id)  \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)\n",
    "\n",
    "    copies = 1\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "    \n",
    "    save_path = '/data/Hydra_Work/Tuning/Week_Ahead_Models/General_LSTM.pth'\n",
    "    val_loss = 1000\n",
    "     \n",
    "    models, params_to_optimize, optimizers, schedulers = define_models(hindcast_input_size, forecast_input_size,\n",
    "    config[\"hidden_size\"], config[\"num_layers\"], config[\"dropout\"],\n",
    "    config[\"bidirectional\"], config[\"learning_rate\"], copies=copies, device = device)\n",
    "\n",
    "    losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "\n",
    "        train_losses = {}\n",
    "        epoch_val_losses = {}\n",
    "\n",
    "        for copy in range(copies):\n",
    "\n",
    "             # Need to fix the outputs of No_Body_Model_Run\n",
    "            train_losses[copy], Climate_Loss = No_Body_Model_Run(All_Dates, basins, models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, specialised=False)\n",
    "            epoch_val_losses[copy], Climate_Loss = No_Body_Model_Run(Val_Dates, basins, models[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, specialised=False)\n",
    "\n",
    "        loss = np.mean(list(train_losses.values())) - Climate_Loss\n",
    "\n",
    "\n",
    "        candidate_val_loss = ((np.mean(list(epoch_val_losses.values())).mean() - Climate_Loss)[0])/np.mean(Climate_Loss)\n",
    "        val_loss = np.min([val_loss, candidate_val_loss ])\n",
    "         \n",
    "        #if candidate_val_loss == val_loss:\n",
    "        #    torch.save(models[0], save_path)\n",
    "               \n",
    "        ray.train.report({'val_loss' : val_loss})\n",
    "\n",
    "        losses.append(loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "\n",
    "    return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 23:06:47,710\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)  \n",
    "Val_Dates_id = ray.put(Val_Dates)  \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(Static_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='val_loss',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=4,\n",
    "    reduction_factor=2,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "\n",
    "plateau_stopper = TrialPlateauStopper(\n",
    "    metric=\"val_loss\",\n",
    "    num_results = 4,\n",
    "    grace_period=4,\n",
    "    mode=\"min\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-25 23:12:28</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:26.57        </td></tr>\n",
       "<tr><td>Memory:      </td><td>73.0/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None<br>Logical resource usage: 15.9375/16 CPUs, 0.7083333333333331/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                   </th><th>bidirectional  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  hidden_size</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_8685f_00000</td><td>RUNNING </td><td>136.156.133.98:1605408</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         183.131</td><td style=\"text-align: right;\"> 0.144565 </td></tr>\n",
       "<tr><td>objective_8685f_00001</td><td>RUNNING </td><td>136.156.133.98:1605409</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         209.198</td><td style=\"text-align: right;\"> 0.125172 </td></tr>\n",
       "<tr><td>objective_8685f_00002</td><td>RUNNING </td><td>136.156.133.98:1605448</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         193.979</td><td style=\"text-align: right;\"> 0.224398 </td></tr>\n",
       "<tr><td>objective_8685f_00003</td><td>RUNNING </td><td>136.156.133.98:1605455</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         214.609</td><td style=\"text-align: right;\"> 0.0673899</td></tr>\n",
       "<tr><td>objective_8685f_00004</td><td>RUNNING </td><td>136.156.133.98:1605465</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         210.429</td><td style=\"text-align: right;\"> 0.0795917</td></tr>\n",
       "<tr><td>objective_8685f_00005</td><td>RUNNING </td><td>136.156.133.98:1605479</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         216.545</td><td style=\"text-align: right;\"> 0.0642975</td></tr>\n",
       "<tr><td>objective_8685f_00006</td><td>RUNNING </td><td>136.156.133.98:1605482</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         203.531</td><td style=\"text-align: right;\"> 0.106887 </td></tr>\n",
       "<tr><td>objective_8685f_00007</td><td>RUNNING </td><td>136.156.133.98:1605483</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         234.58 </td><td style=\"text-align: right;\"> 0.171083 </td></tr>\n",
       "<tr><td>objective_8685f_00008</td><td>RUNNING </td><td>136.156.133.98:1605506</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         238.559</td><td style=\"text-align: right;\"> 0.0504668</td></tr>\n",
       "<tr><td>objective_8685f_00009</td><td>RUNNING </td><td>136.156.133.98:1605484</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         264.887</td><td style=\"text-align: right;\"> 0.171591 </td></tr>\n",
       "<tr><td>objective_8685f_00010</td><td>RUNNING </td><td>136.156.133.98:1605580</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         309.665</td><td style=\"text-align: right;\"> 0.136282 </td></tr>\n",
       "<tr><td>objective_8685f_00011</td><td>RUNNING </td><td>136.156.133.98:1605594</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         263.204</td><td style=\"text-align: right;\"> 0.160105 </td></tr>\n",
       "<tr><td>objective_8685f_00012</td><td>RUNNING </td><td>136.156.133.98:1605601</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         196.379</td><td style=\"text-align: right;\"> 1.69426  </td></tr>\n",
       "<tr><td>objective_8685f_00013</td><td>RUNNING </td><td>136.156.133.98:1605648</td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         217.914</td><td style=\"text-align: right;\"> 1.1526   </td></tr>\n",
       "<tr><td>objective_8685f_00014</td><td>RUNNING </td><td>136.156.133.98:1605771</td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         209.385</td><td style=\"text-align: right;\"> 1.61337  </td></tr>\n",
       "<tr><td>objective_8685f_00015</td><td>RUNNING </td><td>136.156.133.98:1605959</td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         210.41 </td><td style=\"text-align: right;\"> 1.1715   </td></tr>\n",
       "<tr><td>objective_8685f_00016</td><td>RUNNING </td><td>136.156.133.98:1606168</td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         202.831</td><td style=\"text-align: right;\"> 1.07075  </td></tr>\n",
       "<tr><td>objective_8685f_00017</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00018</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00019</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00020</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00021</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00022</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00023</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          1e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00024</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00025</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00026</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00027</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">           64</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00028</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00029</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00030</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00031</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.4</td><td style=\"text-align: right;\">          128</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00032</td><td>PENDING </td><td>                      </td><td>False          </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "<tr><td>objective_8685f_00033</td><td>PENDING </td><td>                      </td><td>True           </td><td style=\"text-align: right;\">      0.1</td><td style=\"text-align: right;\">          256</td><td style=\"text-align: right;\">          0.001</td><td style=\"text-align: right;\">           3</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">          </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(objective pid=1605482)\u001b[0m Device available is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 23:12:28,647\tWARNING tune.py:186 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-04-25 23:12:38,836\tINFO tune.py:1042 -- Total run time: 336.78 seconds (326.57 seconds for the tuning loop).\n",
      "2024-04-25 23:12:38,861\tWARNING tune.py:1057 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/gbmc/ray_results/objective_2024-04-25_23-07-02\", trainable=...)\n",
      "2024-04-25 23:12:38,897\tWARNING experiment_analysis.py:193 -- Failed to fetch metrics for 17 trial(s):\n",
      "- objective_8685f_00017: FileNotFoundError('Could not fetch metrics for objective_8685f_00017: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00017_17_bidirectional=True,dropout=0.1000,hidden_size=128,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00018: FileNotFoundError('Could not fetch metrics for objective_8685f_00018: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00018_18_bidirectional=False,dropout=0.4000,hidden_size=128,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00019: FileNotFoundError('Could not fetch metrics for objective_8685f_00019: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00019_19_bidirectional=True,dropout=0.4000,hidden_size=128,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00020: FileNotFoundError('Could not fetch metrics for objective_8685f_00020: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00020_20_bidirectional=False,dropout=0.1000,hidden_size=256,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00021: FileNotFoundError('Could not fetch metrics for objective_8685f_00021: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00021_21_bidirectional=True,dropout=0.1000,hidden_size=256,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00022: FileNotFoundError('Could not fetch metrics for objective_8685f_00022: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00022_22_bidirectional=False,dropout=0.4000,hidden_size=256,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00023: FileNotFoundError('Could not fetch metrics for objective_8685f_00023: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00023_23_bidirectional=True,dropout=0.4000,hidden_size=256,learning_rate=0.0000,num_layers=2_2024-04-25_23-07-07')\n",
      "- objective_8685f_00024: FileNotFoundError('Could not fetch metrics for objective_8685f_00024: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00024_24_bidirectional=False,dropout=0.1000,hidden_size=64,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-07')\n",
      "- objective_8685f_00025: FileNotFoundError('Could not fetch metrics for objective_8685f_00025: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00025_25_bidirectional=True,dropout=0.1000,hidden_size=64,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-07')\n",
      "- objective_8685f_00026: FileNotFoundError('Could not fetch metrics for objective_8685f_00026: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00026_26_bidirectional=False,dropout=0.4000,hidden_size=64,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-07')\n",
      "- objective_8685f_00027: FileNotFoundError('Could not fetch metrics for objective_8685f_00027: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00027_27_bidirectional=True,dropout=0.4000,hidden_size=64,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-07')\n",
      "- objective_8685f_00028: FileNotFoundError('Could not fetch metrics for objective_8685f_00028: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00028_28_bidirectional=False,dropout=0.1000,hidden_size=128,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-08')\n",
      "- objective_8685f_00029: FileNotFoundError('Could not fetch metrics for objective_8685f_00029: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00029_29_bidirectional=True,dropout=0.1000,hidden_size=128,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-08')\n",
      "- objective_8685f_00030: FileNotFoundError('Could not fetch metrics for objective_8685f_00030: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00030_30_bidirectional=False,dropout=0.4000,hidden_size=128,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-08')\n",
      "- objective_8685f_00031: FileNotFoundError('Could not fetch metrics for objective_8685f_00031: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00031_31_bidirectional=True,dropout=0.4000,hidden_size=128,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-08')\n",
      "- objective_8685f_00032: FileNotFoundError('Could not fetch metrics for objective_8685f_00032: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00032_32_bidirectional=False,dropout=0.1000,hidden_size=256,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-08')\n",
      "- objective_8685f_00033: FileNotFoundError('Could not fetch metrics for objective_8685f_00033: both result.json and progress.csv were not found at /home/gbmc/ray_results/objective_2024-04-25_23-07-02/objective_8685f_00033_33_bidirectional=True,dropout=0.1000,hidden_size=256,learning_rate=0.0010,num_layers=3_2024-04-25_23-07-08')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_size': 256, 'num_layers': 2, 'dropout': 0.1, 'bidirectional': False, 'learning_rate': 0.001}\n",
      "Best configuration saved to: /data/Hydra_Work/Tuning/Config_Text/General_Model_best_config.txt\n"
     ]
    }
   ],
   "source": [
    "# {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.1, 'bidirectional': True, 'learning_rate': 0.001}\n",
    "# 7 Days:  128\t2\t0.4\tFalse\t0.001\n",
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "    print('Device available is', device)\n",
    "    \n",
    "\n",
    "    score = train_model_general(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "\n",
    "#, search_alg = optuna_search\n",
    "optuna_tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "tune_config = tune.TuneConfig(scheduler=asha_scheduler)\n",
    "run_config=train.RunConfig(stop= plateau_stopper)\n",
    "\n",
    "# Without Optuna\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 15/16, \"gpu\": 1/24}), param_space=config_space, tune_config = tune_config, run_config = run_config) \n",
    "# With Optuna\n",
    "#tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 1, \"gpu\": 1/16}), param_space = optuna_config_space, tune_config = optuna_tune_config, run_config = run_config) \n",
    "\n",
    "results = tuner.fit()\n",
    "# try get_best_checkpoint, or change val to be maximum of current val_loss and previous ones\n",
    "best_config = results.get_best_result(metric=\"val_loss\", mode=\"min\").config\n",
    "print(best_config)\n",
    "file_path = f\"/data/Hydra_Work/Tuning/Config_Text/General_Model_best_config.txt\"\n",
    "\n",
    "# Open the file in write mode and save the configuration\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(str(best_config))\n",
    "\n",
    "print(\"Best configuration saved to:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>time_since_restore</th>\n",
       "      <th>iterations_since_restore</th>\n",
       "      <th>config/hidden_size</th>\n",
       "      <th>config/num_layers</th>\n",
       "      <th>config/dropout</th>\n",
       "      <th>config/bidirectional</th>\n",
       "      <th>config/learning_rate</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.158072</td>\n",
       "      <td>1713182530</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>7d6a0_00002</td>\n",
       "      <td>2024-04-15_12-02-10</td>\n",
       "      <td>584.030554</td>\n",
       "      <td>4503.406271</td>\n",
       "      <td>1290504</td>\n",
       "      <td>floodrodeo.novalocal</td>\n",
       "      <td>136.156.133.98</td>\n",
       "      <td>4503.406271</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7d6a0_00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.176701</td>\n",
       "      <td>1713182975</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>7d6a0_00006</td>\n",
       "      <td>2024-04-15_12-09-35</td>\n",
       "      <td>662.736408</td>\n",
       "      <td>4948.471493</td>\n",
       "      <td>1290542</td>\n",
       "      <td>floodrodeo.novalocal</td>\n",
       "      <td>136.156.133.98</td>\n",
       "      <td>4948.471493</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7d6a0_00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.153886</td>\n",
       "      <td>1713185397</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>7d6a0_00024</td>\n",
       "      <td>2024-04-15_12-49-57</td>\n",
       "      <td>694.571735</td>\n",
       "      <td>4692.569446</td>\n",
       "      <td>1290631</td>\n",
       "      <td>floodrodeo.novalocal</td>\n",
       "      <td>136.156.133.98</td>\n",
       "      <td>4692.569446</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7d6a0_00024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss   timestamp checkpoint_dir_name  done  training_iteration  \\\n",
       "2  -0.158072  1713182530                None  True                   8   \n",
       "6  -0.176701  1713182975                None  True                   8   \n",
       "24 -0.153886  1713185397                None  True                   7   \n",
       "\n",
       "       trial_id                 date  time_this_iter_s  time_total_s      pid  \\\n",
       "2   7d6a0_00002  2024-04-15_12-02-10        584.030554   4503.406271  1290504   \n",
       "6   7d6a0_00006  2024-04-15_12-09-35        662.736408   4948.471493  1290542   \n",
       "24  7d6a0_00024  2024-04-15_12-49-57        694.571735   4692.569446  1290631   \n",
       "\n",
       "                hostname         node_ip  time_since_restore  \\\n",
       "2   floodrodeo.novalocal  136.156.133.98         4503.406271   \n",
       "6   floodrodeo.novalocal  136.156.133.98         4948.471493   \n",
       "24  floodrodeo.novalocal  136.156.133.98         4692.569446   \n",
       "\n",
       "    iterations_since_restore  config/hidden_size  config/num_layers  \\\n",
       "2                          8                  64                  2   \n",
       "6                          8                 128                  2   \n",
       "24                         7                  64                  3   \n",
       "\n",
       "    config/dropout  config/bidirectional  config/learning_rate       logdir  \n",
       "2              0.4                 False                 0.001  7d6a0_00002  \n",
       "6              0.4                 False                 0.001  7d6a0_00006  \n",
       "24             0.1                 False                 0.001  7d6a0_00024  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = results.get_dataframe()\n",
    "results_df[results_df['val_loss'] < -0.15] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_Model = torch.load('/data/Hydra_Work/Post_Rodeo_Work/Tuned_General_Model/General_model.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hydra Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_models_hydra(body_hindcast_input_size, body_forecast_input_size, body_output_size, body_hidden_size, body_num_layers, body_dropout,\n",
    "                        head_hidden_size, head_num_layers, head_forecast_output_size, head_dropout, bidirectional, basins,\n",
    "                        learning_rate_general_head, learning_rate_head, learning_rate_body, LR = 1e-3, \n",
    "                        additional_specific_head_hindcast_input_size = 1, additional_specific_head_forecast_input_size = 0,\n",
    "                        copies=3, device=None):\n",
    "    Hydra_Bodys = {}\n",
    "    Basin_Heads = {}\n",
    "    General_Heads = {}   \n",
    "    general_optimizers = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    \n",
    "    body_forecast_output_size = body_output_size\n",
    "    body_hindcast_output_size = body_output_size\n",
    "    \n",
    "    # Define head hindcast size as head-forecast for simplicty\n",
    "    head_hindcast_output_size = head_forecast_output_size\n",
    "    specific_head_hindcast_output_size = head_forecast_output_size\n",
    "    specific_head_forecast_output_size = head_forecast_output_size\n",
    "    specific_head_hidden_size = head_hidden_size\n",
    "    specific_head_num_layers = head_num_layers\n",
    "    \n",
    "    # Head takes Body as inputs\n",
    "    #head_hindcast_input_size = body_hindcast_input_size \n",
    "    head_hindcast_input_size = body_hindcast_output_size\n",
    "    head_forecast_input_size = body_forecast_output_size\n",
    "    \n",
    "    # Specific input size\n",
    "    specific_head_hindcast_input_size = head_hindcast_input_size + additional_specific_head_hindcast_input_size\n",
    "    specific_head_forecast_input_size = head_forecast_input_size + additional_specific_head_forecast_input_size\n",
    "    \n",
    "\n",
    "    \n",
    "    for copy in range(copies):\n",
    "        Hydra_Bodys[copy] = Google_Model_Block(body_hindcast_input_size, body_forecast_input_size, body_hindcast_output_size, body_forecast_output_size, body_hidden_size, body_num_layers, device, body_dropout, bidirectional)\n",
    "        General_Heads[copy] = Google_Model_Block(head_hindcast_input_size, head_forecast_input_size, head_hindcast_output_size, head_forecast_output_size, head_hidden_size, head_num_layers, device, head_dropout, bidirectional)\n",
    "        Basin_Heads[copy] = Specific_Heads(basins, specific_head_hindcast_input_size, specific_head_forecast_input_size, specific_head_hindcast_output_size, specific_head_forecast_output_size, specific_head_hidden_size, specific_head_num_layers, device, head_dropout, bidirectional)\n",
    "\n",
    "\n",
    "        specific_head_parameters = list()\n",
    "        for basin, model in Basin_Heads[copy].items():\n",
    "            specific_head_parameters += list(model.parameters())\n",
    "\n",
    "        optimizers[copy] = torch.optim.Adam(\n",
    "        # Extra LR is the global learning rate, not really important\n",
    "        [\n",
    "            {\"params\": General_Heads[copy].parameters(), \"lr\": learning_rate_general_head},\n",
    "            {\"params\": specific_head_parameters, \"lr\": learning_rate_head},\n",
    "            {\"params\": Hydra_Bodys[copy].parameters(), \"lr\": learning_rate_body},\n",
    "        ],\n",
    "        lr=LR, weight_decay = 1e-2 )\n",
    "\n",
    "        general_optimizers[copy] = torch.optim.Adam(\n",
    "        # Extra LR is the global learning rate, not really important\n",
    "        [\n",
    "            {\"params\": General_Heads[copy].parameters(), \"lr\": learning_rate_general_head},\n",
    "            {\"params\": Hydra_Bodys[copy].parameters(), \"lr\": learning_rate_body},\n",
    "        ],\n",
    "        lr=LR, )\n",
    "        schedulers[copy] = lr_scheduler.CosineAnnealingLR(optimizers[copy], T_max=4e2)\n",
    "\n",
    "    return Hydra_Bodys, General_Heads, Basin_Heads, optimizers, schedulers, general_optimizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "static_size = np.shape(Static_variables)[1]\n",
    "forecast_size = np.shape(seasonal_forecasts['american_river_folsom_lake_2000_apr'])[1]\n",
    "History_Fourier_in_forcings = 0 #2*3*(6 - 1)\n",
    "Climate_guess = 3\n",
    "History_Statistics_in_forcings = 0 # 5*2\n",
    "\n",
    "forecast_input_size = forecast_size + static_size + History_Fourier_in_forcings + History_Statistics_in_forcings  + Climate_guess + 3\n",
    "output_size, head_hidden_size, head_num_layers =  3, 64, 3\n",
    "body_hindcast_input_size = 16\n",
    "body_forecast_input_size = forecast_input_size\n",
    "\n",
    "\n",
    "Overall_Best_Val_Loss = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1255521053.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[101], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    body_learning_rates = [1e-2 1e-4]\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import TrialPlateauStopper\n",
    "\n",
    "# Fixed parameters\n",
    "total_epochs = 120\n",
    "n_epochs = 1 # Epochs between tests\n",
    "group_lengths = [7] #np.arange(180)\n",
    "batch_size = 1\n",
    "copies = 3\n",
    "head_output_size = 3\n",
    "\n",
    "# parameters to tune\n",
    "# chose 128, 2, 0.1, 1e-3, 6, 32, 1, 0.4, 1e-3\n",
    "body_hidden_sizes =  [64]\n",
    "body_num_layers = [1,2]\n",
    "body_dropouts = [0.1] #[0.1, 0.4]\n",
    "body_learning_rates = [1e-2 1e-4]\n",
    "body_outputs = [4] # Say hindcast and forecasts have same outputrs body_hindcast_output_size\n",
    "\n",
    "\n",
    "head_hidden_sizes = [32]\n",
    "head_num_layers = [1]\n",
    "head_dropouts = [0.2] #[0.1, 0.4, 0.7]\n",
    "head_learning_rates = [1e-3]\n",
    "LR = 1e-3\n",
    "bidirectionals = [False]\n",
    "\n",
    "config_space = {\n",
    "    \"body_hidden_size\": tune.grid_search(body_hidden_sizes),\n",
    "    \"body_num_layer\": tune.grid_search(body_num_layers),\n",
    "    \"body_dropout\": tune.grid_search(body_dropouts),\n",
    "    \"bidirectional\": tune.grid_search(bidirectionals),\n",
    "    \"body_output\": tune.grid_search(body_outputs),\n",
    "    \"body_learning_rate\": tune.grid_search(body_learning_rates),\n",
    "    \"head_hidden_size\": tune.grid_search(head_hidden_sizes),\n",
    "    \"head_num_layer\": tune.grid_search(head_num_layers),\n",
    "    \"head_dropout\": tune.grid_search(head_dropouts),\n",
    "    \"head_learning_rate\": tune.grid_search(head_learning_rates),\n",
    "    #\"general_head_learning_rate\": tune.grid_search(head_learning_rates),\n",
    "}\n",
    "\n",
    "# Places to save info\n",
    "model_dir = '/data/Hydra_Work/Post_Rodeo_Work/Tuned_Hydra_Model/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_hydra(config):\n",
    "\n",
    "    All_Dates = ray.get(All_Dates_id)  \n",
    "    Val_Dates = ray.get(Val_Dates_id)  \n",
    "    era5 = ray.get(era5_id)  \n",
    "    daily_flow = ray.get(daily_flow_id)  \n",
    "    climatological_flows = ray.get(climatological_flows_id)\n",
    "    climate_indices = ray.get(climate_indices_id)\n",
    "    seasonal_forecasts = ray.get(seasonal_forecasts_id)\n",
    "    Static_variables = ray.get(Static_variables_id)  \n",
    "  \n",
    "\n",
    "    body_save_path = '/data/Hydra_Work/Tuning/Week_Ahead_Models/Hydra_Body_LSTM.pth'\n",
    "    head_save_path = '/data/Hydra_Work/Tuning/Week_Ahead_Models/Hydra_Head_LSTM.pth'\n",
    "    specific_save_path_folder = '/data/Hydra_Work/Tuning/Week_Ahead_Models/Hydra_Heads'\n",
    "\n",
    "    copies = 1\n",
    "    warmup = 4\n",
    "    best_val_loss = 999\n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                    is_available() else 'cpu')\n",
    "   \n",
    "\n",
    "    general_head_learning_rate = config['body_learning_rate']\n",
    "    Hydra_Bodys, General_Hydra_Heads, model_heads, optimizers, schedulers, general_optimizers  = define_models_hydra(body_hindcast_input_size, body_forecast_input_size, config['body_output'],\n",
    "                                config['body_hidden_size'], config['body_num_layer'], config['body_dropout'], \n",
    "                                config['head_hidden_size'], config['head_num_layer'], 3, config['head_dropout'], config['bidirectional'], basins,\n",
    "                                general_head_learning_rate, config['head_learning_rate'], config['body_learning_rate'], LR, device = device\n",
    "                                )\n",
    "     \n",
    "\n",
    "    general_losses, specific_losses, general_val_losses, specific_val_losses, val_losses = [], [], [], [], []\n",
    "\n",
    "\n",
    "    for epoch in range(total_epochs):\n",
    "        train_general_losses = {}\n",
    "        train_specific_losses = {}\n",
    "        epoch_val_general_losses = {}\n",
    "        epoch_val_specific_losses = {}\n",
    "        climate_losses = {}\n",
    "        \n",
    "        for copy in range(copies):\n",
    "            # Initialise\n",
    "            train_general_losses[copy], train_specific_losses[copy], climate_losses[copy] = Model_Run(All_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, general_optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs= warmup,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, feed_forcing = False)\n",
    "                        \n",
    "\n",
    "            # Full Training\n",
    "            train_general_losses[copy], train_specific_losses[copy], climate_losses[copy] = Model_Run(All_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=True, device=device, feed_forcing = False)\n",
    "            epoch_val_general_losses[copy], epoch_val_specific_losses[copy], climate_losses[copy] = Model_Run(Val_Dates, basins, Hydra_Bodys[copy], General_Hydra_Heads[copy], model_heads[copy], era5, daily_flow, climatological_flows, climate_indices, seasonal_forecasts,\n",
    "                Static_variables, optimizers[copy], schedulers[copy], criterion, early_stopper= None, n_epochs=n_epochs,\n",
    "                batch_size=batch_size, group_lengths=group_lengths, Train_Mode=False, device=device, feed_forcing = False)\n",
    "\n",
    "        general_loss = np.mean(list(train_general_losses.values()))\n",
    "        specific_loss = np.mean(list(train_specific_losses.values()))\n",
    "        climate_loss = np.mean(list(climate_losses.values()))\n",
    "        \n",
    "        epoch_val_general_loss = np.mean(list(epoch_val_general_losses.values())).mean()\n",
    "        epoch_val_specific_loss = np.mean(list(epoch_val_specific_losses.values())).mean()\n",
    "        \n",
    "        \n",
    "        general_losses.append(general_loss)\n",
    "        specific_losses.append(specific_loss)\n",
    "        specific_val_losses.append(epoch_val_specific_loss)\n",
    "        general_val_losses.append(epoch_val_general_loss)\n",
    "\n",
    "        val_loss = 0.5*(epoch_val_general_loss + epoch_val_specific_loss)\n",
    "        \n",
    "        candidate_val_loss = ((val_loss.mean() - climate_loss))/np.mean(climate_loss)\n",
    "        best_val_loss = np.min([best_val_loss, candidate_val_loss ])\n",
    "         \n",
    "        with open('/data/Hydra_Work/Tuning/Week_Ahead_Models/Current_Loss.txt', 'r') as file:\n",
    "            # Read the entire contents of the file\n",
    "            Overall_Best_Val_Loss = float(file.read())\n",
    "\n",
    "        if best_val_loss < Overall_Best_Val_Loss:\n",
    "            with open('/data/Hydra_Work/Tuning/Week_Ahead_Models/Current_Loss.txt', 'w') as f:\n",
    "                f.write('%f' % best_val_loss)\n",
    "\n",
    "            torch.save(Hydra_Bodys[0], body_save_path)\n",
    "            torch.save(General_Hydra_Heads[0], head_save_path)\n",
    "            for basin in basins:\n",
    "                torch.save(model_heads[0][basin], f\"{specific_save_path_folder}/{basin}.path\")\n",
    "                \n",
    "            \n",
    "               \n",
    "        ray.train.report({'val_loss' : best_val_loss})\n",
    "\n",
    "        val_losses.append(best_val_loss)\n",
    "\n",
    "\n",
    "    return best_val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-01 07:26:51,558\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "from ray import train, tune\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env = { \"env_vars\":   {\"PYTHONPATH\": '/data/Hydra_Work/Competition_Functions/' } } )\n",
    "         \n",
    "All_Dates_id = ray.put(All_Dates)  \n",
    "Val_Dates_id = ray.put(Val_Dates)  \n",
    "era5_id = ray.put(era5)  \n",
    "daily_flow_id = ray.put(daily_flow)  \n",
    "climatological_flows_id = ray.put(climatological_flows)\n",
    "climate_indices_id = ray.put(climate_indices)\n",
    "seasonal_forecasts_id = ray.put(seasonal_forecasts)\n",
    "Static_variables_id = ray.put(Static_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "asha_scheduler = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='val_loss',\n",
    "    mode='min',\n",
    "    max_t=100,\n",
    "    grace_period=10,\n",
    "    reduction_factor=3,\n",
    "    brackets=1,\n",
    ")\n",
    "\n",
    "\n",
    "plateau_stopper = TrialPlateauStopper(\n",
    "    metric=\"val_loss\",\n",
    "    num_results = 4,\n",
    "    grace_period=10,\n",
    "    mode=\"min\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-01 07:31:30</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:00.59        </td></tr>\n",
       "<tr><td>Memory:      </td><td>22.4/125.9 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 15.0/16 CPUs, 0.8/1 GPUs (0.0/1.0 accelerator_type:A100D)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>status  </th><th>loc                   </th><th>bidirectional  </th><th style=\"text-align: right;\">  body_dropout</th><th style=\"text-align: right;\">  body_hidden_size</th><th style=\"text-align: right;\">  body_learning_rate</th><th style=\"text-align: right;\">  body_num_layer</th><th style=\"text-align: right;\">  body_output</th><th style=\"text-align: right;\">  head_dropout</th><th style=\"text-align: right;\">  head_hidden_size</th><th style=\"text-align: right;\">  head_learning_rate</th><th style=\"text-align: right;\">  head_num_layer</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_8c499_00000</td><td>RUNNING </td><td>136.156.133.98:1758662</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">              0.001 </td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_8c499_00001</td><td>RUNNING </td><td>136.156.133.98:1758663</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">              0.0001</td><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_8c499_00002</td><td>RUNNING </td><td>136.156.133.98:1758835</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">              0.001 </td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "<tr><td>objective_8c499_00003</td><td>RUNNING </td><td>136.156.133.98:1758840</td><td>False          </td><td style=\"text-align: right;\">           0.1</td><td style=\"text-align: right;\">                64</td><td style=\"text-align: right;\">              0.0001</td><td style=\"text-align: right;\">               2</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">           0.2</td><td style=\"text-align: right;\">                32</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">               1</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runs_per_iteration = 4\n",
    "def objective(config):  \n",
    "    device = torch.device('cuda' if torch.cuda.\n",
    "                      is_available() else 'cpu')\n",
    "    \n",
    "\n",
    "    score = train_model_hydra(config) # Have training loop in here that outputs loss of model\n",
    "    return {\"val_loss\": score}\n",
    "\n",
    "\n",
    "# Can use fractions of GPU\n",
    "tuner = tune.Tuner(tune.with_resources(tune.with_parameters(objective), resources={\"cpu\": 15/runs_per_iteration, \"gpu\": 1/(runs_per_iteration+1)}), param_space=config_space) \n",
    "\n",
    "results = tuner.fit()\n",
    "best_config = results.get_best_result(metric=\"val_loss\", mode=\"min\").config\n",
    "print(best_config)\n",
    "file_path = f\"/data/Hydra_Work/Tuning/Config_Text/Hydral_Model_best_config.txt\"\n",
    "\n",
    "# Open the file in write mode and save the configuration\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(str(best_config))\n",
    "\n",
    "print(\"Best configuration saved to:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>checkpoint_dir_name</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>config/body_num_layer</th>\n",
       "      <th>config/body_dropout</th>\n",
       "      <th>config/bidirectional</th>\n",
       "      <th>config/body_output</th>\n",
       "      <th>config/body_learning_rate</th>\n",
       "      <th>config/head_hidden_size</th>\n",
       "      <th>config/head_num_layer</th>\n",
       "      <th>config/head_dropout</th>\n",
       "      <th>config/head_learning_rate</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.140246</td>\n",
       "      <td>1714473087</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>f96d7_00017</td>\n",
       "      <td>2024-04-30_10-31-27</td>\n",
       "      <td>0.028421</td>\n",
       "      <td>25120.633540</td>\n",
       "      <td>1723537</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>f96d7_00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.125336</td>\n",
       "      <td>1714472901</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>f96d7_00018</td>\n",
       "      <td>2024-04-30_10-28-21</td>\n",
       "      <td>0.027875</td>\n",
       "      <td>24924.925317</td>\n",
       "      <td>1723636</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>f96d7_00018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.141807</td>\n",
       "      <td>1714473104</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>f96d7_00019</td>\n",
       "      <td>2024-04-30_10-31-44</td>\n",
       "      <td>0.026957</td>\n",
       "      <td>25118.832308</td>\n",
       "      <td>1723623</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>f96d7_00019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.107290</td>\n",
       "      <td>1714473123</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>f96d7_00022</td>\n",
       "      <td>2024-04-30_10-32-03</td>\n",
       "      <td>0.031044</td>\n",
       "      <td>25128.270957</td>\n",
       "      <td>1723502</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>f96d7_00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.100405</td>\n",
       "      <td>1714473125</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>f96d7_00025</td>\n",
       "      <td>2024-04-30_10-32-05</td>\n",
       "      <td>0.021802</td>\n",
       "      <td>25126.842232</td>\n",
       "      <td>1723664</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>f96d7_00025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    val_loss   timestamp checkpoint_dir_name   done  training_iteration  \\\n",
       "17 -0.140246  1714473087                None  False                  21   \n",
       "18 -0.125336  1714472901                None  False                  21   \n",
       "19 -0.141807  1714473104                None  False                  21   \n",
       "22 -0.107290  1714473123                None  False                  21   \n",
       "25 -0.100405  1714473125                None  False                  21   \n",
       "\n",
       "       trial_id                 date  time_this_iter_s  time_total_s      pid  \\\n",
       "17  f96d7_00017  2024-04-30_10-31-27          0.028421  25120.633540  1723537   \n",
       "18  f96d7_00018  2024-04-30_10-28-21          0.027875  24924.925317  1723636   \n",
       "19  f96d7_00019  2024-04-30_10-31-44          0.026957  25118.832308  1723623   \n",
       "22  f96d7_00022  2024-04-30_10-32-03          0.031044  25128.270957  1723502   \n",
       "25  f96d7_00025  2024-04-30_10-32-05          0.021802  25126.842232  1723664   \n",
       "\n",
       "    ... config/body_num_layer config/body_dropout  config/bidirectional  \\\n",
       "17  ...                     1                 0.2                 False   \n",
       "18  ...                     1                 0.2                 False   \n",
       "19  ...                     1                 0.2                 False   \n",
       "22  ...                     1                 0.2                 False   \n",
       "25  ...                     1                 0.2                 False   \n",
       "\n",
       "    config/body_output  config/body_learning_rate  config/head_hidden_size  \\\n",
       "17                   4                    0.00100                       32   \n",
       "18                   4                    0.00001                       32   \n",
       "19                   4                    0.00001                       32   \n",
       "22                   8                    0.00001                       32   \n",
       "25                   4                    0.00100                       64   \n",
       "\n",
       "    config/head_num_layer  config/head_dropout  config/head_learning_rate  \\\n",
       "17                      1                  0.2                      0.001   \n",
       "18                      1                  0.2                      0.001   \n",
       "19                      1                  0.2                      0.001   \n",
       "22                      1                  0.2                      0.001   \n",
       "25                      1                  0.2                      0.001   \n",
       "\n",
       "         logdir  \n",
       "17  f96d7_00017  \n",
       "18  f96d7_00018  \n",
       "19  f96d7_00019  \n",
       "22  f96d7_00022  \n",
       "25  f96d7_00025  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df['val_loss'] < -0.1]#[['val_loss', 'config/body_output']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hydra_Code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
